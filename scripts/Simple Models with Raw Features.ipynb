{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy as sp\n",
    "\n",
    "# from scipy.special import erfinv\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_raw = pd.read_csv('../input/train.csv')\n",
    "# data_train_raw = data_train_raw.sample(frac=0.01, random_state=0)\n",
    "data_test_raw = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188318, 132)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ylog=np.log1p(data_train_raw['loss'])\n",
    "# ymean=ylog.mean()\n",
    "# ystd=ylog.std()\n",
    "ymean=ylog.min()\n",
    "ystd=ylog.max()\n",
    "data_train_raw['loss_g']=(ylog-ymean)/ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of log1py: 0.612892612558\n",
      "Std of log1py: 0.0693210249117\n",
      "Lower clipping bound: 0.404929537823\n",
      "Upper clipping bound: 0.820855687293\n",
      "Shape of cleaned data: (187954, 133)\n"
     ]
    }
   ],
   "source": [
    "# clean outliers in training data\n",
    "lossMean = data_train_raw['loss_g'].mean()\n",
    "lossStd = data_train_raw['loss_g'].std()\n",
    "print('Mean of log1py: {}'.format(lossMean))\n",
    "print('Std of log1py: {}'.format(lossStd))\n",
    "lbound = lossMean-3.0*lossStd\n",
    "ubound = lossMean+3.0*lossStd\n",
    "print('Lower clipping bound: {}\\nUpper clipping bound: {}'.format(lbound, ubound))\n",
    "data_train_raw = data_train_raw[(data_train_raw['loss_g']>=lbound) & (data_train_raw['loss_g']<=ubound)]\n",
    "print('Shape of cleaned data: {}'.format(data_train_raw.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ToUniform(y):\n",
    "    z = norm.cdf(-y/np.sqrt(2))\n",
    "    return z\n",
    "def UniformToGauss(z):\n",
    "    return -np.sqrt(2)*norm.ppf(z)*ystd+ymean\n",
    "# def BackToOriginal(z):\n",
    "#     return np.exp(UniformToGauss(z))\n",
    "\n",
    "data_train_raw['loss_u']=ToUniform(data_train_raw['loss_g'])\n",
    "\n",
    "def lossRestore(logloss, ymean, ystd):\n",
    "    loss = np.expm1(logloss*ystd+ymean)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4cAAAEKCAYAAAChXCC5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQzMzMzMzM8OVQzMzMzMzMwP+H5HzbSkhdUDTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc009f83e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(data_train_raw['loss'],100)\n",
    "plt.title('loss');\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(ylog,100)\n",
    "plt.title('log(loss) - Gauss');\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(data_train_raw['loss_g'],100)\n",
    "plt.title('Normal');\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(lossRestore(data_train_raw['loss_g'],ymean,ystd),100)\n",
    "plt.title('Normal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation - labeling encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDf has features from the raw data:\n",
      "Index([u'cat1', u'cat2', u'cat3', u'cat4', u'cat5', u'cat6', u'cat7', u'cat8',\n",
      "       u'cat9', u'cat10',\n",
      "       ...\n",
      "       u'cont5', u'cont6', u'cont7', u'cont8', u'cont9', u'cont10', u'cont11',\n",
      "       u'cont12', u'cont13', u'cont14'],\n",
      "      dtype='object', length=130)\n",
      "testDf has features from the raw data:\n",
      "Index([u'cat1', u'cat2', u'cat3', u'cat4', u'cat5', u'cat6', u'cat7', u'cat8',\n",
      "       u'cat9', u'cat10',\n",
      "       ...\n",
      "       u'cont5', u'cont6', u'cont7', u'cont8', u'cont9', u'cont10', u'cont11',\n",
      "       u'cont12', u'cont13', u'cont14'],\n",
      "      dtype='object', length=130)\n"
     ]
    }
   ],
   "source": [
    "# save label in a seperate serie\n",
    "labelSs = data_train_raw['loss_g'] \n",
    "trainDf = data_train_raw.drop(['id','loss','loss_g','loss_u'],axis=1)\n",
    "subId = data_test_raw['id']\n",
    "testDf = data_test_raw.drop(['id'],axis=1)\n",
    "\n",
    "print('trainDf has features from the raw data:\\n{}'.format(trainDf.columns))\n",
    "print('testDf has features from the raw data:\\n{}'.format(testDf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the stacked data's dimension are:\n",
      "(313500, 130)\n",
      "(313500, 116) of which are categorical\n",
      "(313500, 14) of which are continuous\n"
     ]
    }
   ],
   "source": [
    "dataAll = pd.concat([trainDf,testDf])\n",
    "dataCatAll = dataAll.select_dtypes(include=['object'])\n",
    "dataFltAll = dataAll.select_dtypes(include=['float64'])\n",
    "print('the stacked data\\'s dimension are:\\n{}'.format(dataAll.shape))\n",
    "print('{} of which are categorical'.format(dataCatAll.shape))\n",
    "print('{} of which are continuous'.format(dataFltAll.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'cat1', u'cat2', u'cat3', u'cat4', u'cat5', u'cat6', u'cat7', u'cat8',\n",
      "       u'cat9', u'cat10',\n",
      "       ...\n",
      "       u'cat107', u'cat108', u'cat109', u'cat110', u'cat111', u'cat112',\n",
      "       u'cat113', u'cat114', u'cat115', u'cat116'],\n",
      "      dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in dataCatAll.columns:\n",
    "    if (col.find('cat') !=-1):\n",
    "#        print(col)\n",
    "        dataCatAll[col]=le.fit_transform(dataCatAll[col])\n",
    "#         dataAll[col] = dataAll[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "#         le.classes_ = np.append(le.classes_, '<unknown>')\n",
    "#         data_test_raw[str(col+'_numerical')]=le.transform(data_test_raw[col])\n",
    "print(dataCatAll.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restore to x_trainDf and x_testDf - skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # hstack all the features and .\n",
    "# x_allDf = pd.concat([dataCatAll,dataFltAll],axis=1)\n",
    "# x_means = x_allDf.mean()\n",
    "# x_stds = x_allDf.std()\n",
    "# x_allDf = (x_allDf-x_means)/x_stds\n",
    "# x_allDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_Train = x_allDf.iloc[0:len(labelSs),:]\n",
    "# x_Test = x_allDf.iloc[len(labelSs):,:]\n",
    "# y_Train = labelSs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313500, 1175)\n"
     ]
    }
   ],
   "source": [
    "# one-hot-encoding the categorical features\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "x_catAll = enc.fit_transform(dataCatAll)\n",
    "print(x_catAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split x_train and x_test\n",
    "x_Train = sp.sparse.hstack((x_catAll[0:len(labelSs),:], sp.sparse.csr_matrix(dataFltAll.as_matrix())[0:len(labelSs),:]))\n",
    "x_Test = sp.sparse.hstack((x_catAll[len(labelSs):,:], sp.sparse.csr_matrix(dataFltAll.as_matrix())[len(labelSs):,:]))\n",
    "y_Train = labelSs.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the dimension of prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125546, 1189)\n",
      "(187954, 1189)\n",
      "(187954,)\n"
     ]
    }
   ],
   "source": [
    "print(x_Test.shape)\n",
    "print(x_Train.shape)\n",
    "print(y_Train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splite the training data for valication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150363, 1189)\n",
      "(150363,)\n",
      "(37591, 1189)\n",
      "(37591,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "val_size = 0.2\n",
    "seed = 0\n",
    "x_train, x_val, y_train, y_val = cross_validation.train_test_split(x_Train, y_Train, test_size=val_size, random_state=seed)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x_Train\n",
    "del y_Train\n",
    "del x_catAll\n",
    "del dataCatAll\n",
    "# del trainDf\n",
    "# del testDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = []\n",
    "y_pred_val = []\n",
    "submission = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testList = ['XGBoostTrees', 'AdaBoosting', 'MLPRegressor','Ensemble']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV\n",
    "# # from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cv = 3\n",
    "# # alphas = (1e-2,1e-1,1,1e1,1e2)\n",
    "# # alphas = (20,30,40)\n",
    "# alphas = [40]\n",
    "# regCV = RidgeCV(cv=cv,alphas = alphas)\n",
    "# regCV.fit(x_train,y_train)\n",
    "# print('alpha: {}\\n'.format(regCV.alpha_))\n",
    "# # print('cv_values_: {}\\n'.format(regCV.cv_values_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(regCV.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(regCV.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(regCV.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cv = 3\n",
    "# # alphas = (1e-3,1e-2,1e-1,1,1e1,1e2,1e3)\n",
    "# # alphas = (0.0005,0.0007,0.001,0.003,0.005)\n",
    "# # alphas = [0.00005,0.0001,0.0003,0.0005]\n",
    "# alphas = [0.00005]\n",
    "# LassoCV = LassoCV(cv=cv,alphas = alphas)\n",
    "# LassoCV.fit(x_train,y_train)\n",
    "# print('alpha: {}\\n'.format(LassoCV.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(LassoCV.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(LassoCV.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(LassoCV.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipped - Random Forest - using mse rather than mae, because the mae implementation is much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# criterion = 'mse'\n",
    "# n_estimators = [30]\n",
    "# err = 999999999\n",
    "# n_estimator = 0\n",
    "# random_state = 0\n",
    "# for n_est in n_estimators:\n",
    "#     tmpRFReg = RandomForestRegressor(n_estimators = n_est,criterion = criterion, random_state = random_state)\n",
    "#     tmpRFReg.fit(x_train,y_train)\n",
    "#     err_i = mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(tmpRFReg.predict(x_val),ymean,ystd))\n",
    "#     print(err_i)\n",
    "#     if err_i < err:\n",
    "#         RFReg = tmpRFReg\n",
    "#         n_estimator = n_est\n",
    "#         err = err_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('n_estimator = {}'.format(n_estimator))\n",
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(RFReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(RFReg.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(RFReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_train_xgb = xgb.DMatrix(x_train.tocsc(),label=y_train)\n",
    "d_val_xgb = xgb.DMatrix(x_val.tocsc(),label = y_val)\n",
    "x_val_xgb = xgb.DMatrix(x_val.tocsc())\n",
    "d_test_xgb = xgb.DMatrix(x_Test.tocsc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mae:0.109682\ttrain-mae:0.109271\n",
      "[1]\teval-mae:0.104732\ttrain-mae:0.104322\n",
      "[2]\teval-mae:0.100101\ttrain-mae:0.099692\n",
      "[3]\teval-mae:0.09577\ttrain-mae:0.095361\n",
      "[4]\teval-mae:0.091725\ttrain-mae:0.091313\n",
      "[5]\teval-mae:0.087956\ttrain-mae:0.087539\n",
      "[6]\teval-mae:0.084438\ttrain-mae:0.084023\n",
      "[7]\teval-mae:0.081155\ttrain-mae:0.080742\n",
      "[8]\teval-mae:0.078089\ttrain-mae:0.077678\n",
      "[9]\teval-mae:0.075254\ttrain-mae:0.074847\n",
      "[10]\teval-mae:0.072599\ttrain-mae:0.072191\n",
      "[11]\teval-mae:0.070113\ttrain-mae:0.069702\n",
      "[12]\teval-mae:0.067834\ttrain-mae:0.067427\n",
      "[13]\teval-mae:0.065695\ttrain-mae:0.065286\n",
      "[14]\teval-mae:0.063693\ttrain-mae:0.063289\n",
      "[15]\teval-mae:0.06183\ttrain-mae:0.06143\n",
      "[16]\teval-mae:0.060126\ttrain-mae:0.059732\n",
      "[17]\teval-mae:0.058564\ttrain-mae:0.058166\n",
      "[18]\teval-mae:0.05706\ttrain-mae:0.056663\n",
      "[19]\teval-mae:0.055719\ttrain-mae:0.055317\n",
      "[20]\teval-mae:0.054422\ttrain-mae:0.054026\n",
      "[21]\teval-mae:0.05326\ttrain-mae:0.052864\n",
      "[22]\teval-mae:0.052156\ttrain-mae:0.051762\n",
      "[23]\teval-mae:0.051151\ttrain-mae:0.050758\n",
      "[24]\teval-mae:0.050203\ttrain-mae:0.049814\n",
      "[25]\teval-mae:0.049358\ttrain-mae:0.048972\n",
      "[26]\teval-mae:0.048573\ttrain-mae:0.048189\n",
      "[27]\teval-mae:0.047848\ttrain-mae:0.047465\n",
      "[28]\teval-mae:0.047146\ttrain-mae:0.046767\n",
      "[29]\teval-mae:0.046527\ttrain-mae:0.046148\n",
      "[30]\teval-mae:0.045945\ttrain-mae:0.045566\n",
      "[31]\teval-mae:0.045416\ttrain-mae:0.045037\n",
      "[32]\teval-mae:0.044901\ttrain-mae:0.044523\n",
      "[33]\teval-mae:0.044422\ttrain-mae:0.044041\n",
      "[34]\teval-mae:0.043997\ttrain-mae:0.043621\n",
      "[35]\teval-mae:0.043599\ttrain-mae:0.043222\n",
      "[36]\teval-mae:0.043191\ttrain-mae:0.04282\n",
      "[37]\teval-mae:0.042836\ttrain-mae:0.042465\n",
      "[38]\teval-mae:0.04251\ttrain-mae:0.04214\n",
      "[39]\teval-mae:0.042219\ttrain-mae:0.041851\n",
      "[40]\teval-mae:0.041934\ttrain-mae:0.04157\n",
      "[41]\teval-mae:0.041662\ttrain-mae:0.041303\n",
      "[42]\teval-mae:0.041417\ttrain-mae:0.041058\n",
      "[43]\teval-mae:0.041156\ttrain-mae:0.040797\n",
      "[44]\teval-mae:0.040934\ttrain-mae:0.040576\n",
      "[45]\teval-mae:0.040726\ttrain-mae:0.040371\n",
      "[46]\teval-mae:0.040514\ttrain-mae:0.040161\n",
      "[47]\teval-mae:0.040343\ttrain-mae:0.039991\n",
      "[48]\teval-mae:0.040173\ttrain-mae:0.039821\n",
      "[49]\teval-mae:0.040018\ttrain-mae:0.039672\n",
      "[50]\teval-mae:0.039857\ttrain-mae:0.039509\n",
      "[51]\teval-mae:0.039721\ttrain-mae:0.03937\n",
      "[52]\teval-mae:0.03956\ttrain-mae:0.039211\n",
      "[53]\teval-mae:0.039423\ttrain-mae:0.039076\n",
      "[54]\teval-mae:0.039287\ttrain-mae:0.03894\n",
      "[55]\teval-mae:0.039182\ttrain-mae:0.038833\n",
      "[56]\teval-mae:0.039084\ttrain-mae:0.038737\n",
      "[57]\teval-mae:0.038985\ttrain-mae:0.038636\n",
      "[58]\teval-mae:0.038882\ttrain-mae:0.038531\n",
      "[59]\teval-mae:0.038801\ttrain-mae:0.038447\n",
      "[60]\teval-mae:0.038715\ttrain-mae:0.038361\n",
      "[61]\teval-mae:0.038629\ttrain-mae:0.038274\n",
      "[62]\teval-mae:0.038534\ttrain-mae:0.038183\n",
      "[63]\teval-mae:0.038452\ttrain-mae:0.038103\n",
      "[64]\teval-mae:0.038389\ttrain-mae:0.038039\n",
      "[65]\teval-mae:0.038319\ttrain-mae:0.037966\n",
      "[66]\teval-mae:0.038238\ttrain-mae:0.037887\n",
      "[67]\teval-mae:0.038181\ttrain-mae:0.037831\n",
      "[68]\teval-mae:0.038123\ttrain-mae:0.037771\n",
      "[69]\teval-mae:0.038051\ttrain-mae:0.037698\n",
      "[70]\teval-mae:0.037997\ttrain-mae:0.037645\n",
      "[71]\teval-mae:0.037943\ttrain-mae:0.037592\n",
      "[72]\teval-mae:0.037855\ttrain-mae:0.037507\n",
      "[73]\teval-mae:0.03781\ttrain-mae:0.03746\n",
      "[74]\teval-mae:0.037761\ttrain-mae:0.03741\n",
      "[75]\teval-mae:0.037724\ttrain-mae:0.037373\n",
      "[76]\teval-mae:0.03766\ttrain-mae:0.037311\n",
      "[77]\teval-mae:0.037614\ttrain-mae:0.037264\n",
      "[78]\teval-mae:0.03757\ttrain-mae:0.037219\n",
      "[79]\teval-mae:0.03753\ttrain-mae:0.037176\n",
      "[80]\teval-mae:0.037488\ttrain-mae:0.037135\n",
      "[81]\teval-mae:0.037454\ttrain-mae:0.0371\n",
      "[82]\teval-mae:0.037405\ttrain-mae:0.037053\n",
      "[83]\teval-mae:0.037367\ttrain-mae:0.037012\n",
      "[84]\teval-mae:0.037329\ttrain-mae:0.036975\n",
      "[85]\teval-mae:0.037301\ttrain-mae:0.036947\n",
      "[86]\teval-mae:0.037263\ttrain-mae:0.03691\n",
      "[87]\teval-mae:0.037235\ttrain-mae:0.036881\n",
      "[88]\teval-mae:0.037206\ttrain-mae:0.03685\n",
      "[89]\teval-mae:0.037174\ttrain-mae:0.036814\n",
      "[90]\teval-mae:0.037147\ttrain-mae:0.036789\n",
      "[91]\teval-mae:0.037112\ttrain-mae:0.036751\n",
      "[92]\teval-mae:0.037088\ttrain-mae:0.036726\n",
      "[93]\teval-mae:0.037059\ttrain-mae:0.036696\n",
      "[94]\teval-mae:0.037039\ttrain-mae:0.036674\n",
      "[95]\teval-mae:0.037014\ttrain-mae:0.036646\n",
      "[96]\teval-mae:0.036986\ttrain-mae:0.036617\n",
      "[97]\teval-mae:0.036964\ttrain-mae:0.036594\n",
      "[98]\teval-mae:0.036937\ttrain-mae:0.036563\n",
      "[99]\teval-mae:0.036904\ttrain-mae:0.03653\n",
      "[100]\teval-mae:0.036885\ttrain-mae:0.036511\n",
      "[101]\teval-mae:0.036855\ttrain-mae:0.036482\n",
      "[102]\teval-mae:0.03684\ttrain-mae:0.036465\n",
      "[103]\teval-mae:0.036818\ttrain-mae:0.036442\n",
      "[104]\teval-mae:0.0368\ttrain-mae:0.036423\n",
      "[105]\teval-mae:0.036769\ttrain-mae:0.036392\n",
      "[106]\teval-mae:0.03675\ttrain-mae:0.036369\n",
      "[107]\teval-mae:0.03673\ttrain-mae:0.036348\n",
      "[108]\teval-mae:0.036693\ttrain-mae:0.036312\n",
      "[109]\teval-mae:0.036667\ttrain-mae:0.036285\n",
      "[110]\teval-mae:0.036648\ttrain-mae:0.036262\n",
      "[111]\teval-mae:0.036631\ttrain-mae:0.036245\n",
      "[112]\teval-mae:0.036611\ttrain-mae:0.036225\n",
      "[113]\teval-mae:0.03659\ttrain-mae:0.036203\n",
      "[114]\teval-mae:0.036574\ttrain-mae:0.036187\n",
      "[115]\teval-mae:0.036559\ttrain-mae:0.036171\n",
      "[116]\teval-mae:0.036538\ttrain-mae:0.036152\n",
      "[117]\teval-mae:0.03652\ttrain-mae:0.036133\n",
      "[118]\teval-mae:0.036502\ttrain-mae:0.036117\n",
      "[119]\teval-mae:0.036488\ttrain-mae:0.0361\n",
      "[120]\teval-mae:0.036474\ttrain-mae:0.036085\n",
      "[121]\teval-mae:0.036459\ttrain-mae:0.036067\n",
      "[122]\teval-mae:0.036446\ttrain-mae:0.036054\n",
      "[123]\teval-mae:0.036432\ttrain-mae:0.03604\n",
      "[124]\teval-mae:0.036422\ttrain-mae:0.036028\n",
      "[125]\teval-mae:0.036396\ttrain-mae:0.036002\n",
      "[126]\teval-mae:0.036384\ttrain-mae:0.035987\n",
      "[127]\teval-mae:0.036373\ttrain-mae:0.035974\n",
      "[128]\teval-mae:0.036362\ttrain-mae:0.035961\n",
      "[129]\teval-mae:0.036345\ttrain-mae:0.035944\n",
      "[130]\teval-mae:0.036335\ttrain-mae:0.035932\n",
      "[131]\teval-mae:0.036323\ttrain-mae:0.035918\n",
      "[132]\teval-mae:0.036308\ttrain-mae:0.035902\n",
      "[133]\teval-mae:0.036294\ttrain-mae:0.035885\n",
      "[134]\teval-mae:0.036273\ttrain-mae:0.035864\n",
      "[135]\teval-mae:0.036264\ttrain-mae:0.035851\n",
      "[136]\teval-mae:0.036251\ttrain-mae:0.035838\n",
      "[137]\teval-mae:0.036237\ttrain-mae:0.035824\n",
      "[138]\teval-mae:0.036228\ttrain-mae:0.035813\n",
      "[139]\teval-mae:0.036218\ttrain-mae:0.035801\n",
      "[140]\teval-mae:0.036205\ttrain-mae:0.035787\n",
      "[141]\teval-mae:0.036184\ttrain-mae:0.035765\n",
      "[142]\teval-mae:0.036171\ttrain-mae:0.035752\n",
      "[143]\teval-mae:0.036165\ttrain-mae:0.035745\n",
      "[144]\teval-mae:0.036158\ttrain-mae:0.035735\n",
      "[145]\teval-mae:0.03615\ttrain-mae:0.035724\n",
      "[146]\teval-mae:0.036143\ttrain-mae:0.035716\n",
      "[147]\teval-mae:0.036133\ttrain-mae:0.035705\n",
      "[148]\teval-mae:0.036126\ttrain-mae:0.035696\n",
      "[149]\teval-mae:0.036113\ttrain-mae:0.035682\n",
      "[150]\teval-mae:0.036103\ttrain-mae:0.035671\n",
      "[151]\teval-mae:0.036094\ttrain-mae:0.03566\n",
      "[152]\teval-mae:0.036089\ttrain-mae:0.035653\n",
      "[153]\teval-mae:0.036078\ttrain-mae:0.035641\n",
      "[154]\teval-mae:0.036066\ttrain-mae:0.035629\n",
      "[155]\teval-mae:0.036062\ttrain-mae:0.035623\n",
      "[156]\teval-mae:0.036053\ttrain-mae:0.035612\n",
      "[157]\teval-mae:0.036037\ttrain-mae:0.035596\n",
      "[158]\teval-mae:0.036034\ttrain-mae:0.035589\n",
      "[159]\teval-mae:0.036026\ttrain-mae:0.03558\n",
      "[160]\teval-mae:0.036018\ttrain-mae:0.03557\n",
      "[161]\teval-mae:0.036006\ttrain-mae:0.035557\n",
      "[162]\teval-mae:0.036\ttrain-mae:0.035552\n",
      "[163]\teval-mae:0.035994\ttrain-mae:0.035544\n",
      "[164]\teval-mae:0.035987\ttrain-mae:0.035534\n",
      "[165]\teval-mae:0.035979\ttrain-mae:0.035524\n",
      "[166]\teval-mae:0.035973\ttrain-mae:0.035518\n",
      "[167]\teval-mae:0.035969\ttrain-mae:0.035511\n",
      "[168]\teval-mae:0.035963\ttrain-mae:0.035504\n",
      "[169]\teval-mae:0.035956\ttrain-mae:0.035496\n",
      "[170]\teval-mae:0.035948\ttrain-mae:0.035487\n",
      "[171]\teval-mae:0.035941\ttrain-mae:0.035477\n",
      "[172]\teval-mae:0.035936\ttrain-mae:0.035472\n",
      "[173]\teval-mae:0.03593\ttrain-mae:0.035465\n",
      "[174]\teval-mae:0.035922\ttrain-mae:0.035456\n",
      "[175]\teval-mae:0.035914\ttrain-mae:0.035448\n",
      "[176]\teval-mae:0.03591\ttrain-mae:0.03544\n",
      "[177]\teval-mae:0.035906\ttrain-mae:0.035435\n",
      "[178]\teval-mae:0.035901\ttrain-mae:0.035427\n",
      "[179]\teval-mae:0.035893\ttrain-mae:0.035418\n",
      "[180]\teval-mae:0.035886\ttrain-mae:0.035409\n",
      "[181]\teval-mae:0.035879\ttrain-mae:0.0354\n",
      "[182]\teval-mae:0.035875\ttrain-mae:0.035393\n",
      "[183]\teval-mae:0.03587\ttrain-mae:0.035387\n",
      "[184]\teval-mae:0.035867\ttrain-mae:0.035382\n",
      "[185]\teval-mae:0.035857\ttrain-mae:0.035372\n",
      "[186]\teval-mae:0.035853\ttrain-mae:0.035368\n",
      "[187]\teval-mae:0.035847\ttrain-mae:0.03536\n",
      "[188]\teval-mae:0.035844\ttrain-mae:0.035355\n",
      "[189]\teval-mae:0.035839\ttrain-mae:0.035349\n",
      "[190]\teval-mae:0.035835\ttrain-mae:0.035345\n",
      "[191]\teval-mae:0.035831\ttrain-mae:0.035338\n",
      "[192]\teval-mae:0.035827\ttrain-mae:0.035333\n",
      "[193]\teval-mae:0.035819\ttrain-mae:0.035325\n",
      "[194]\teval-mae:0.035816\ttrain-mae:0.03532\n",
      "[195]\teval-mae:0.035814\ttrain-mae:0.035316\n",
      "[196]\teval-mae:0.035808\ttrain-mae:0.035308\n",
      "[197]\teval-mae:0.035802\ttrain-mae:0.0353\n",
      "[198]\teval-mae:0.035798\ttrain-mae:0.035295\n",
      "[199]\teval-mae:0.035791\ttrain-mae:0.035287\n",
      "[200]\teval-mae:0.035784\ttrain-mae:0.035279\n",
      "[201]\teval-mae:0.035781\ttrain-mae:0.035274\n",
      "[202]\teval-mae:0.035778\ttrain-mae:0.03527\n",
      "[203]\teval-mae:0.035772\ttrain-mae:0.035261\n",
      "[204]\teval-mae:0.035767\ttrain-mae:0.035253\n",
      "[205]\teval-mae:0.035765\ttrain-mae:0.03525\n",
      "[206]\teval-mae:0.035759\ttrain-mae:0.035242\n",
      "[207]\teval-mae:0.035753\ttrain-mae:0.035235\n",
      "[208]\teval-mae:0.035748\ttrain-mae:0.035229\n",
      "[209]\teval-mae:0.035743\ttrain-mae:0.035222\n",
      "[210]\teval-mae:0.03574\ttrain-mae:0.035218\n",
      "[211]\teval-mae:0.035738\ttrain-mae:0.035214\n",
      "[212]\teval-mae:0.035734\ttrain-mae:0.035209\n",
      "[213]\teval-mae:0.035732\ttrain-mae:0.035204\n",
      "[214]\teval-mae:0.035727\ttrain-mae:0.035198\n",
      "[215]\teval-mae:0.035723\ttrain-mae:0.035192\n",
      "[216]\teval-mae:0.035718\ttrain-mae:0.035185\n",
      "[217]\teval-mae:0.035714\ttrain-mae:0.035178\n",
      "[218]\teval-mae:0.035711\ttrain-mae:0.035174\n",
      "[219]\teval-mae:0.035709\ttrain-mae:0.03517\n",
      "[220]\teval-mae:0.035706\ttrain-mae:0.035165\n",
      "[221]\teval-mae:0.035702\ttrain-mae:0.035158\n",
      "[222]\teval-mae:0.0357\ttrain-mae:0.035154\n",
      "[223]\teval-mae:0.035696\ttrain-mae:0.035149\n",
      "[224]\teval-mae:0.035693\ttrain-mae:0.035145\n",
      "[225]\teval-mae:0.035685\ttrain-mae:0.035137\n",
      "[226]\teval-mae:0.035683\ttrain-mae:0.035133\n",
      "[227]\teval-mae:0.035681\ttrain-mae:0.035129\n",
      "[228]\teval-mae:0.035674\ttrain-mae:0.035121\n",
      "[229]\teval-mae:0.035671\ttrain-mae:0.035118\n",
      "[230]\teval-mae:0.035667\ttrain-mae:0.035113\n",
      "[231]\teval-mae:0.03566\ttrain-mae:0.035105\n",
      "[232]\teval-mae:0.035656\ttrain-mae:0.035099\n",
      "[233]\teval-mae:0.035653\ttrain-mae:0.035093\n",
      "[234]\teval-mae:0.035647\ttrain-mae:0.035087\n",
      "[235]\teval-mae:0.035645\ttrain-mae:0.035084\n",
      "[236]\teval-mae:0.035642\ttrain-mae:0.035079\n",
      "[237]\teval-mae:0.035641\ttrain-mae:0.035076\n",
      "[238]\teval-mae:0.035637\ttrain-mae:0.035071\n",
      "[239]\teval-mae:0.035634\ttrain-mae:0.035067\n",
      "[240]\teval-mae:0.03563\ttrain-mae:0.03506\n",
      "[241]\teval-mae:0.035626\ttrain-mae:0.035056\n",
      "[242]\teval-mae:0.035623\ttrain-mae:0.035052\n",
      "[243]\teval-mae:0.035621\ttrain-mae:0.035049\n",
      "[244]\teval-mae:0.035619\ttrain-mae:0.035046\n",
      "[245]\teval-mae:0.035616\ttrain-mae:0.035041\n",
      "[246]\teval-mae:0.035613\ttrain-mae:0.035036\n",
      "[247]\teval-mae:0.035611\ttrain-mae:0.035033\n",
      "[248]\teval-mae:0.035608\ttrain-mae:0.035028\n",
      "[249]\teval-mae:0.035605\ttrain-mae:0.035024\n",
      "[250]\teval-mae:0.035603\ttrain-mae:0.035021\n",
      "[251]\teval-mae:0.0356\ttrain-mae:0.035017\n",
      "[252]\teval-mae:0.035597\ttrain-mae:0.035012\n",
      "[253]\teval-mae:0.035594\ttrain-mae:0.035006\n",
      "[254]\teval-mae:0.035591\ttrain-mae:0.035004\n",
      "[255]\teval-mae:0.035588\ttrain-mae:0.034999\n",
      "[256]\teval-mae:0.035584\ttrain-mae:0.034993\n",
      "[257]\teval-mae:0.035583\ttrain-mae:0.034989\n",
      "[258]\teval-mae:0.035581\ttrain-mae:0.034985\n",
      "[259]\teval-mae:0.035579\ttrain-mae:0.034982\n",
      "[260]\teval-mae:0.035576\ttrain-mae:0.034979\n",
      "[261]\teval-mae:0.035572\ttrain-mae:0.034973\n",
      "[262]\teval-mae:0.03557\ttrain-mae:0.034969\n",
      "[263]\teval-mae:0.035567\ttrain-mae:0.034964\n",
      "[264]\teval-mae:0.035564\ttrain-mae:0.034959\n",
      "[265]\teval-mae:0.035562\ttrain-mae:0.034955\n",
      "[266]\teval-mae:0.035559\ttrain-mae:0.034951\n",
      "[267]\teval-mae:0.035557\ttrain-mae:0.034947\n",
      "[268]\teval-mae:0.035554\ttrain-mae:0.034942\n",
      "[269]\teval-mae:0.035552\ttrain-mae:0.034938\n",
      "[270]\teval-mae:0.035547\ttrain-mae:0.034931\n",
      "[271]\teval-mae:0.035544\ttrain-mae:0.034928\n",
      "[272]\teval-mae:0.035542\ttrain-mae:0.034924\n",
      "[273]\teval-mae:0.035539\ttrain-mae:0.03492\n",
      "[274]\teval-mae:0.035537\ttrain-mae:0.034916\n",
      "[275]\teval-mae:0.035534\ttrain-mae:0.034911\n",
      "[276]\teval-mae:0.035533\ttrain-mae:0.034908\n",
      "[277]\teval-mae:0.035532\ttrain-mae:0.034904\n",
      "[278]\teval-mae:0.03553\ttrain-mae:0.034902\n",
      "[279]\teval-mae:0.035526\ttrain-mae:0.034896\n",
      "[280]\teval-mae:0.035523\ttrain-mae:0.034892\n",
      "[281]\teval-mae:0.035522\ttrain-mae:0.03489\n",
      "[282]\teval-mae:0.035519\ttrain-mae:0.034884\n",
      "[283]\teval-mae:0.035516\ttrain-mae:0.034879\n",
      "[284]\teval-mae:0.035514\ttrain-mae:0.034876\n",
      "[285]\teval-mae:0.035511\ttrain-mae:0.034872\n",
      "[286]\teval-mae:0.03551\ttrain-mae:0.034869\n",
      "[287]\teval-mae:0.035507\ttrain-mae:0.034864\n",
      "[288]\teval-mae:0.035505\ttrain-mae:0.034861\n",
      "[289]\teval-mae:0.035503\ttrain-mae:0.034858\n",
      "[290]\teval-mae:0.035502\ttrain-mae:0.034855\n",
      "[291]\teval-mae:0.0355\ttrain-mae:0.03485\n",
      "[292]\teval-mae:0.035498\ttrain-mae:0.034848\n",
      "[293]\teval-mae:0.035494\ttrain-mae:0.034842\n",
      "[294]\teval-mae:0.035492\ttrain-mae:0.034838\n",
      "[295]\teval-mae:0.035491\ttrain-mae:0.034836\n",
      "[296]\teval-mae:0.035488\ttrain-mae:0.034832\n",
      "[297]\teval-mae:0.035486\ttrain-mae:0.034828\n",
      "[298]\teval-mae:0.035484\ttrain-mae:0.034825\n",
      "[299]\teval-mae:0.035481\ttrain-mae:0.034821\n",
      "[300]\teval-mae:0.03548\ttrain-mae:0.034819\n",
      "[301]\teval-mae:0.035477\ttrain-mae:0.034815\n",
      "[302]\teval-mae:0.035474\ttrain-mae:0.034811\n",
      "[303]\teval-mae:0.035471\ttrain-mae:0.034807\n",
      "[304]\teval-mae:0.03547\ttrain-mae:0.034805\n",
      "[305]\teval-mae:0.035468\ttrain-mae:0.034803\n",
      "[306]\teval-mae:0.035467\ttrain-mae:0.034799\n",
      "[307]\teval-mae:0.035464\ttrain-mae:0.034795\n",
      "[308]\teval-mae:0.035462\ttrain-mae:0.034792\n",
      "[309]\teval-mae:0.035461\ttrain-mae:0.034789\n",
      "[310]\teval-mae:0.035459\ttrain-mae:0.034786\n",
      "[311]\teval-mae:0.035457\ttrain-mae:0.034783\n",
      "[312]\teval-mae:0.035456\ttrain-mae:0.034779\n",
      "[313]\teval-mae:0.035453\ttrain-mae:0.034775\n",
      "[314]\teval-mae:0.035453\ttrain-mae:0.034773\n",
      "[315]\teval-mae:0.03545\ttrain-mae:0.034769\n",
      "[316]\teval-mae:0.03545\ttrain-mae:0.034767\n",
      "[317]\teval-mae:0.035448\ttrain-mae:0.034763\n",
      "[318]\teval-mae:0.035446\ttrain-mae:0.034759\n",
      "[319]\teval-mae:0.035443\ttrain-mae:0.034756\n",
      "[320]\teval-mae:0.03544\ttrain-mae:0.034753\n",
      "[321]\teval-mae:0.035438\ttrain-mae:0.034749\n",
      "[322]\teval-mae:0.035435\ttrain-mae:0.034745\n",
      "[323]\teval-mae:0.035433\ttrain-mae:0.03474\n",
      "[324]\teval-mae:0.035432\ttrain-mae:0.034736\n",
      "[325]\teval-mae:0.035431\ttrain-mae:0.034733\n",
      "[326]\teval-mae:0.03543\ttrain-mae:0.034732\n",
      "[327]\teval-mae:0.035428\ttrain-mae:0.034729\n",
      "[328]\teval-mae:0.035426\ttrain-mae:0.034725\n",
      "[329]\teval-mae:0.035425\ttrain-mae:0.034722\n",
      "[330]\teval-mae:0.035423\ttrain-mae:0.034718\n",
      "[331]\teval-mae:0.035422\ttrain-mae:0.034715\n",
      "[332]\teval-mae:0.035421\ttrain-mae:0.034712\n",
      "[333]\teval-mae:0.035418\ttrain-mae:0.03471\n",
      "[334]\teval-mae:0.035415\ttrain-mae:0.034705\n",
      "[335]\teval-mae:0.035414\ttrain-mae:0.034702\n",
      "[336]\teval-mae:0.035413\ttrain-mae:0.0347\n",
      "[337]\teval-mae:0.035412\ttrain-mae:0.034698\n",
      "[338]\teval-mae:0.035409\ttrain-mae:0.034692\n",
      "[339]\teval-mae:0.035408\ttrain-mae:0.034689\n",
      "[340]\teval-mae:0.035406\ttrain-mae:0.034688\n",
      "[341]\teval-mae:0.035405\ttrain-mae:0.034686\n",
      "[342]\teval-mae:0.035404\ttrain-mae:0.034684\n",
      "[343]\teval-mae:0.035403\ttrain-mae:0.034682\n",
      "[344]\teval-mae:0.035403\ttrain-mae:0.034678\n",
      "[345]\teval-mae:0.035401\ttrain-mae:0.034675\n",
      "[346]\teval-mae:0.0354\ttrain-mae:0.034673\n",
      "[347]\teval-mae:0.035398\ttrain-mae:0.034669\n",
      "[348]\teval-mae:0.035396\ttrain-mae:0.034666\n",
      "[349]\teval-mae:0.035396\ttrain-mae:0.034663\n",
      "[350]\teval-mae:0.035394\ttrain-mae:0.034659\n",
      "[351]\teval-mae:0.035392\ttrain-mae:0.034657\n",
      "[352]\teval-mae:0.035391\ttrain-mae:0.034655\n",
      "[353]\teval-mae:0.035389\ttrain-mae:0.03465\n",
      "[354]\teval-mae:0.035389\ttrain-mae:0.034647\n",
      "[355]\teval-mae:0.035387\ttrain-mae:0.034644\n",
      "[356]\teval-mae:0.035385\ttrain-mae:0.034641\n",
      "[357]\teval-mae:0.035384\ttrain-mae:0.034638\n",
      "[358]\teval-mae:0.035382\ttrain-mae:0.034636\n",
      "[359]\teval-mae:0.035381\ttrain-mae:0.034634\n",
      "[360]\teval-mae:0.03538\ttrain-mae:0.034632\n",
      "[361]\teval-mae:0.035379\ttrain-mae:0.03463\n",
      "[362]\teval-mae:0.035377\ttrain-mae:0.034627\n",
      "[363]\teval-mae:0.035376\ttrain-mae:0.034623\n",
      "[364]\teval-mae:0.035373\ttrain-mae:0.03462\n",
      "[365]\teval-mae:0.035373\ttrain-mae:0.034618\n",
      "[366]\teval-mae:0.035372\ttrain-mae:0.034616\n",
      "[367]\teval-mae:0.035369\ttrain-mae:0.034611\n",
      "[368]\teval-mae:0.035368\ttrain-mae:0.034608\n",
      "[369]\teval-mae:0.035366\ttrain-mae:0.034605\n",
      "[370]\teval-mae:0.035364\ttrain-mae:0.034603\n",
      "[371]\teval-mae:0.035362\ttrain-mae:0.034601\n",
      "[372]\teval-mae:0.035361\ttrain-mae:0.034598\n",
      "[373]\teval-mae:0.035357\ttrain-mae:0.034594\n",
      "[374]\teval-mae:0.035357\ttrain-mae:0.034591\n",
      "[375]\teval-mae:0.035356\ttrain-mae:0.034589\n",
      "[376]\teval-mae:0.035356\ttrain-mae:0.034587\n",
      "[377]\teval-mae:0.035354\ttrain-mae:0.034585\n",
      "[378]\teval-mae:0.035352\ttrain-mae:0.034582\n",
      "[379]\teval-mae:0.035352\ttrain-mae:0.03458\n",
      "[380]\teval-mae:0.03535\ttrain-mae:0.034578\n",
      "[381]\teval-mae:0.035349\ttrain-mae:0.034576\n",
      "[382]\teval-mae:0.035348\ttrain-mae:0.034573\n",
      "[383]\teval-mae:0.035346\ttrain-mae:0.034569\n",
      "[384]\teval-mae:0.035344\ttrain-mae:0.034564\n",
      "[385]\teval-mae:0.035343\ttrain-mae:0.034562\n",
      "[386]\teval-mae:0.035342\ttrain-mae:0.03456\n",
      "[387]\teval-mae:0.035342\ttrain-mae:0.034559\n",
      "[388]\teval-mae:0.035338\ttrain-mae:0.034554\n",
      "[389]\teval-mae:0.035336\ttrain-mae:0.03455\n",
      "[390]\teval-mae:0.035334\ttrain-mae:0.034546\n",
      "[391]\teval-mae:0.035332\ttrain-mae:0.034543\n",
      "[392]\teval-mae:0.035331\ttrain-mae:0.034541\n",
      "[393]\teval-mae:0.03533\ttrain-mae:0.034538\n",
      "[394]\teval-mae:0.035329\ttrain-mae:0.034536\n",
      "[395]\teval-mae:0.035328\ttrain-mae:0.034534\n",
      "[396]\teval-mae:0.035327\ttrain-mae:0.03453\n",
      "[397]\teval-mae:0.035327\ttrain-mae:0.034528\n",
      "[398]\teval-mae:0.035325\ttrain-mae:0.034525\n",
      "[399]\teval-mae:0.035322\ttrain-mae:0.034521\n",
      "[400]\teval-mae:0.035322\ttrain-mae:0.034519\n",
      "[401]\teval-mae:0.035322\ttrain-mae:0.034518\n",
      "[402]\teval-mae:0.03532\ttrain-mae:0.034514\n",
      "[403]\teval-mae:0.035318\ttrain-mae:0.03451\n",
      "[404]\teval-mae:0.035315\ttrain-mae:0.034507\n",
      "[405]\teval-mae:0.035314\ttrain-mae:0.034504\n",
      "[406]\teval-mae:0.035311\ttrain-mae:0.034499\n",
      "[407]\teval-mae:0.035309\ttrain-mae:0.034496\n",
      "[408]\teval-mae:0.035308\ttrain-mae:0.034494\n",
      "[409]\teval-mae:0.035308\ttrain-mae:0.034493\n",
      "[410]\teval-mae:0.035306\ttrain-mae:0.03449\n",
      "[411]\teval-mae:0.035305\ttrain-mae:0.034486\n",
      "[412]\teval-mae:0.035303\ttrain-mae:0.034481\n",
      "[413]\teval-mae:0.035302\ttrain-mae:0.034479\n",
      "[414]\teval-mae:0.0353\ttrain-mae:0.034476\n",
      "[415]\teval-mae:0.035299\ttrain-mae:0.034472\n",
      "[416]\teval-mae:0.035298\ttrain-mae:0.034471\n",
      "[417]\teval-mae:0.035297\ttrain-mae:0.034469\n",
      "[418]\teval-mae:0.035297\ttrain-mae:0.034467\n",
      "[419]\teval-mae:0.035295\ttrain-mae:0.034464\n",
      "[420]\teval-mae:0.035295\ttrain-mae:0.034461\n",
      "[421]\teval-mae:0.035294\ttrain-mae:0.03446\n",
      "[422]\teval-mae:0.035293\ttrain-mae:0.034455\n",
      "[423]\teval-mae:0.035293\ttrain-mae:0.034454\n",
      "[424]\teval-mae:0.03529\ttrain-mae:0.034451\n",
      "[425]\teval-mae:0.03529\ttrain-mae:0.034449\n",
      "[426]\teval-mae:0.035289\ttrain-mae:0.034448\n",
      "[427]\teval-mae:0.035288\ttrain-mae:0.034445\n",
      "[428]\teval-mae:0.035286\ttrain-mae:0.034442\n",
      "[429]\teval-mae:0.035286\ttrain-mae:0.034441\n",
      "[430]\teval-mae:0.035285\ttrain-mae:0.034438\n",
      "[431]\teval-mae:0.035284\ttrain-mae:0.034436\n",
      "[432]\teval-mae:0.035283\ttrain-mae:0.034432\n",
      "[433]\teval-mae:0.035281\ttrain-mae:0.034429\n",
      "[434]\teval-mae:0.035281\ttrain-mae:0.034428\n",
      "[435]\teval-mae:0.035279\ttrain-mae:0.034424\n",
      "[436]\teval-mae:0.035277\ttrain-mae:0.03442\n",
      "[437]\teval-mae:0.035277\ttrain-mae:0.034418\n",
      "[438]\teval-mae:0.035274\ttrain-mae:0.034415\n",
      "[439]\teval-mae:0.035273\ttrain-mae:0.034412\n",
      "[440]\teval-mae:0.035272\ttrain-mae:0.03441\n",
      "[441]\teval-mae:0.035272\ttrain-mae:0.034407\n",
      "[442]\teval-mae:0.035272\ttrain-mae:0.034405\n",
      "[443]\teval-mae:0.035271\ttrain-mae:0.034402\n",
      "[444]\teval-mae:0.03527\ttrain-mae:0.034399\n",
      "[445]\teval-mae:0.035269\ttrain-mae:0.034397\n",
      "[446]\teval-mae:0.035268\ttrain-mae:0.034395\n",
      "[447]\teval-mae:0.035267\ttrain-mae:0.034393\n",
      "[448]\teval-mae:0.035267\ttrain-mae:0.034392\n",
      "[449]\teval-mae:0.035267\ttrain-mae:0.034389\n",
      "[450]\teval-mae:0.035266\ttrain-mae:0.034387\n",
      "[451]\teval-mae:0.035264\ttrain-mae:0.034384\n",
      "[452]\teval-mae:0.035264\ttrain-mae:0.034382\n",
      "[453]\teval-mae:0.035263\ttrain-mae:0.034379\n",
      "[454]\teval-mae:0.035262\ttrain-mae:0.034377\n",
      "[455]\teval-mae:0.035262\ttrain-mae:0.034375\n",
      "[456]\teval-mae:0.035261\ttrain-mae:0.034373\n",
      "[457]\teval-mae:0.035259\ttrain-mae:0.034371\n",
      "[458]\teval-mae:0.035257\ttrain-mae:0.034369\n",
      "[459]\teval-mae:0.035255\ttrain-mae:0.034364\n",
      "[460]\teval-mae:0.035255\ttrain-mae:0.034361\n",
      "[461]\teval-mae:0.035254\ttrain-mae:0.034359\n",
      "[462]\teval-mae:0.035253\ttrain-mae:0.034357\n",
      "[463]\teval-mae:0.035253\ttrain-mae:0.034355\n",
      "[464]\teval-mae:0.035251\ttrain-mae:0.034352\n",
      "[465]\teval-mae:0.035249\ttrain-mae:0.034348\n",
      "[466]\teval-mae:0.035248\ttrain-mae:0.034347\n",
      "[467]\teval-mae:0.035247\ttrain-mae:0.034344\n",
      "[468]\teval-mae:0.035246\ttrain-mae:0.034342\n",
      "[469]\teval-mae:0.035245\ttrain-mae:0.03434\n",
      "[470]\teval-mae:0.035243\ttrain-mae:0.034337\n",
      "[471]\teval-mae:0.035241\ttrain-mae:0.034334\n",
      "[472]\teval-mae:0.03524\ttrain-mae:0.034332\n",
      "[473]\teval-mae:0.03524\ttrain-mae:0.034331\n",
      "[474]\teval-mae:0.035239\ttrain-mae:0.034329\n",
      "[475]\teval-mae:0.035238\ttrain-mae:0.034328\n",
      "[476]\teval-mae:0.035238\ttrain-mae:0.034326\n",
      "[477]\teval-mae:0.035237\ttrain-mae:0.034323\n",
      "[478]\teval-mae:0.035235\ttrain-mae:0.034319\n",
      "[479]\teval-mae:0.035235\ttrain-mae:0.034318\n",
      "[480]\teval-mae:0.035234\ttrain-mae:0.034315\n",
      "[481]\teval-mae:0.035233\ttrain-mae:0.034313\n",
      "[482]\teval-mae:0.035232\ttrain-mae:0.03431\n",
      "[483]\teval-mae:0.035231\ttrain-mae:0.034307\n",
      "[484]\teval-mae:0.03523\ttrain-mae:0.034303\n",
      "[485]\teval-mae:0.035229\ttrain-mae:0.034301\n",
      "[486]\teval-mae:0.035229\ttrain-mae:0.034299\n",
      "[487]\teval-mae:0.035229\ttrain-mae:0.034298\n",
      "[488]\teval-mae:0.035228\ttrain-mae:0.034295\n",
      "[489]\teval-mae:0.035228\ttrain-mae:0.034294\n",
      "[490]\teval-mae:0.035227\ttrain-mae:0.034292\n",
      "[491]\teval-mae:0.035226\ttrain-mae:0.034291\n",
      "[492]\teval-mae:0.035226\ttrain-mae:0.034289\n",
      "[493]\teval-mae:0.035224\ttrain-mae:0.034286\n",
      "[494]\teval-mae:0.035222\ttrain-mae:0.034282\n",
      "[495]\teval-mae:0.035222\ttrain-mae:0.03428\n",
      "[496]\teval-mae:0.035222\ttrain-mae:0.034279\n",
      "[497]\teval-mae:0.035221\ttrain-mae:0.034277\n",
      "[498]\teval-mae:0.03522\ttrain-mae:0.034274\n",
      "[499]\teval-mae:0.035219\ttrain-mae:0.034272\n",
      "[500]\teval-mae:0.035219\ttrain-mae:0.03427\n",
      "[501]\teval-mae:0.035218\ttrain-mae:0.034269\n",
      "[502]\teval-mae:0.035216\ttrain-mae:0.034265\n",
      "[503]\teval-mae:0.035215\ttrain-mae:0.034262\n",
      "[504]\teval-mae:0.035214\ttrain-mae:0.034259\n",
      "[505]\teval-mae:0.035213\ttrain-mae:0.034256\n",
      "[506]\teval-mae:0.035213\ttrain-mae:0.034254\n",
      "[507]\teval-mae:0.035213\ttrain-mae:0.034252\n",
      "[508]\teval-mae:0.035212\ttrain-mae:0.03425\n",
      "[509]\teval-mae:0.035212\ttrain-mae:0.034249\n",
      "[510]\teval-mae:0.035211\ttrain-mae:0.034248\n",
      "[511]\teval-mae:0.035211\ttrain-mae:0.034246\n",
      "[512]\teval-mae:0.03521\ttrain-mae:0.034243\n",
      "[513]\teval-mae:0.035209\ttrain-mae:0.034242\n",
      "[514]\teval-mae:0.035208\ttrain-mae:0.03424\n",
      "[515]\teval-mae:0.035207\ttrain-mae:0.034237\n",
      "[516]\teval-mae:0.035207\ttrain-mae:0.034235\n",
      "[517]\teval-mae:0.035207\ttrain-mae:0.034233\n",
      "[518]\teval-mae:0.035205\ttrain-mae:0.03423\n",
      "[519]\teval-mae:0.035205\ttrain-mae:0.034229\n",
      "[520]\teval-mae:0.035204\ttrain-mae:0.034227\n",
      "[521]\teval-mae:0.035204\ttrain-mae:0.034224\n",
      "[522]\teval-mae:0.035203\ttrain-mae:0.034222\n",
      "[523]\teval-mae:0.035203\ttrain-mae:0.03422\n",
      "[524]\teval-mae:0.035203\ttrain-mae:0.034219\n",
      "[525]\teval-mae:0.035202\ttrain-mae:0.034217\n",
      "[526]\teval-mae:0.035202\ttrain-mae:0.034215\n",
      "[527]\teval-mae:0.035201\ttrain-mae:0.034214\n",
      "[528]\teval-mae:0.0352\ttrain-mae:0.034211\n",
      "[529]\teval-mae:0.0352\ttrain-mae:0.034209\n",
      "[530]\teval-mae:0.035198\ttrain-mae:0.034206\n",
      "[531]\teval-mae:0.035197\ttrain-mae:0.034203\n",
      "[532]\teval-mae:0.035195\ttrain-mae:0.034198\n",
      "[533]\teval-mae:0.035195\ttrain-mae:0.034196\n",
      "[534]\teval-mae:0.035195\ttrain-mae:0.034195\n",
      "[535]\teval-mae:0.035195\ttrain-mae:0.034192\n",
      "[536]\teval-mae:0.035194\ttrain-mae:0.034191\n",
      "[537]\teval-mae:0.035193\ttrain-mae:0.034188\n",
      "[538]\teval-mae:0.035192\ttrain-mae:0.034187\n",
      "[539]\teval-mae:0.035192\ttrain-mae:0.034186\n",
      "[540]\teval-mae:0.035191\ttrain-mae:0.034183\n",
      "[541]\teval-mae:0.03519\ttrain-mae:0.03418\n",
      "[542]\teval-mae:0.03519\ttrain-mae:0.034177\n",
      "[543]\teval-mae:0.035189\ttrain-mae:0.034174\n",
      "[544]\teval-mae:0.035187\ttrain-mae:0.034171\n",
      "[545]\teval-mae:0.035187\ttrain-mae:0.034169\n",
      "[546]\teval-mae:0.035187\ttrain-mae:0.034167\n",
      "[547]\teval-mae:0.035186\ttrain-mae:0.034166\n",
      "[548]\teval-mae:0.035186\ttrain-mae:0.034163\n",
      "[549]\teval-mae:0.035184\ttrain-mae:0.03416\n",
      "[550]\teval-mae:0.035183\ttrain-mae:0.034157\n",
      "[551]\teval-mae:0.035182\ttrain-mae:0.034155\n",
      "[552]\teval-mae:0.035181\ttrain-mae:0.034154\n",
      "[553]\teval-mae:0.035181\ttrain-mae:0.034152\n",
      "[554]\teval-mae:0.03518\ttrain-mae:0.034151\n",
      "[555]\teval-mae:0.035178\ttrain-mae:0.034147\n",
      "[556]\teval-mae:0.035176\ttrain-mae:0.034144\n",
      "[557]\teval-mae:0.035176\ttrain-mae:0.034142\n",
      "[558]\teval-mae:0.035175\ttrain-mae:0.034139\n",
      "[559]\teval-mae:0.035175\ttrain-mae:0.034137\n",
      "[560]\teval-mae:0.035174\ttrain-mae:0.034136\n",
      "[561]\teval-mae:0.035174\ttrain-mae:0.034134\n",
      "[562]\teval-mae:0.035173\ttrain-mae:0.034132\n",
      "[563]\teval-mae:0.035172\ttrain-mae:0.034129\n",
      "[564]\teval-mae:0.035172\ttrain-mae:0.034127\n",
      "[565]\teval-mae:0.035172\ttrain-mae:0.034126\n",
      "[566]\teval-mae:0.035171\ttrain-mae:0.034124\n",
      "[567]\teval-mae:0.035171\ttrain-mae:0.034121\n",
      "[568]\teval-mae:0.03517\ttrain-mae:0.034118\n",
      "[569]\teval-mae:0.03517\ttrain-mae:0.034117\n",
      "[570]\teval-mae:0.03517\ttrain-mae:0.034114\n",
      "[571]\teval-mae:0.035169\ttrain-mae:0.034112\n",
      "[572]\teval-mae:0.035168\ttrain-mae:0.034108\n",
      "[573]\teval-mae:0.035167\ttrain-mae:0.034106\n",
      "[574]\teval-mae:0.035167\ttrain-mae:0.034103\n",
      "[575]\teval-mae:0.035166\ttrain-mae:0.034101\n",
      "[576]\teval-mae:0.035165\ttrain-mae:0.034099\n",
      "[577]\teval-mae:0.035164\ttrain-mae:0.034096\n",
      "[578]\teval-mae:0.035163\ttrain-mae:0.034093\n",
      "[579]\teval-mae:0.035162\ttrain-mae:0.03409\n",
      "[580]\teval-mae:0.035162\ttrain-mae:0.034088\n",
      "[581]\teval-mae:0.035161\ttrain-mae:0.034086\n",
      "[582]\teval-mae:0.035161\ttrain-mae:0.034083\n",
      "[583]\teval-mae:0.035161\ttrain-mae:0.034083\n",
      "[584]\teval-mae:0.03516\ttrain-mae:0.03408\n",
      "[585]\teval-mae:0.03516\ttrain-mae:0.034078\n",
      "[586]\teval-mae:0.035159\ttrain-mae:0.034075\n",
      "[587]\teval-mae:0.035158\ttrain-mae:0.034073\n",
      "[588]\teval-mae:0.035158\ttrain-mae:0.03407\n",
      "[589]\teval-mae:0.035157\ttrain-mae:0.034068\n",
      "[590]\teval-mae:0.035157\ttrain-mae:0.034067\n",
      "[591]\teval-mae:0.035157\ttrain-mae:0.034066\n",
      "[592]\teval-mae:0.035157\ttrain-mae:0.034062\n",
      "[593]\teval-mae:0.035157\ttrain-mae:0.034061\n",
      "[594]\teval-mae:0.035156\ttrain-mae:0.034058\n",
      "[595]\teval-mae:0.035154\ttrain-mae:0.034055\n",
      "[596]\teval-mae:0.035154\ttrain-mae:0.034054\n",
      "[597]\teval-mae:0.035153\ttrain-mae:0.034052\n",
      "[598]\teval-mae:0.035152\ttrain-mae:0.03405\n",
      "[599]\teval-mae:0.035152\ttrain-mae:0.034048\n",
      "[600]\teval-mae:0.035152\ttrain-mae:0.034047\n",
      "[601]\teval-mae:0.03515\ttrain-mae:0.034043\n",
      "[602]\teval-mae:0.035149\ttrain-mae:0.03404\n",
      "[603]\teval-mae:0.035147\ttrain-mae:0.034036\n",
      "[604]\teval-mae:0.035146\ttrain-mae:0.034033\n",
      "[605]\teval-mae:0.035145\ttrain-mae:0.034029\n",
      "[606]\teval-mae:0.035145\ttrain-mae:0.034028\n",
      "[607]\teval-mae:0.035144\ttrain-mae:0.034025\n",
      "[608]\teval-mae:0.035144\ttrain-mae:0.034024\n",
      "[609]\teval-mae:0.035143\ttrain-mae:0.034022\n",
      "[610]\teval-mae:0.035142\ttrain-mae:0.034018\n",
      "[611]\teval-mae:0.035141\ttrain-mae:0.034017\n",
      "[612]\teval-mae:0.035141\ttrain-mae:0.034015\n",
      "[613]\teval-mae:0.035141\ttrain-mae:0.034013\n",
      "[614]\teval-mae:0.03514\ttrain-mae:0.034012\n",
      "[615]\teval-mae:0.03514\ttrain-mae:0.03401\n",
      "[616]\teval-mae:0.035141\ttrain-mae:0.034008\n",
      "[617]\teval-mae:0.03514\ttrain-mae:0.034006\n",
      "[618]\teval-mae:0.03514\ttrain-mae:0.034004\n",
      "[619]\teval-mae:0.03514\ttrain-mae:0.034002\n",
      "[620]\teval-mae:0.03514\ttrain-mae:0.034\n",
      "[621]\teval-mae:0.035139\ttrain-mae:0.033998\n",
      "[622]\teval-mae:0.035138\ttrain-mae:0.033996\n",
      "[623]\teval-mae:0.035137\ttrain-mae:0.033993\n",
      "[624]\teval-mae:0.035138\ttrain-mae:0.03399\n",
      "[625]\teval-mae:0.035137\ttrain-mae:0.033988\n",
      "[626]\teval-mae:0.035136\ttrain-mae:0.033986\n",
      "[627]\teval-mae:0.035135\ttrain-mae:0.033982\n",
      "[628]\teval-mae:0.035134\ttrain-mae:0.03398\n",
      "[629]\teval-mae:0.035133\ttrain-mae:0.033979\n",
      "[630]\teval-mae:0.035133\ttrain-mae:0.033978\n",
      "[631]\teval-mae:0.035133\ttrain-mae:0.033976\n",
      "[632]\teval-mae:0.035131\ttrain-mae:0.033973\n",
      "[633]\teval-mae:0.035131\ttrain-mae:0.033972\n",
      "[634]\teval-mae:0.035131\ttrain-mae:0.03397\n",
      "[635]\teval-mae:0.03513\ttrain-mae:0.033967\n",
      "[636]\teval-mae:0.03513\ttrain-mae:0.033965\n",
      "[637]\teval-mae:0.03513\ttrain-mae:0.033964\n",
      "[638]\teval-mae:0.03513\ttrain-mae:0.033962\n",
      "[639]\teval-mae:0.035129\ttrain-mae:0.033961\n",
      "[640]\teval-mae:0.035129\ttrain-mae:0.033959\n",
      "[641]\teval-mae:0.035128\ttrain-mae:0.033957\n",
      "[642]\teval-mae:0.035127\ttrain-mae:0.033954\n",
      "[643]\teval-mae:0.035127\ttrain-mae:0.033953\n",
      "[644]\teval-mae:0.035125\ttrain-mae:0.03395\n",
      "[645]\teval-mae:0.035124\ttrain-mae:0.033947\n",
      "[646]\teval-mae:0.035123\ttrain-mae:0.033944\n",
      "[647]\teval-mae:0.035124\ttrain-mae:0.033942\n",
      "[648]\teval-mae:0.035122\ttrain-mae:0.033938\n",
      "[649]\teval-mae:0.035122\ttrain-mae:0.033936\n",
      "[650]\teval-mae:0.035121\ttrain-mae:0.033934\n",
      "[651]\teval-mae:0.03512\ttrain-mae:0.033931\n",
      "[652]\teval-mae:0.03512\ttrain-mae:0.03393\n",
      "[653]\teval-mae:0.035119\ttrain-mae:0.033927\n",
      "[654]\teval-mae:0.035119\ttrain-mae:0.033924\n",
      "[655]\teval-mae:0.035118\ttrain-mae:0.033923\n",
      "[656]\teval-mae:0.035117\ttrain-mae:0.033921\n",
      "[657]\teval-mae:0.035117\ttrain-mae:0.033919\n",
      "[658]\teval-mae:0.035116\ttrain-mae:0.033917\n",
      "[659]\teval-mae:0.035116\ttrain-mae:0.033915\n",
      "[660]\teval-mae:0.035116\ttrain-mae:0.033912\n",
      "[661]\teval-mae:0.035116\ttrain-mae:0.03391\n",
      "[662]\teval-mae:0.035115\ttrain-mae:0.033907\n",
      "[663]\teval-mae:0.035114\ttrain-mae:0.033905\n",
      "[664]\teval-mae:0.035114\ttrain-mae:0.033902\n",
      "[665]\teval-mae:0.035113\ttrain-mae:0.0339\n",
      "[666]\teval-mae:0.035113\ttrain-mae:0.033899\n",
      "[667]\teval-mae:0.035112\ttrain-mae:0.033897\n",
      "[668]\teval-mae:0.035112\ttrain-mae:0.033894\n",
      "[669]\teval-mae:0.035111\ttrain-mae:0.033891\n",
      "[670]\teval-mae:0.035111\ttrain-mae:0.033889\n",
      "[671]\teval-mae:0.03511\ttrain-mae:0.033887\n",
      "[672]\teval-mae:0.03511\ttrain-mae:0.033886\n",
      "[673]\teval-mae:0.03511\ttrain-mae:0.033883\n",
      "[674]\teval-mae:0.035108\ttrain-mae:0.03388\n",
      "[675]\teval-mae:0.035107\ttrain-mae:0.033878\n",
      "[676]\teval-mae:0.035107\ttrain-mae:0.033877\n",
      "[677]\teval-mae:0.035106\ttrain-mae:0.033874\n",
      "[678]\teval-mae:0.035105\ttrain-mae:0.033871\n",
      "[679]\teval-mae:0.035105\ttrain-mae:0.03387\n",
      "[680]\teval-mae:0.035105\ttrain-mae:0.033869\n",
      "[681]\teval-mae:0.035105\ttrain-mae:0.033868\n",
      "[682]\teval-mae:0.035105\ttrain-mae:0.033867\n",
      "[683]\teval-mae:0.035104\ttrain-mae:0.033864\n",
      "[684]\teval-mae:0.035104\ttrain-mae:0.033862\n",
      "[685]\teval-mae:0.035104\ttrain-mae:0.033861\n",
      "[686]\teval-mae:0.035104\ttrain-mae:0.033859\n",
      "[687]\teval-mae:0.035103\ttrain-mae:0.033858\n",
      "[688]\teval-mae:0.035103\ttrain-mae:0.033856\n",
      "[689]\teval-mae:0.035103\ttrain-mae:0.033855\n",
      "[690]\teval-mae:0.035103\ttrain-mae:0.033853\n",
      "[691]\teval-mae:0.035103\ttrain-mae:0.033851\n",
      "[692]\teval-mae:0.035103\ttrain-mae:0.033848\n",
      "[693]\teval-mae:0.035102\ttrain-mae:0.033845\n",
      "[694]\teval-mae:0.035102\ttrain-mae:0.033843\n",
      "[695]\teval-mae:0.0351\ttrain-mae:0.03384\n",
      "[696]\teval-mae:0.0351\ttrain-mae:0.033839\n",
      "[697]\teval-mae:0.035099\ttrain-mae:0.033835\n",
      "[698]\teval-mae:0.035098\ttrain-mae:0.033832\n",
      "[699]\teval-mae:0.035098\ttrain-mae:0.03383\n",
      "[700]\teval-mae:0.035097\ttrain-mae:0.033827\n",
      "[701]\teval-mae:0.035096\ttrain-mae:0.033825\n",
      "[702]\teval-mae:0.035096\ttrain-mae:0.033823\n",
      "[703]\teval-mae:0.035095\ttrain-mae:0.033821\n",
      "[704]\teval-mae:0.035094\ttrain-mae:0.03382\n",
      "[705]\teval-mae:0.035094\ttrain-mae:0.033817\n",
      "[706]\teval-mae:0.035094\ttrain-mae:0.033815\n",
      "[707]\teval-mae:0.035094\ttrain-mae:0.033812\n",
      "[708]\teval-mae:0.035094\ttrain-mae:0.03381\n",
      "[709]\teval-mae:0.035093\ttrain-mae:0.033808\n",
      "[710]\teval-mae:0.035093\ttrain-mae:0.033807\n",
      "[711]\teval-mae:0.035093\ttrain-mae:0.033806\n",
      "[712]\teval-mae:0.035092\ttrain-mae:0.033804\n",
      "[713]\teval-mae:0.035092\ttrain-mae:0.033801\n",
      "[714]\teval-mae:0.035091\ttrain-mae:0.0338\n",
      "[715]\teval-mae:0.035091\ttrain-mae:0.033799\n",
      "[716]\teval-mae:0.035091\ttrain-mae:0.033797\n",
      "[717]\teval-mae:0.03509\ttrain-mae:0.033794\n",
      "[718]\teval-mae:0.03509\ttrain-mae:0.033791\n",
      "[719]\teval-mae:0.03509\ttrain-mae:0.033789\n",
      "[720]\teval-mae:0.035089\ttrain-mae:0.033787\n",
      "[721]\teval-mae:0.035089\ttrain-mae:0.033786\n",
      "[722]\teval-mae:0.035088\ttrain-mae:0.033783\n",
      "[723]\teval-mae:0.035088\ttrain-mae:0.033781\n",
      "[724]\teval-mae:0.035088\ttrain-mae:0.033779\n",
      "[725]\teval-mae:0.035088\ttrain-mae:0.033778\n",
      "[726]\teval-mae:0.035087\ttrain-mae:0.033776\n",
      "[727]\teval-mae:0.035086\ttrain-mae:0.033775\n",
      "[728]\teval-mae:0.035085\ttrain-mae:0.033772\n",
      "[729]\teval-mae:0.035085\ttrain-mae:0.03377\n",
      "[730]\teval-mae:0.035084\ttrain-mae:0.033768\n",
      "[731]\teval-mae:0.035084\ttrain-mae:0.033766\n",
      "[732]\teval-mae:0.035084\ttrain-mae:0.033764\n",
      "[733]\teval-mae:0.035084\ttrain-mae:0.033762\n",
      "[734]\teval-mae:0.035083\ttrain-mae:0.03376\n",
      "[735]\teval-mae:0.035084\ttrain-mae:0.033758\n",
      "[736]\teval-mae:0.035084\ttrain-mae:0.033756\n",
      "[737]\teval-mae:0.035084\ttrain-mae:0.033753\n",
      "[738]\teval-mae:0.035083\ttrain-mae:0.033751\n",
      "[739]\teval-mae:0.035081\ttrain-mae:0.033748\n",
      "[740]\teval-mae:0.035082\ttrain-mae:0.033745\n",
      "[741]\teval-mae:0.035082\ttrain-mae:0.033744\n",
      "[742]\teval-mae:0.035082\ttrain-mae:0.033743\n",
      "[743]\teval-mae:0.035082\ttrain-mae:0.033741\n",
      "[744]\teval-mae:0.035081\ttrain-mae:0.033739\n",
      "[745]\teval-mae:0.03508\ttrain-mae:0.033737\n",
      "[746]\teval-mae:0.03508\ttrain-mae:0.033734\n",
      "[747]\teval-mae:0.03508\ttrain-mae:0.033732\n",
      "[748]\teval-mae:0.03508\ttrain-mae:0.033731\n",
      "[749]\teval-mae:0.03508\ttrain-mae:0.033729\n",
      "[750]\teval-mae:0.03508\ttrain-mae:0.033726\n",
      "[751]\teval-mae:0.035079\ttrain-mae:0.033724\n",
      "[752]\teval-mae:0.035079\ttrain-mae:0.033722\n",
      "[753]\teval-mae:0.035079\ttrain-mae:0.03372\n",
      "[754]\teval-mae:0.035078\ttrain-mae:0.033718\n",
      "[755]\teval-mae:0.035078\ttrain-mae:0.033716\n",
      "[756]\teval-mae:0.035078\ttrain-mae:0.033716\n",
      "[757]\teval-mae:0.035078\ttrain-mae:0.033713\n",
      "[758]\teval-mae:0.035078\ttrain-mae:0.033712\n",
      "[759]\teval-mae:0.035078\ttrain-mae:0.033711\n",
      "[760]\teval-mae:0.035076\ttrain-mae:0.033708\n",
      "[761]\teval-mae:0.035077\ttrain-mae:0.033705\n",
      "[762]\teval-mae:0.035076\ttrain-mae:0.033704\n",
      "[763]\teval-mae:0.035076\ttrain-mae:0.033702\n",
      "[764]\teval-mae:0.035076\ttrain-mae:0.033701\n",
      "[765]\teval-mae:0.035075\ttrain-mae:0.033699\n",
      "[766]\teval-mae:0.035075\ttrain-mae:0.033699\n",
      "[767]\teval-mae:0.035075\ttrain-mae:0.033697\n",
      "[768]\teval-mae:0.035075\ttrain-mae:0.033695\n",
      "[769]\teval-mae:0.035075\ttrain-mae:0.033693\n",
      "[770]\teval-mae:0.035075\ttrain-mae:0.03369\n",
      "[771]\teval-mae:0.035075\ttrain-mae:0.033688\n",
      "[772]\teval-mae:0.035074\ttrain-mae:0.033686\n",
      "[773]\teval-mae:0.035074\ttrain-mae:0.033683\n",
      "[774]\teval-mae:0.035074\ttrain-mae:0.033681\n",
      "[775]\teval-mae:0.035074\ttrain-mae:0.033678\n",
      "[776]\teval-mae:0.035073\ttrain-mae:0.033675\n",
      "[777]\teval-mae:0.035073\ttrain-mae:0.033672\n",
      "[778]\teval-mae:0.035073\ttrain-mae:0.03367\n",
      "[779]\teval-mae:0.035073\ttrain-mae:0.033668\n",
      "[780]\teval-mae:0.035073\ttrain-mae:0.033666\n",
      "[781]\teval-mae:0.035073\ttrain-mae:0.033664\n",
      "[782]\teval-mae:0.035073\ttrain-mae:0.033663\n",
      "[783]\teval-mae:0.035072\ttrain-mae:0.033662\n",
      "[784]\teval-mae:0.035071\ttrain-mae:0.03366\n",
      "[785]\teval-mae:0.03507\ttrain-mae:0.033658\n",
      "[786]\teval-mae:0.035069\ttrain-mae:0.033655\n",
      "[787]\teval-mae:0.035069\ttrain-mae:0.033653\n",
      "[788]\teval-mae:0.035068\ttrain-mae:0.033652\n",
      "[789]\teval-mae:0.035068\ttrain-mae:0.033649\n",
      "[790]\teval-mae:0.035068\ttrain-mae:0.033648\n",
      "[791]\teval-mae:0.035068\ttrain-mae:0.033647\n",
      "[792]\teval-mae:0.035067\ttrain-mae:0.033645\n",
      "[793]\teval-mae:0.035067\ttrain-mae:0.033642\n",
      "[794]\teval-mae:0.035067\ttrain-mae:0.03364\n",
      "[795]\teval-mae:0.035066\ttrain-mae:0.033638\n",
      "[796]\teval-mae:0.035066\ttrain-mae:0.033636\n",
      "[797]\teval-mae:0.035066\ttrain-mae:0.033635\n",
      "[798]\teval-mae:0.035066\ttrain-mae:0.033633\n",
      "[799]\teval-mae:0.035065\ttrain-mae:0.033631\n",
      "[800]\teval-mae:0.035065\ttrain-mae:0.033628\n",
      "[801]\teval-mae:0.035064\ttrain-mae:0.033627\n",
      "[802]\teval-mae:0.035064\ttrain-mae:0.033624\n",
      "[803]\teval-mae:0.035064\ttrain-mae:0.033622\n",
      "[804]\teval-mae:0.035062\ttrain-mae:0.03362\n",
      "[805]\teval-mae:0.035062\ttrain-mae:0.033618\n",
      "[806]\teval-mae:0.035062\ttrain-mae:0.033616\n",
      "[807]\teval-mae:0.035061\ttrain-mae:0.033614\n",
      "[808]\teval-mae:0.035061\ttrain-mae:0.033612\n",
      "[809]\teval-mae:0.035061\ttrain-mae:0.03361\n",
      "[810]\teval-mae:0.035062\ttrain-mae:0.033608\n",
      "[811]\teval-mae:0.035061\ttrain-mae:0.033606\n",
      "[812]\teval-mae:0.035061\ttrain-mae:0.033604\n",
      "[813]\teval-mae:0.035061\ttrain-mae:0.033601\n",
      "[814]\teval-mae:0.03506\ttrain-mae:0.033599\n",
      "[815]\teval-mae:0.03506\ttrain-mae:0.033597\n",
      "[816]\teval-mae:0.03506\ttrain-mae:0.033596\n",
      "[817]\teval-mae:0.03506\ttrain-mae:0.033594\n",
      "[818]\teval-mae:0.035059\ttrain-mae:0.033592\n",
      "[819]\teval-mae:0.035059\ttrain-mae:0.03359\n",
      "[820]\teval-mae:0.035059\ttrain-mae:0.033588\n",
      "[821]\teval-mae:0.035059\ttrain-mae:0.033586\n",
      "[822]\teval-mae:0.035058\ttrain-mae:0.033584\n",
      "[823]\teval-mae:0.035058\ttrain-mae:0.033582\n",
      "[824]\teval-mae:0.035058\ttrain-mae:0.033581\n",
      "[825]\teval-mae:0.035058\ttrain-mae:0.03358\n",
      "[826]\teval-mae:0.035058\ttrain-mae:0.033578\n",
      "[827]\teval-mae:0.035058\ttrain-mae:0.033575\n",
      "[828]\teval-mae:0.035058\ttrain-mae:0.033573\n",
      "[829]\teval-mae:0.035058\ttrain-mae:0.033571\n",
      "[830]\teval-mae:0.035057\ttrain-mae:0.033569\n",
      "[831]\teval-mae:0.035056\ttrain-mae:0.033566\n",
      "[832]\teval-mae:0.035056\ttrain-mae:0.033563\n",
      "[833]\teval-mae:0.035055\ttrain-mae:0.033559\n",
      "[834]\teval-mae:0.035055\ttrain-mae:0.033558\n",
      "[835]\teval-mae:0.035055\ttrain-mae:0.033556\n",
      "[836]\teval-mae:0.035054\ttrain-mae:0.033554\n",
      "[837]\teval-mae:0.035053\ttrain-mae:0.033551\n",
      "[838]\teval-mae:0.035052\ttrain-mae:0.033549\n",
      "[839]\teval-mae:0.035052\ttrain-mae:0.033547\n",
      "[840]\teval-mae:0.035052\ttrain-mae:0.033546\n",
      "[841]\teval-mae:0.03505\ttrain-mae:0.033543\n",
      "[842]\teval-mae:0.035049\ttrain-mae:0.03354\n",
      "[843]\teval-mae:0.035048\ttrain-mae:0.033538\n",
      "[844]\teval-mae:0.035047\ttrain-mae:0.033535\n",
      "[845]\teval-mae:0.035048\ttrain-mae:0.033532\n",
      "[846]\teval-mae:0.035047\ttrain-mae:0.03353\n",
      "[847]\teval-mae:0.035047\ttrain-mae:0.033527\n",
      "[848]\teval-mae:0.035046\ttrain-mae:0.033524\n",
      "[849]\teval-mae:0.035045\ttrain-mae:0.033522\n",
      "[850]\teval-mae:0.035045\ttrain-mae:0.03352\n",
      "[851]\teval-mae:0.035045\ttrain-mae:0.033519\n",
      "[852]\teval-mae:0.035045\ttrain-mae:0.033517\n",
      "[853]\teval-mae:0.035045\ttrain-mae:0.033516\n",
      "[854]\teval-mae:0.035045\ttrain-mae:0.033514\n",
      "[855]\teval-mae:0.035044\ttrain-mae:0.033512\n",
      "[856]\teval-mae:0.035045\ttrain-mae:0.033511\n",
      "[857]\teval-mae:0.035044\ttrain-mae:0.03351\n",
      "[858]\teval-mae:0.035044\ttrain-mae:0.033509\n",
      "[859]\teval-mae:0.035044\ttrain-mae:0.033506\n",
      "[860]\teval-mae:0.035044\ttrain-mae:0.033505\n",
      "[861]\teval-mae:0.035044\ttrain-mae:0.033503\n",
      "[862]\teval-mae:0.035044\ttrain-mae:0.033501\n",
      "[863]\teval-mae:0.035044\ttrain-mae:0.0335\n",
      "[864]\teval-mae:0.035043\ttrain-mae:0.033499\n",
      "[865]\teval-mae:0.035043\ttrain-mae:0.033496\n",
      "[866]\teval-mae:0.035043\ttrain-mae:0.033495\n",
      "[867]\teval-mae:0.035044\ttrain-mae:0.033494\n",
      "[868]\teval-mae:0.035043\ttrain-mae:0.033492\n",
      "[869]\teval-mae:0.035043\ttrain-mae:0.03349\n",
      "[870]\teval-mae:0.035043\ttrain-mae:0.033488\n",
      "[871]\teval-mae:0.035043\ttrain-mae:0.033486\n",
      "[872]\teval-mae:0.035042\ttrain-mae:0.033486\n",
      "[873]\teval-mae:0.035042\ttrain-mae:0.033483\n",
      "[874]\teval-mae:0.035042\ttrain-mae:0.033481\n",
      "[875]\teval-mae:0.035041\ttrain-mae:0.033479\n",
      "[876]\teval-mae:0.035041\ttrain-mae:0.033477\n",
      "[877]\teval-mae:0.035041\ttrain-mae:0.033476\n",
      "[878]\teval-mae:0.035041\ttrain-mae:0.033474\n",
      "[879]\teval-mae:0.035041\ttrain-mae:0.033473\n",
      "[880]\teval-mae:0.035041\ttrain-mae:0.033471\n",
      "[881]\teval-mae:0.035041\ttrain-mae:0.03347\n",
      "[882]\teval-mae:0.035041\ttrain-mae:0.033468\n",
      "[883]\teval-mae:0.035041\ttrain-mae:0.033466\n",
      "[884]\teval-mae:0.03504\ttrain-mae:0.033464\n",
      "[885]\teval-mae:0.03504\ttrain-mae:0.033463\n",
      "[886]\teval-mae:0.03504\ttrain-mae:0.033461\n",
      "[887]\teval-mae:0.03504\ttrain-mae:0.033458\n",
      "[888]\teval-mae:0.035039\ttrain-mae:0.033457\n",
      "[889]\teval-mae:0.03504\ttrain-mae:0.033455\n",
      "[890]\teval-mae:0.035039\ttrain-mae:0.033454\n",
      "[891]\teval-mae:0.035039\ttrain-mae:0.033451\n",
      "[892]\teval-mae:0.035039\ttrain-mae:0.033449\n",
      "[893]\teval-mae:0.035039\ttrain-mae:0.033447\n",
      "[894]\teval-mae:0.035038\ttrain-mae:0.033445\n",
      "[895]\teval-mae:0.035038\ttrain-mae:0.033443\n",
      "[896]\teval-mae:0.035038\ttrain-mae:0.033441\n",
      "[897]\teval-mae:0.035038\ttrain-mae:0.033438\n",
      "[898]\teval-mae:0.035038\ttrain-mae:0.033436\n",
      "[899]\teval-mae:0.035037\ttrain-mae:0.033434\n",
      "[900]\teval-mae:0.035037\ttrain-mae:0.033433\n",
      "[901]\teval-mae:0.035036\ttrain-mae:0.03343\n",
      "[902]\teval-mae:0.035036\ttrain-mae:0.033428\n",
      "[903]\teval-mae:0.035036\ttrain-mae:0.033426\n",
      "[904]\teval-mae:0.035036\ttrain-mae:0.033423\n",
      "[905]\teval-mae:0.035036\ttrain-mae:0.033422\n",
      "[906]\teval-mae:0.035036\ttrain-mae:0.03342\n",
      "[907]\teval-mae:0.035036\ttrain-mae:0.033419\n",
      "[908]\teval-mae:0.035035\ttrain-mae:0.033417\n",
      "[909]\teval-mae:0.035035\ttrain-mae:0.033415\n",
      "[910]\teval-mae:0.035034\ttrain-mae:0.033413\n",
      "[911]\teval-mae:0.035034\ttrain-mae:0.033412\n",
      "[912]\teval-mae:0.035034\ttrain-mae:0.03341\n",
      "[913]\teval-mae:0.035034\ttrain-mae:0.033407\n",
      "[914]\teval-mae:0.035033\ttrain-mae:0.033405\n",
      "[915]\teval-mae:0.035033\ttrain-mae:0.033403\n",
      "[916]\teval-mae:0.035032\ttrain-mae:0.033401\n",
      "[917]\teval-mae:0.035032\ttrain-mae:0.033399\n",
      "[918]\teval-mae:0.035032\ttrain-mae:0.033397\n",
      "[919]\teval-mae:0.035032\ttrain-mae:0.033394\n",
      "[920]\teval-mae:0.035031\ttrain-mae:0.033392\n",
      "[921]\teval-mae:0.035031\ttrain-mae:0.033389\n",
      "[922]\teval-mae:0.035031\ttrain-mae:0.033389\n",
      "[923]\teval-mae:0.035031\ttrain-mae:0.033386\n",
      "[924]\teval-mae:0.03503\ttrain-mae:0.033385\n",
      "[925]\teval-mae:0.03503\ttrain-mae:0.033384\n",
      "[926]\teval-mae:0.03503\ttrain-mae:0.033382\n",
      "[927]\teval-mae:0.03503\ttrain-mae:0.03338\n",
      "[928]\teval-mae:0.03503\ttrain-mae:0.033378\n",
      "[929]\teval-mae:0.03503\ttrain-mae:0.033376\n",
      "[930]\teval-mae:0.03503\ttrain-mae:0.033374\n",
      "[931]\teval-mae:0.03503\ttrain-mae:0.033373\n",
      "[932]\teval-mae:0.03503\ttrain-mae:0.033372\n",
      "[933]\teval-mae:0.03503\ttrain-mae:0.03337\n",
      "[934]\teval-mae:0.03503\ttrain-mae:0.033369\n",
      "[935]\teval-mae:0.03503\ttrain-mae:0.033367\n",
      "[936]\teval-mae:0.03503\ttrain-mae:0.033365\n",
      "[937]\teval-mae:0.035029\ttrain-mae:0.033363\n",
      "[938]\teval-mae:0.035029\ttrain-mae:0.033362\n",
      "[939]\teval-mae:0.035028\ttrain-mae:0.03336\n",
      "[940]\teval-mae:0.035029\ttrain-mae:0.033358\n",
      "[941]\teval-mae:0.035029\ttrain-mae:0.033356\n",
      "[942]\teval-mae:0.035029\ttrain-mae:0.033354\n",
      "[943]\teval-mae:0.035029\ttrain-mae:0.033353\n",
      "[944]\teval-mae:0.035029\ttrain-mae:0.033352\n",
      "[945]\teval-mae:0.035029\ttrain-mae:0.033349\n",
      "[946]\teval-mae:0.035029\ttrain-mae:0.033348\n",
      "[947]\teval-mae:0.035028\ttrain-mae:0.033346\n",
      "[948]\teval-mae:0.035028\ttrain-mae:0.033345\n",
      "[949]\teval-mae:0.035028\ttrain-mae:0.033343\n",
      "[950]\teval-mae:0.035027\ttrain-mae:0.033341\n",
      "[951]\teval-mae:0.035027\ttrain-mae:0.03334\n",
      "[952]\teval-mae:0.035027\ttrain-mae:0.033338\n",
      "[953]\teval-mae:0.035026\ttrain-mae:0.033336\n",
      "[954]\teval-mae:0.035026\ttrain-mae:0.033334\n",
      "[955]\teval-mae:0.035026\ttrain-mae:0.033333\n",
      "[956]\teval-mae:0.035026\ttrain-mae:0.033331\n",
      "[957]\teval-mae:0.035026\ttrain-mae:0.03333\n",
      "[958]\teval-mae:0.035025\ttrain-mae:0.033328\n",
      "[959]\teval-mae:0.035026\ttrain-mae:0.033327\n",
      "[960]\teval-mae:0.035025\ttrain-mae:0.033325\n",
      "[961]\teval-mae:0.035025\ttrain-mae:0.033324\n",
      "[962]\teval-mae:0.035025\ttrain-mae:0.033323\n",
      "[963]\teval-mae:0.035025\ttrain-mae:0.033322\n",
      "[964]\teval-mae:0.035026\ttrain-mae:0.03332\n",
      "[965]\teval-mae:0.035025\ttrain-mae:0.033319\n",
      "[966]\teval-mae:0.035026\ttrain-mae:0.033317\n",
      "[967]\teval-mae:0.035024\ttrain-mae:0.033313\n",
      "[968]\teval-mae:0.035024\ttrain-mae:0.033311\n",
      "[969]\teval-mae:0.035024\ttrain-mae:0.03331\n",
      "[970]\teval-mae:0.035024\ttrain-mae:0.033308\n",
      "[971]\teval-mae:0.035024\ttrain-mae:0.033307\n",
      "[972]\teval-mae:0.035024\ttrain-mae:0.033306\n",
      "[973]\teval-mae:0.035024\ttrain-mae:0.033303\n",
      "[974]\teval-mae:0.035024\ttrain-mae:0.033302\n",
      "[975]\teval-mae:0.035025\ttrain-mae:0.0333\n",
      "[976]\teval-mae:0.035024\ttrain-mae:0.033299\n",
      "[977]\teval-mae:0.035024\ttrain-mae:0.033297\n",
      "[978]\teval-mae:0.035025\ttrain-mae:0.033295\n",
      "[979]\teval-mae:0.035025\ttrain-mae:0.033294\n",
      "[980]\teval-mae:0.035025\ttrain-mae:0.033292\n",
      "[981]\teval-mae:0.035025\ttrain-mae:0.033291\n",
      "[982]\teval-mae:0.035024\ttrain-mae:0.033289\n",
      "[983]\teval-mae:0.035024\ttrain-mae:0.033287\n",
      "[984]\teval-mae:0.035024\ttrain-mae:0.033285\n",
      "[985]\teval-mae:0.035024\ttrain-mae:0.033284\n",
      "[986]\teval-mae:0.035023\ttrain-mae:0.033282\n",
      "[987]\teval-mae:0.035024\ttrain-mae:0.033281\n",
      "[988]\teval-mae:0.035023\ttrain-mae:0.033279\n",
      "[989]\teval-mae:0.035023\ttrain-mae:0.033276\n",
      "[990]\teval-mae:0.035023\ttrain-mae:0.033274\n",
      "[991]\teval-mae:0.035023\ttrain-mae:0.033272\n",
      "[992]\teval-mae:0.035023\ttrain-mae:0.03327\n",
      "[993]\teval-mae:0.035023\ttrain-mae:0.033268\n",
      "[994]\teval-mae:0.035022\ttrain-mae:0.033266\n",
      "[995]\teval-mae:0.035022\ttrain-mae:0.033264\n",
      "[996]\teval-mae:0.035022\ttrain-mae:0.033262\n",
      "[997]\teval-mae:0.035021\ttrain-mae:0.033261\n",
      "[998]\teval-mae:0.03502\ttrain-mae:0.033259\n",
      "[999]\teval-mae:0.03502\ttrain-mae:0.033257\n"
     ]
    }
   ],
   "source": [
    "num_round = 1000\n",
    "# params = {'eval_metric':'mae','max_depth':6,'colsample_bytree':1,'alpha':1,'gamma':1,'eta':0.155,'min_child_weight':1}# 1134, 200 rounds\n",
    "# params = {'eval_metric':'mae','max_depth':6,'colsample_bytree':1,'alpha':1,'gamma':1,'eta':0.15,'min_child_weight':1}# 1133, 250 rounds\n",
    "# params = {'eval_metric':'mae','max_depth':6,'colsample_bytree':1,'alpha':1,'gamma':0,'eta':0.1,'min_child_weight':1}# 1128, 600 rounds\n",
    "params = {'eval_metric':'mae','max_depth':6,'colsample_bytree':1,'alpha':1,'gamma':0,'eta':0.05,'min_child_weight':0}# 1127, 1000\n",
    "\n",
    "watchlist  = [(d_val_xgb,'eval'), (d_train_xgb,'train')]\n",
    "gbt = xgb.train(params, d_train_xgb,num_round,watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1127.45756915\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(gbt.predict(x_val_xgb),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(gbt.predict(d_test_xgb),ymean,ystd)\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(gbt.predict(x_val_xgb),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_estimators = [30, 60, 90, 120]\n",
    "# n_estimators = [10,20,30,40]\n",
    "n_estimators = [6]\n",
    "base_estimator = Ridge(alpha = 40)\n",
    "err = 999999999\n",
    "n_estimator = 0\n",
    "random_state = 0\n",
    "for n_est in n_estimators:\n",
    "    tmpAdReg = AdaBoostRegressor(n_estimators = n_est, random_state = random_state,base_estimator = base_estimator)\n",
    "#     tmpAdReg = AdaBoostRegressor(n_estimators = n_est, random_state = random_state)\n",
    "    tmpAdReg.fit(x_train,y_train)\n",
    "    err_i = mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(tmpAdReg.predict(x_val),ymean,ystd))\n",
    "    print(err_i)\n",
    "    if err_i < err:\n",
    "        AdReg = tmpAdReg\n",
    "        n_estimator = n_est\n",
    "        err = err_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('n_estimator = {}'.format(n_estimator))\n",
    "print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(AdReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(AdReg.predict(x_Test),ymean,ystd)\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(AdReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipped - K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_neighbors = [5, 10, 15]\n",
    "# weights = 'distance'\n",
    "# err = 999999999\n",
    "# n_nns = 0\n",
    "# # random_state = 0\n",
    "# for n_nn in n_neighbors:\n",
    "#     tmpKNReg = KNeighborsRegressor(n_neighbors = n_nn,weights = weights)\n",
    "#     tmpKNReg.fit(x_train,y_train)\n",
    "#     err_i = mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(tmpKNReg.predict(x_val),ymean,ystd))\n",
    "#     print(err_i)\n",
    "#     if err_i < err:\n",
    "#         KNReg = tmpKNReg\n",
    "#         n_nns = n_nn\n",
    "#         err = err_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('n_neighbors = {}'.format(n_nns))\n",
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(KNReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(KNReg.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(KNReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # SVReg = svm.SVR(kernel = 'rbf')\n",
    "# # SVReg.fit(x_train,y_train)\n",
    "# SVReg = LinearSVR(C=0.5)\n",
    "# SVReg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(SVReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(SVReg.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(SVReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLPReg = MLPRegressor(alpha = 1e-5, hidden_layer_sizes = (35,3),random_state=0,early_stopping=True)\n",
    "MLPReg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(MLPReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(MLPReg.predict(x_Test),ymean,ystd)\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(MLPReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save files for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ensemble the results\n",
    "y_pred.append(np.ndarray.mean(np.vstack(y_pred).T,axis=1))\n",
    "\n",
    "# ensembled y_val\n",
    "print('The loss of the ensembled result:')\n",
    "y_pred_val_en = np.ndarray.mean(np.vstack(y_pred_val).T,axis=1)\n",
    "mean_absolute_error(lossRestore(y_val,ymean,ystd),y_pred_val_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save all the predictions for submission\n",
    "for i,stri in enumerate(testList):\n",
    "    submission['id'] = subId\n",
    "    submission['loss']=pd.Series(data=y_pred[i])\n",
    "    submission.to_csv('../output/'+stri+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump([regCV, gbt, AdReg, MLPReg, y_pred, y_pred_val, x_train, x_val, y_train, y_val, x_Test]\n",
    "            ,'../output/models_data_on_raw_features.pkl',compress=3) \n",
    "\n",
    "# clf = joblib.load('filename.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
