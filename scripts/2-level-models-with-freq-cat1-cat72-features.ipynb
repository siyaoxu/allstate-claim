{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy as sp\n",
    "\n",
    "# from scipy.special import erfinv\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_raw = pd.read_csv('../input/clean-new-ft-train.csv')\n",
    "# data_train_raw = data_train_raw.sample(frac=0.01, random_state=0)\n",
    "data_test_raw = pd.read_csv('../input/clean-new-ft-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187954, 61)\n",
      "(125546, 60)\n"
     ]
    }
   ],
   "source": [
    "print(data_train_raw.shape)\n",
    "print(data_test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat72</th>\n",
       "      <th>cat73</th>\n",
       "      <th>cat74</th>\n",
       "      <th>cat75</th>\n",
       "      <th>cat76</th>\n",
       "      <th>cat77</th>\n",
       "      <th>cat78</th>\n",
       "      <th>cat79</th>\n",
       "      <th>cat80</th>\n",
       "      <th>cat81</th>\n",
       "      <th>...</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>cat1cat72_freq</th>\n",
       "      <th>loss_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>0.105084</td>\n",
       "      <td>7.702637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>0.063871</td>\n",
       "      <td>7.158203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>0.164987</td>\n",
       "      <td>8.008396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>0.105084</td>\n",
       "      <td>6.846784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>0.145266</td>\n",
       "      <td>7.924742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat72 cat73 cat74 cat75 cat76 cat77 cat78 cat79 cat80 cat81    ...     \\\n",
       "0     A     A     A     B     A     D     B     B     D     D    ...      \n",
       "1     A     A     A     A     A     D     B     B     D     D    ...      \n",
       "2     A     A     A     A     A     D     B     B     B     D    ...      \n",
       "3     A     B     A     A     A     D     B     B     D     D    ...      \n",
       "4     B     A     A     A     A     D     B     D     B     D    ...      \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "3  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "4  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "\n",
       "     cont14 cat1cat72_freq    loss_g  \n",
       "0  0.714843       0.105084  7.702637  \n",
       "1  0.304496       0.063871  7.158203  \n",
       "2  0.774425       0.164987  8.008396  \n",
       "3  0.602642       0.105084  6.846784  \n",
       "4  0.432606       0.145266  7.924742  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat72</th>\n",
       "      <th>cat73</th>\n",
       "      <th>cat74</th>\n",
       "      <th>cat75</th>\n",
       "      <th>cat76</th>\n",
       "      <th>cat77</th>\n",
       "      <th>cat78</th>\n",
       "      <th>cat79</th>\n",
       "      <th>cat80</th>\n",
       "      <th>cat81</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>cat1cat72_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466591</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.377724</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.392562</td>\n",
       "      <td>0.114231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.51890</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.689039</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>0.208045</td>\n",
       "      <td>0.187841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.297232</td>\n",
       "      <td>0.496757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369930</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.33237</td>\n",
       "      <td>0.31480</td>\n",
       "      <td>0.348867</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.555955</td>\n",
       "      <td>0.151282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398862</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>0.359572</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.825823</td>\n",
       "      <td>0.114231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat72 cat73 cat74 cat75 cat76 cat77 cat78 cat79 cat80 cat81      ...        \\\n",
       "0     A     A     A     A     A     D     B     B     D     D      ...         \n",
       "1     B     A     A     B     A     D     B     B     D     D      ...         \n",
       "2     A     A     A     A     B     D     B     B     B     B      ...         \n",
       "3     B     A     A     A     A     D     B     D     B     D      ...         \n",
       "4     A     A     A     A     A     D     B     B     D     D      ...         \n",
       "\n",
       "      cont6     cont7    cont8    cont9   cont10    cont11    cont12  \\\n",
       "0  0.466591  0.317681  0.61229  0.34365  0.38016  0.377724  0.369858   \n",
       "1  0.482425  0.443760  0.71330  0.51890  0.60401  0.689039  0.675759   \n",
       "2  0.212308  0.325779  0.29758  0.34365  0.30529  0.245410  0.241676   \n",
       "3  0.369930  0.342355  0.40028  0.33237  0.31480  0.348867  0.341872   \n",
       "4  0.398862  0.391833  0.23688  0.43731  0.50556  0.359572  0.352251   \n",
       "\n",
       "     cont13    cont14 cat1cat72_freq  \n",
       "0  0.704052  0.392562       0.114231  \n",
       "1  0.453468  0.208045       0.187841  \n",
       "2  0.258586  0.297232       0.496757  \n",
       "3  0.592264  0.555955       0.151282  \n",
       "4  0.301535  0.825823       0.114231  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Check data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4cAAAEKCAYAAAChXCC5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa81ef5add0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lossRestore(val_g):\n",
    "    return np.expm1(val_g)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.hist(data_train_raw['loss_g'],100)\n",
    "plt.title('log1p(loss)');\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.hist(lossRestore(data_train_raw['loss_g']),100)\n",
    "plt.title('loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labeling encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDf has features from the raw data:\n",
      "Index([u'cat72', u'cat73', u'cat74', u'cat75', u'cat76', u'cat77', u'cat78',\n",
      "       u'cat79', u'cat80', u'cat81', u'cat82', u'cat83', u'cat84', u'cat85',\n",
      "       u'cat86', u'cat87', u'cat88', u'cat89', u'cat90', u'cat91', u'cat92',\n",
      "       u'cat93', u'cat94', u'cat95', u'cat96', u'cat97', u'cat98', u'cat99',\n",
      "       u'cat100', u'cat101', u'cat102', u'cat103', u'cat104', u'cat105',\n",
      "       u'cat106', u'cat107', u'cat108', u'cat109', u'cat110', u'cat111',\n",
      "       u'cat112', u'cat113', u'cat114', u'cat115', u'cat116', u'cont1',\n",
      "       u'cont2', u'cont3', u'cont4', u'cont5', u'cont6', u'cont7', u'cont8',\n",
      "       u'cont9', u'cont10', u'cont11', u'cont12', u'cont13', u'cont14',\n",
      "       u'cat1cat72_freq'],\n",
      "      dtype='object')\n",
      "testDf has features from the raw data:\n",
      "Index([u'cat72', u'cat73', u'cat74', u'cat75', u'cat76', u'cat77', u'cat78',\n",
      "       u'cat79', u'cat80', u'cat81', u'cat82', u'cat83', u'cat84', u'cat85',\n",
      "       u'cat86', u'cat87', u'cat88', u'cat89', u'cat90', u'cat91', u'cat92',\n",
      "       u'cat93', u'cat94', u'cat95', u'cat96', u'cat97', u'cat98', u'cat99',\n",
      "       u'cat100', u'cat101', u'cat102', u'cat103', u'cat104', u'cat105',\n",
      "       u'cat106', u'cat107', u'cat108', u'cat109', u'cat110', u'cat111',\n",
      "       u'cat112', u'cat113', u'cat114', u'cat115', u'cat116', u'cont1',\n",
      "       u'cont2', u'cont3', u'cont4', u'cont5', u'cont6', u'cont7', u'cont8',\n",
      "       u'cont9', u'cont10', u'cont11', u'cont12', u'cont13', u'cont14',\n",
      "       u'cat1cat72_freq'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# save label in a seperate serie\n",
    "labelSs = data_train_raw['loss_g'] \n",
    "trainDf = data_train_raw.drop(['loss_g'],axis=1)\n",
    "# subId = data_test_raw['id']\n",
    "testDf = data_test_raw\n",
    "\n",
    "print('trainDf has features from the raw data:\\n{}'.format(trainDf.columns))\n",
    "print('testDf has features from the raw data:\\n{}'.format(testDf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the stacked data's dimension are:\n",
      "(313500, 60)\n",
      "(313500, 45) of which are categorical\n",
      "(313500, 15) of which are continuous\n"
     ]
    }
   ],
   "source": [
    "dataAll = pd.concat([trainDf,testDf])\n",
    "dataCatAll = dataAll.select_dtypes(include=['object'])\n",
    "dataFltAll = dataAll.select_dtypes(include=['float64'])\n",
    "print('the stacked data\\'s dimension are:\\n{}'.format(dataAll.shape))\n",
    "print('{} of which are categorical'.format(dataCatAll.shape))\n",
    "print('{} of which are continuous'.format(dataFltAll.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'cat72', u'cat73', u'cat74', u'cat75', u'cat76', u'cat77', u'cat78',\n",
      "       u'cat79', u'cat80', u'cat81', u'cat82', u'cat83', u'cat84', u'cat85',\n",
      "       u'cat86', u'cat87', u'cat88', u'cat89', u'cat90', u'cat91', u'cat92',\n",
      "       u'cat93', u'cat94', u'cat95', u'cat96', u'cat97', u'cat98', u'cat99',\n",
      "       u'cat100', u'cat101', u'cat102', u'cat103', u'cat104', u'cat105',\n",
      "       u'cat106', u'cat107', u'cat108', u'cat109', u'cat110', u'cat111',\n",
      "       u'cat112', u'cat113', u'cat114', u'cat115', u'cat116'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in dataCatAll.columns:\n",
    "    if (col.find('cat') !=-1):\n",
    "#        print(col)\n",
    "        dataCatAll[col]=le.fit_transform(dataCatAll[col])\n",
    "#         dataAll[col] = dataAll[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "#         le.classes_ = np.append(le.classes_, '<unknown>')\n",
    "#         data_test_raw[str(col+'_numerical')]=le.transform(data_test_raw[col])\n",
    "print(dataCatAll.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skipped - restore to x_trainDf and x_testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # hstack all the features and .\n",
    "# x_allDf = pd.concat([dataCatAll,dataFltAll],axis=1)\n",
    "# x_means = x_allDf.mean()\n",
    "# x_stds = x_allDf.std()\n",
    "# x_allDf = (x_allDf-x_means)/x_stds\n",
    "# x_allDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_Train = x_allDf.iloc[0:len(labelSs),:]\n",
    "# x_Test = x_allDf.iloc[len(labelSs):,:]\n",
    "# y_Train = labelSs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313500, 1033)\n"
     ]
    }
   ],
   "source": [
    "# one-hot-encoding the categorical features\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "x_catAll = enc.fit_transform(dataCatAll)\n",
    "print(x_catAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split x_train and x_test\n",
    "x_Train = sp.sparse.hstack((x_catAll[0:len(labelSs),:], sp.sparse.csr_matrix(dataFltAll.as_matrix())[0:len(labelSs),:]))\n",
    "x_Test = sp.sparse.hstack((x_catAll[len(labelSs):,:], sp.sparse.csr_matrix(dataFltAll.as_matrix())[len(labelSs):,:]))\n",
    "y_Train = labelSs.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the dimension of prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125546, 1048)\n",
      "(187954, 1048)\n",
      "(187954,)\n"
     ]
    }
   ],
   "source": [
    "print(x_Test.shape)\n",
    "print(x_Train.shape)\n",
    "print(y_Train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the training data for valiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150363, 1048)\n",
      "(150363,)\n",
      "(37591, 1048)\n",
      "(37591,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "val_size = 0.2\n",
    "seed = 0\n",
    "x_train, x_val, y_train, y_val = cross_validation.train_test_split(x_Train, y_Train, test_size=val_size, random_state=seed)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x_Train\n",
    "del y_Train\n",
    "# del x_catAll\n",
    "# del dataCatAll\n",
    "del trainDf\n",
    "del testDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 1st Level Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = []\n",
    "y_pred_val = []\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "testList = ['Ridge', 'XGBoostTrees', 'AdaBoosting', 'MLPRegressor','Ensemble']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = 3\n",
    "alphas = (1e-2,1e-1,1,1e1,1e2)\n",
    "# alphas = (90, 100, 120, 130,150)\n",
    "# alphas = [40]\n",
    "regCV = RidgeCV(cv=cv,alphas = alphas)\n",
    "regCV.fit(x_train,y_train)\n",
    "print('alpha: {}\\n'.format(regCV.alpha_))\n",
    "# print('cv_values_: {}\\n'.format(regCV.cv_values_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260.93406804\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(lossRestore(y_val),lossRestore(regCV.predict(x_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(regCV.predict(x_Test))\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(regCV.predict(x_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skipped - Lasso Regression - almost the same as Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cv = 3\n",
    "# # alphas = (1e-3,1e-2,1e-1,1,1e1,1e2,1e3)\n",
    "# # alphas = (0.0005,0.0007,0.001,0.003,0.005)\n",
    "# # alphas = [0.00005,0.0001,0.0003,0.0005]\n",
    "# alphas = [0.00005]\n",
    "# LassoCV = LassoCV(cv=cv,alphas = alphas)\n",
    "# LassoCV.fit(x_train,y_train)\n",
    "# print('alpha: {}\\n'.format(LassoCV.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(LassoCV.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(LassoCV.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(LassoCV.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipped - Random Forest - using mse rather than mae, because the mae implementation is much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# criterion = 'mse'\n",
    "# n_estimators = [30]\n",
    "# err = 999999999\n",
    "# n_estimator = 0\n",
    "# random_state = 0\n",
    "# for n_est in n_estimators:\n",
    "#     tmpRFReg = RandomForestRegressor(n_estimators = n_est,criterion = criterion, random_state = random_state)\n",
    "#     tmpRFReg.fit(x_train,y_train)\n",
    "#     err_i = mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(tmpRFReg.predict(x_val),ymean,ystd))\n",
    "#     print(err_i)\n",
    "#     if err_i < err:\n",
    "#         RFReg = tmpRFReg\n",
    "#         n_estimator = n_est\n",
    "#         err = err_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('n_estimator = {}'.format(n_estimator))\n",
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(RFReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(RFReg.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(RFReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_train, x_val, y_train, y_val\n",
    "# d_train_xgb = xgb.DMatrix(x_train.tocsc(),label=y_train)\n",
    "# d_val_xgb = xgb.DMatrix(x_val.tocsc(),label = y_val)\n",
    "# x_val_xgb = xgb.DMatrix(x_val.tocsc())\n",
    "# d_test_xgb = xgb.DMatrix(x_Test.tocsc())\n",
    "d_train_xgb = xgb.DMatrix(x_train,label=y_train)\n",
    "d_val_xgb = xgb.DMatrix(x_val,label = y_val)\n",
    "x_val_xgb = xgb.DMatrix(x_val)\n",
    "d_test_xgb = xgb.DMatrix(x_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:5.08482\ttrain-rmse:5.08072\n",
      "[1]\teval-rmse:3.58729\ttrain-rmse:3.58393\n",
      "[2]\teval-rmse:2.54779\ttrain-rmse:2.54451\n",
      "[3]\teval-rmse:1.83232\ttrain-rmse:1.82867\n",
      "[4]\teval-rmse:1.34891\ttrain-rmse:1.3435\n",
      "[5]\teval-rmse:1.03086\ttrain-rmse:1.02348\n",
      "[6]\teval-rmse:0.829256\ttrain-rmse:0.819913\n",
      "[7]\teval-rmse:0.70842\ttrain-rmse:0.696179\n",
      "[8]\teval-rmse:0.639588\ttrain-rmse:0.624808\n",
      "[9]\teval-rmse:0.602091\ttrain-rmse:0.585585\n",
      "[10]\teval-rmse:0.582038\ttrain-rmse:0.563696\n",
      "[11]\teval-rmse:0.570747\ttrain-rmse:0.550582\n",
      "[12]\teval-rmse:0.564969\ttrain-rmse:0.543211\n",
      "[13]\teval-rmse:0.561273\ttrain-rmse:0.537767\n",
      "[14]\teval-rmse:0.5593\ttrain-rmse:0.534344\n",
      "[15]\teval-rmse:0.558161\ttrain-rmse:0.531322\n",
      "[16]\teval-rmse:0.557192\ttrain-rmse:0.52894\n",
      "[17]\teval-rmse:0.556516\ttrain-rmse:0.52714\n",
      "[18]\teval-rmse:0.556004\ttrain-rmse:0.525659\n",
      "[19]\teval-rmse:0.555641\ttrain-rmse:0.524392\n",
      "[20]\teval-rmse:0.555262\ttrain-rmse:0.523148\n",
      "[21]\teval-rmse:0.555012\ttrain-rmse:0.521943\n",
      "[22]\teval-rmse:0.554766\ttrain-rmse:0.521014\n",
      "[23]\teval-rmse:0.554421\ttrain-rmse:0.519316\n",
      "[24]\teval-rmse:0.554194\ttrain-rmse:0.517958\n",
      "[25]\teval-rmse:0.554149\ttrain-rmse:0.516948\n",
      "[26]\teval-rmse:0.554074\ttrain-rmse:0.515691\n",
      "[27]\teval-rmse:0.553776\ttrain-rmse:0.514164\n",
      "[28]\teval-rmse:0.553695\ttrain-rmse:0.513322\n",
      "[29]\teval-rmse:0.553773\ttrain-rmse:0.512787\n",
      "[30]\teval-rmse:0.553702\ttrain-rmse:0.51175\n",
      "[31]\teval-rmse:0.553636\ttrain-rmse:0.51078\n",
      "[32]\teval-rmse:0.553549\ttrain-rmse:0.509981\n"
     ]
    }
   ],
   "source": [
    "num_round = 33\n",
    "params = {'eval_metric':'rmse','max_depth':9,'colsample_bytree':0.5}\n",
    "watchlist  = [(d_val_xgb,'eval'), (d_train_xgb,'train')]\n",
    "gbt = xgb.train(params, d_train_xgb,num_round,watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191.30375242\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(lossRestore(y_val),lossRestore(gbt.predict(x_val_xgb))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(gbt.predict(d_test_xgb))\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(gbt.predict(x_val_xgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408.78858092\n",
      "1428.47401025\n",
      "1511.16292214\n",
      "1520.16483783\n",
      "1520.16483783\n",
      "1520.16483783\n"
     ]
    }
   ],
   "source": [
    "# n_estimators = [4,6,8,10,20,30,40,50,60,70,80,90,100,110,120]\n",
    "n_estimators = [6,10,40,70,100,120]\n",
    "# n_estimators = [6]\n",
    "base_estimator = Ridge(alpha = 40)\n",
    "err = 999999999\n",
    "n_estimator = 0\n",
    "random_state = 0\n",
    "for n_est in n_estimators:\n",
    "#     tmpAdReg = AdaBoostRegressor(n_estimators = n_est, random_state = random_state,base_estimator = base_estimator)\n",
    "    tmpAdReg = AdaBoostRegressor(n_estimators = n_est, random_state = random_state)\n",
    "    tmpAdReg.fit(x_train,y_train)\n",
    "    err_i = mean_absolute_error(lossRestore(y_val),lossRestore(tmpAdReg.predict(x_val)))\n",
    "    print(err_i)\n",
    "    if err_i < err:\n",
    "        AdReg = tmpAdReg\n",
    "        n_estimator = n_est\n",
    "        err = err_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimator = 6\n",
      "1408.78858092\n"
     ]
    }
   ],
   "source": [
    "print('n_estimator = {}'.format(n_estimator))\n",
    "print(mean_absolute_error(lossRestore(y_val),lossRestore(AdReg.predict(x_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(AdReg.predict(x_Test))\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(AdReg.predict(x_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipped - K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_neighbors = [5, 10, 15]\n",
    "# weights = 'distance'\n",
    "# err = 999999999\n",
    "# n_nns = 0\n",
    "# # random_state = 0\n",
    "# for n_nn in n_neighbors:\n",
    "#     tmpKNReg = KNeighborsRegressor(n_neighbors = n_nn,weights = weights)\n",
    "#     tmpKNReg.fit(x_train,y_train)\n",
    "#     err_i = mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(tmpKNReg.predict(x_val),ymean,ystd))\n",
    "#     print(err_i)\n",
    "#     if err_i < err:\n",
    "#         KNReg = tmpKNReg\n",
    "#         n_nns = n_nn\n",
    "#         err = err_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('n_neighbors = {}'.format(n_nns))\n",
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(KNReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(KNReg.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(KNReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skipped - Linear SVR - similar to the Ridge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVR,SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SVReg = SVR(kernel = 'rbf')\n",
    "## SVReg.fit(x_train,y_train)\n",
    "#SVReg = LinearSVR(C=0.5)\n",
    "#SVReg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(SVReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(SVReg.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(SVReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(75, 3), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPReg = MLPRegressor(alpha = 1e-5, hidden_layer_sizes = (75,3),random_state=0,early_stopping=True)\n",
    "MLPReg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197.48621604\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(lossRestore(y_val),lossRestore(MLPReg.predict(x_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(MLPReg.predict(x_Test))\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(MLPReg.predict(x_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging results to get the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of the ensembled result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1198.3996878033417"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble the results\n",
    "y_pred.append(np.ndarray.mean(np.vstack(y_pred).T,axis=1))\n",
    "\n",
    "# ensembled y_val\n",
    "print('The loss of the ensembled result:')\n",
    "y_pred_val_en = np.ndarray.mean(np.vstack(y_pred_val).T,axis=1)\n",
    "mean_absolute_error(lossRestore(y_val),y_pred_val_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_val.append(y_pred_val_en)\n",
    "# testList.append('y_val')\n",
    "# testList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Check the correlation among results of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation among all the predicted resutls for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "(\"global name 'ymean' is not defined\", u'occurred at index Ridge')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-66da3bb06eb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0myValPredDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestList\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0myValPredDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myValPredDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mymean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mystd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0myValPredDf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_val'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0myValPredDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ec2-user/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapplymap\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   4248\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4250\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4252\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ec2-user/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   4059\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4060\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4061\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4062\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ec2-user/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4155\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4156\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4157\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4158\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4159\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ec2-user/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36minfer\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   4246\u001b[0m         \u001b[1;31m# if we have a dtype == 'M8[ns]', provide boxed values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4247\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4248\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4250\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62658)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-66da3bb06eb4>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0myValPredDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestList\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0myValPredDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myValPredDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mymean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mystd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0myValPredDf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_val'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0myValPredDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: (\"global name 'ymean' is not defined\", u'occurred at index Ridge')"
     ]
    }
   ],
   "source": [
    "# testList.append('y_val')\n",
    "yValPredDf = pd.DataFrame(data=np.column_stack(y_pred_val), columns = testList )\n",
    "\n",
    "yValPredDf = yValPredDf.applymap(lambda x: (np.log1p(x)-ymean)/ystd)\n",
    "yValPredDf['y_val'] = y_val\n",
    "yValPredDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (np.log1p(y_pred_val[5])-ymean)/ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(yValPredDf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate new features from the intermediate results of level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_1 = np.column_stack([regCV.predict(x_train), gbt.predict(d_train_xgb), AdReg.predict(x_train), MLPReg.predict(x_train)])\n",
    "\n",
    "x_val_1 = np.column_stack(y_pred_val[0:4])\n",
    "x_val_1 = (np.log1p(x_val_1)-ymean)/ystd\n",
    "\n",
    "x_test_1 = np.column_stack(y_pred[0:4])\n",
    "x_test_1 = (np.log1p(x_test_1)-ymean)/ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_train_1.shape)\n",
    "print(x_val_1.shape)\n",
    "print(x_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_train_1\n",
    "# x_val_1\n",
    "# x_test_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 2nd Level Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = 5\n",
    "alphas = [1e-3,1e-2,1e-1,1,1e1,1e2,1e3]\n",
    "# alphas = (20,30,40)\n",
    "# alphas = [40]\n",
    "regCV_2 = RidgeCV(cv=cv,alphas = alphas)\n",
    "regCV_2.fit(x_train_1,y_train)\n",
    "print('alpha: {}\\n'.format(regCV_2.alpha_))\n",
    "# print('cv_values_: {}\\n'.format(regCV_2.cv_values_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(lossRestore(y_val),lossRestore(regCV_2.predict(x_val_1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(regCV_2.predict(x_test_1))\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(regCV_2.predict(x_val_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_train_xgb_1 = xgb.DMatrix(x_train_1,label=y_train)\n",
    "d_val_xgb_1 = xgb.DMatrix(x_val_1,label = y_val)\n",
    "x_val_xgb_1 = xgb.DMatrix(x_val_1)\n",
    "d_test_xgb_1 = xgb.DMatrix(x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_round = 8\n",
    "params = {'eval_metric':'rmse','max_depth':9}\n",
    "watchlist  = [(d_val_xgb_1,'eval'), (d_train_xgb_1,'train')]\n",
    "gbt_1 = xgb.train(params, d_train_xgb_1,num_round,watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(lossRestore(y_val),lossRestore(gbt_1.predict(x_val_xgb_1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(gbt_1.predict(d_test_xgb_1))\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(gbt_1.predict(x_val_xgb_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Save results and the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save all the predictions for submission\n",
    "for i,stri in enumerate(testList):\n",
    "    submission['id'] = subId\n",
    "    submission['loss']=pd.Series(data=y_pred[i])\n",
    "    submission.to_csv('../output/'+stri+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump([regCV, gbt, AdReg, MLPReg, y_pred, y_pred_val, x_train, x_val, y_train, y_val, x_Test]\n",
    "            ,'../output/models_data_on_raw_features.pkl',compress=3) \n",
    "\n",
    "# clf = joblib.load('filename.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
