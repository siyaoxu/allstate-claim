{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "326306ca-a5d0-4828-f587-d6e4e3f84d09"
   },
   "source": [
    "## Data statistics\n",
    "* Shape\n",
    "* Peek\n",
    "* Description\n",
    "* Skew\n",
    "\n",
    "## Transformation\n",
    "* Correction of skew\n",
    "\n",
    "## Data Interaction\n",
    "* Correlation\n",
    "* Scatter plot\n",
    "\n",
    "## Data Visualization\n",
    "* Box and density plots\n",
    "* Grouping of one hot encoded attributes\n",
    "\n",
    "## Data Preparation\n",
    "* One hot encoding of categorical data\n",
    "* Test-train split\n",
    "\n",
    "## Evaluation, prediction, and analysis\n",
    "* Linear Regression (Linear algo)\n",
    "* Ridge Regression (Linear algo)\n",
    "* LASSO Linear Regression (Linear algo)\n",
    "* Elastic Net Regression (Linear algo)\n",
    "* KNN (non-linear algo)\n",
    "* CART (non-linear algo)\n",
    "* SVM (Non-linear algo)\n",
    "* Bagged Decision Trees (Bagging)\n",
    "* Random Forest (Bagging)\n",
    "* Extra Trees (Bagging)\n",
    "* AdaBoost (Boosting)\n",
    "* Stochastic Gradient Boosting (Boosting)\n",
    "* MLP (Deep Learning)\n",
    "* XGBoost\n",
    "\n",
    "## Make Predictions\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d9dd03a6-5daa-e559-b1c3-23b330f330b7"
   },
   "source": [
    "## Load raw data:\n",
    "\n",
    "Information about all the attributes can be found here:\n",
    "\n",
    "https://www.kaggle.com/c/allstate-claims-severity/data\n",
    "\n",
    "Learning: \n",
    "We need to predict the 'loss' based on the other attributes. Hence, this is a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "8c463d4f-7dcc-42b3-500e-fe0aecd73c4c",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10 cat11 cat12 cat13  \\\n",
      "0   1    A    B    A    B    A    A    A    A    B     A     B     A     A   \n",
      "1   2    A    B    A    A    A    A    A    A    B     B     A     A     A   \n",
      "2   5    A    B    A    A    B    A    A    A    B     B     B     B     B   \n",
      "3  10    B    B    A    B    A    A    A    A    B     A     A     A     A   \n",
      "4  11    A    B    A    B    A    A    A    A    B     B     A     B     A   \n",
      "\n",
      "  cat14 cat15 cat16 cat17 cat18 cat19 cat20 cat21 cat22 cat23 cat24 cat25  \\\n",
      "0     A     A     A     A     A     A     A     A     A     B     A     A   \n",
      "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "3     A     A     A     A     A     A     A     A     A     B     A     A   \n",
      "4     A     A     A     A     A     A     A     A     A     B     A     A   \n",
      "\n",
      "  cat26 cat27 cat28 cat29 cat30 cat31 cat32 cat33 cat34 cat35 cat36 cat37  \\\n",
      "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "2     A     A     A     A     A     A     A     A     A     A     B     A   \n",
      "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "\n",
      "  cat38 cat39 cat40 cat41 cat42 cat43 cat44 cat45 cat46 cat47 cat48 cat49  \\\n",
      "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "\n",
      "  cat50 cat51 cat52 cat53 cat54 cat55 cat56 cat57 cat58 cat59 cat60 cat61  \\\n",
      "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "\n",
      "  cat62 cat63 cat64 cat65 cat66 cat67 cat68 cat69 cat70 cat71 cat72 cat73  \\\n",
      "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
      "3     A     A     A     A     A     A     A     A     A     A     A     B   \n",
      "4     A     A     A     A     A     A     A     A     A     A     B     A   \n",
      "\n",
      "  cat74 cat75 cat76 cat77 cat78 cat79 cat80 cat81 cat82 cat83 cat84 cat85  \\\n",
      "0     A     B     A     D     B     B     D     D     B     D     C     B   \n",
      "1     A     A     A     D     B     B     D     D     A     B     C     B   \n",
      "2     A     A     A     D     B     B     B     D     B     D     C     B   \n",
      "3     A     A     A     D     B     B     D     D     D     B     C     B   \n",
      "4     A     A     A     D     B     D     B     D     B     B     C     B   \n",
      "\n",
      "  cat86 cat87 cat88 cat89 cat90 cat91 cat92 cat93 cat94 cat95 cat96 cat97  \\\n",
      "0     D     B     A     A     A     A     A     D     B     C     E     A   \n",
      "1     D     B     A     A     A     A     A     D     D     C     E     E   \n",
      "2     B     B     A     A     A     A     A     D     D     C     E     E   \n",
      "3     D     B     A     A     A     A     A     D     D     C     E     E   \n",
      "4     B     C     A     A     A     B     H     D     B     D     E     E   \n",
      "\n",
      "  cat98 cat99 cat100 cat101 cat102 cat103 cat104 cat105 cat106 cat107 cat108  \\\n",
      "0     C     T      B      G      A      A      I      E      G      J      G   \n",
      "1     D     T      L      F      A      A      E      E      I      K      K   \n",
      "2     A     D      L      O      A      B      E      F      H      F      A   \n",
      "3     D     T      I      D      A      A      E      E      I      K      K   \n",
      "4     A     P      F      J      A      A      D      E      K      G      B   \n",
      "\n",
      "  cat109 cat110 cat111 cat112 cat113 cat114 cat115 cat116     cont1     cont2  \\\n",
      "0     BU     BC      C     AS      S      A      O     LB  0.726300  0.245921   \n",
      "1     BI     CQ      A     AV     BM      A      O     DP  0.330514  0.737068   \n",
      "2     AB     DK      A      C     AF      A      I     GK  0.261841  0.358319   \n",
      "3     BI     CS      C      N     AE      A      O     DJ  0.321594  0.555782   \n",
      "4      H      C      C      Y     BM      A      K     CK  0.273204  0.159990   \n",
      "\n",
      "      cont3     cont4     cont5     cont6     cont7    cont8    cont9  \\\n",
      "0  0.187583  0.789639  0.310061  0.718367  0.335060  0.30260  0.67135   \n",
      "1  0.592681  0.614134  0.885834  0.438917  0.436585  0.60087  0.35127   \n",
      "2  0.484196  0.236924  0.397069  0.289648  0.315545  0.27320  0.26076   \n",
      "3  0.527991  0.373816  0.422268  0.440945  0.391128  0.31796  0.32128   \n",
      "4  0.527991  0.473202  0.704268  0.178193  0.247408  0.24564  0.22089   \n",
      "\n",
      "    cont10    cont11    cont12    cont13    cont14     loss  \n",
      "0  0.83510  0.569745  0.594646  0.822493  0.714843  2213.18  \n",
      "1  0.43919  0.338312  0.366307  0.611431  0.304496  1283.60  \n",
      "2  0.32446  0.381398  0.373424  0.195709  0.774425  3005.09  \n",
      "3  0.44467  0.327915  0.321570  0.605077  0.602642   939.85  \n",
      "4  0.21230  0.204687  0.202213  0.246011  0.432606  2763.85  \n"
     ]
    }
   ],
   "source": [
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read raw data from the file\n",
    "\n",
    "import pandas #provides data structures to quickly analyze data\n",
    "#Since this code runs on Kaggle server, data can be accessed directly in the 'input' folder\n",
    "#Read the train dataset\n",
    "dataset = pandas.read_csv(\"../input/train.csv\") \n",
    "\n",
    "#Read test dataset\n",
    "dataset_test = pandas.read_csv(\"../input/test.csv\")\n",
    "#Save the id's for submission file\n",
    "ID = dataset_test['id']\n",
    "#Drop unnecessary columns\n",
    "dataset_test.drop('id',axis=1,inplace=True)\n",
    "\n",
    "#Print all rows and columns. Dont hide any\n",
    "pandas.set_option('display.max_rows', None)\n",
    "pandas.set_option('display.max_columns', None)\n",
    "\n",
    "#Display the first five rows to get a feel of the data\n",
    "print(dataset.head(5))\n",
    "\n",
    "#Learning : cat1 to cat116 contain alphabets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e9d7e580-ca0d-1939-e037-ce6e53077be0"
   },
   "source": [
    "## Data statistics\n",
    "* Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "63dfe415-ba1f-0b31-f75a-a8be177ca134",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 132)\n"
     ]
    }
   ],
   "source": [
    "# Size of the dataframe\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "# We can see that there are 188318 instances having 132 attributes\n",
    "\n",
    "#Drop the first column 'id' since it just has serial numbers. Not useful in the prediction process.\n",
    "dataset = dataset.iloc[:,1:]\n",
    "\n",
    "#Learning : Data is loaded successfully as dimensions match the data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9dc622e7-2f8b-90a6-1f0d-da7d442c4994"
   },
   "source": [
    "## Data statistics\n",
    "* Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "390f4a98-b5c0-0f08-b483-61a8ea998022",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               cont1          cont2          cont3          cont4  \\\n",
      "count  188318.000000  188318.000000  188318.000000  188318.000000   \n",
      "mean        0.493861       0.507188       0.498918       0.491812   \n",
      "std         0.187640       0.207202       0.202105       0.211292   \n",
      "min         0.000016       0.001149       0.002634       0.176921   \n",
      "25%         0.346090       0.358319       0.336963       0.327354   \n",
      "50%         0.475784       0.555782       0.527991       0.452887   \n",
      "75%         0.623912       0.681761       0.634224       0.652072   \n",
      "max         0.984975       0.862654       0.944251       0.954297   \n",
      "\n",
      "               cont5          cont6          cont7          cont8  \\\n",
      "count  188318.000000  188318.000000  188318.000000  188318.000000   \n",
      "mean        0.487428       0.490945       0.484970       0.486437   \n",
      "std         0.209027       0.205273       0.178450       0.199370   \n",
      "min         0.281143       0.012683       0.069503       0.236880   \n",
      "25%         0.281143       0.336105       0.350175       0.312800   \n",
      "50%         0.422268       0.440945       0.438285       0.441060   \n",
      "75%         0.643315       0.655021       0.591045       0.623580   \n",
      "max         0.983674       0.997162       1.000000       0.980200   \n",
      "\n",
      "               cont9         cont10         cont11         cont12  \\\n",
      "count  188318.000000  188318.000000  188318.000000  188318.000000   \n",
      "mean        0.485506       0.498066       0.493511       0.493150   \n",
      "std         0.181660       0.185877       0.209737       0.209427   \n",
      "min         0.000080       0.000000       0.035321       0.036232   \n",
      "25%         0.358970       0.364580       0.310961       0.311661   \n",
      "50%         0.441450       0.461190       0.457203       0.462286   \n",
      "75%         0.566820       0.614590       0.678924       0.675759   \n",
      "max         0.995400       0.994980       0.998742       0.998484   \n",
      "\n",
      "              cont13         cont14           loss  \n",
      "count  188318.000000  188318.000000  188318.000000  \n",
      "mean        0.493138       0.495717    3037.337686  \n",
      "std         0.212777       0.222488    2904.086186  \n",
      "min         0.000228       0.179722       0.670000  \n",
      "25%         0.315758       0.294610    1204.460000  \n",
      "50%         0.363547       0.407403    2115.570000  \n",
      "75%         0.689974       0.724623    3864.045000  \n",
      "max         0.988494       0.844848  121012.250000  \n"
     ]
    }
   ],
   "source": [
    "# Statistical description\n",
    "\n",
    "print(dataset.describe())\n",
    "\n",
    "# Learning :\n",
    "# No attribute in continuous columns is missing as count is 188318 for all, all rows can be used\n",
    "# No negative values are present. Tests such as chi2 can be used\n",
    "# Statistics not displayed for categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "256cafeb-2554-1eca-2c85-d194cc734593"
   },
   "source": [
    "## Data statistics\n",
    "* Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "fa552a5f-3792-4d0f-155b-b590a7a15a98",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont1     0.516424\n",
      "cont2    -0.310941\n",
      "cont3    -0.010002\n",
      "cont4     0.416096\n",
      "cont5     0.681622\n",
      "cont6     0.461214\n",
      "cont7     0.826053\n",
      "cont8     0.676634\n",
      "cont9     1.072429\n",
      "cont10    0.355001\n",
      "cont11    0.280821\n",
      "cont12    0.291992\n",
      "cont13    0.380742\n",
      "cont14    0.248674\n",
      "loss      3.794958\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Skewness of the distribution\n",
    "\n",
    "print(dataset.skew())\n",
    "\n",
    "# Values close to 0 show less ske\n",
    "# loss shows the highest skew. Let us visualize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5de92921-6b8f-83ca-65f3-3813ca366bcd"
   },
   "source": [
    "## Data Visualization\n",
    "* Box and density plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "1a171815-f5ba-f451-33e5-456e8ded239c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will visualize all the continuous attributes using Violin Plot - a combination of box and density plots\n",
    "\n",
    "import numpy\n",
    "\n",
    "#import plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#range of features considered\n",
    "split = 116 \n",
    "\n",
    "#number of features considered\n",
    "size = 15\n",
    "\n",
    "#create a dataframe with only continuous features\n",
    "data=dataset.iloc[:,split:] \n",
    "\n",
    "#get the names of all the columns\n",
    "cols=data.columns \n",
    "\n",
    "##Plot violin for all attributes in a 7x2 grid\n",
    "#n_cols = 2\n",
    "#n_rows = 7\n",
    "\n",
    "#for i in range(n_rows):\n",
    "#    fg,ax = plt.subplots(nrows=1,ncols=n_cols,figsize=(12, 8))\n",
    "#    for j in range(n_cols):\n",
    "#        sns.violinplot(y=cols[i*n_cols+j], data=dataset, ax=ax[j])\n",
    "\n",
    "\n",
    "##cont1 has many values close to 0.5\n",
    "#cont2 has a pattern where there a several spikes at specific points\n",
    "#cont5 has many values near 0.3\n",
    "#cont14 has a distinct pattern. 0.22 and 0.82 have a lot of concentration\n",
    "#loss distribution must be converted to normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3b52e6c3-6d33-bfcd-417a-e42993019e57"
   },
   "source": [
    "## Data Transformation\n",
    "* Skew correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "991f616d-056f-c31d-51b7-a5495f52b1a5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#log1p function applies log(1+x) to all elements of the column\n",
    "dataset[\"loss\"] = numpy.log1p(dataset[\"loss\"])\n",
    "##visualize the transformed column\n",
    "#sns.violinplot(data=dataset,y=\"loss\")  \n",
    "#plt.show()\n",
    "\n",
    "##Plot shows that skew is corrected to a large extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e01c75f0-d1e7-cb29-a9ea-6a1b169fd3f3"
   },
   "source": [
    "## Data Interaction\n",
    "* Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "497cc626-14f9-d813-bf2a-e99dcc704492",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont11 and cont12 = 0.99\n",
      "cont1 and cont9 = 0.93\n",
      "cont6 and cont10 = 0.88\n",
      "cont6 and cont13 = 0.82\n",
      "cont1 and cont10 = 0.81\n",
      "cont6 and cont9 = 0.80\n",
      "cont9 and cont10 = 0.79\n",
      "cont6 and cont12 = 0.79\n",
      "cont6 and cont11 = 0.77\n",
      "cont1 and cont6 = 0.76\n",
      "cont7 and cont11 = 0.75\n",
      "cont7 and cont12 = 0.74\n",
      "cont10 and cont12 = 0.71\n",
      "cont10 and cont13 = 0.71\n",
      "cont10 and cont11 = 0.70\n",
      "cont6 and cont7 = 0.66\n",
      "cont9 and cont13 = 0.64\n",
      "cont9 and cont12 = 0.63\n",
      "cont1 and cont12 = 0.61\n",
      "cont9 and cont11 = 0.61\n",
      "cont1 and cont11 = 0.60\n",
      "cont1 and cont13 = 0.53\n",
      "cont4 and cont8 = 0.53\n"
     ]
    }
   ],
   "source": [
    "# Correlation tells relation between two attributes.\n",
    "# Correlation requires continous data. Hence, ignore categorical data\n",
    "\n",
    "# Calculates pearson co-efficient for all combinations\n",
    "data_corr = data.corr()\n",
    "\n",
    "# Set the threshold to select only highly correlated attributes\n",
    "threshold = 0.5\n",
    "\n",
    "# List of pairs along with correlation above threshold\n",
    "corr_list = []\n",
    "\n",
    "#Search for the highly correlated pairs\n",
    "for i in range(0,size): #for 'size' features\n",
    "    for j in range(i+1,size): #avoid repetition\n",
    "        if (data_corr.iloc[i,j] >= threshold and data_corr.iloc[i,j] < 1) or (data_corr.iloc[i,j] < 0 and data_corr.iloc[i,j] <= -threshold):\n",
    "            corr_list.append([data_corr.iloc[i,j],i,j]) #store correlation and columns index\n",
    "\n",
    "#Sort to show higher ones first            \n",
    "s_corr_list = sorted(corr_list,key=lambda x: -abs(x[0]))\n",
    "\n",
    "#Print correlations and column names\n",
    "for v,i,j in s_corr_list:\n",
    "    print (\"%s and %s = %.2f\" % (cols[i],cols[j],v))\n",
    "\n",
    "# Strong correlation is observed between the following pairs\n",
    "# This represents an opportunity to reduce the feature set through transformations such as PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3cb5b864-ec2b-07c4-659f-09760f78620a"
   },
   "source": [
    "## Data Interaction\n",
    "* Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "0e7fc7f5-f9a6-4b5c-b176-b555174c8772",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Scatter plot of only the highly correlated pairs\n",
    "#for v,i,j in s_corr_list:\n",
    "#    sns.pairplot(dataset, size=6, x_vars=cols[i],y_vars=cols[j] )\n",
    "#    plt.show()\n",
    "\n",
    "#cont11 and cont12 give an almost linear pattern...one must be removed\n",
    "#cont1 and cont9 are highly correlated ...either of them could be safely removed \n",
    "#cont6 and cont10 show very good correlation too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bcd4e9e4-da38-a95b-62ea-4dedb5a267c5"
   },
   "source": [
    "## Data Visualization\n",
    "* Categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "6fdc916f-2eb8-6fc8-67b2-02bf997a55d9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Count of each label in each category#\n",
    "#\n",
    "##names of all the columns\n",
    "#cols = dataset.columns\n",
    "#\n",
    "##Plot count plot for all attributes in a 29x4 grid\n",
    "#n_cols = 4\n",
    "#n_rows = 29\n",
    "#for i in range(n_rows):\n",
    "#    fg,ax = plt.subplots(nrows=1,ncols=n_cols,sharey=True,figsize=(12, 8))\n",
    "#    for j in range(n_cols):\n",
    "#        sns.countplot(x=cols[i*n_cols+j], data=dataset, ax=ax[j])\n",
    "\n",
    "#cat1 to cat72 have only two labels A and B. In most of the cases, B has very few entries\n",
    "#cat73 to cat 108 have more than two labels\n",
    "#cat109 to cat116 have many labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "816254c9-6ceb-3777-099a-d6c3fa2de438"
   },
   "source": [
    "##Data Preparation\n",
    "* One Hot Encoding of categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "90e603ad-40f9-aa94-db4f-aa87679e30c8",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a1d3e3df871f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "#cat1 to cat116 have strings. The ML algorithms we are going to study require numberical data\n",
    "#One-hot encoding converts an attribute to a binary vector\n",
    "\n",
    "#Variable to hold the list of variables for an attribute in the train and test data\n",
    "labels = []\n",
    "\n",
    "for i in range(0,split):\n",
    "    train = dataset[cols[i]].unique()\n",
    "    test = dataset_test[cols[i]].unique()\n",
    "    labels.append(list(set(train) | set(test)))    \n",
    "\n",
    "del dataset_test\n",
    "\n",
    "#Import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#One hot encode all categorical attributes\n",
    "cats = []\n",
    "for i in range(0, split):\n",
    "    #Label encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(labels[i])\n",
    "    feature = label_encoder.transform(dataset.iloc[:,i])\n",
    "    feature = feature.reshape(dataset.shape[0], 1)\n",
    "    #One hot encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False,n_values=len(labels[i]))\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    cats.append(feature)\n",
    "\n",
    "# Make a 2D array from a list of 1D arrays\n",
    "encoded_cats = numpy.column_stack(cats)\n",
    "\n",
    "# Print the shape of the encoded data\n",
    "print(encoded_cats.shape)\n",
    "l\n",
    "#Concatenate encoded attributes with continuous attributes\n",
    "dataset_encoded = numpy.concatenate((encoded_cats,dataset.iloc[:,split:].values),axis=1)\n",
    "del cats\n",
    "del feature\n",
    "del dataset\n",
    "del encoded_cats\n",
    "print(dataset_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e679f431-acf3-d7ed-4307-f92424338379"
   },
   "source": [
    "##Data Preparation\n",
    "* Split into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "d6ce2c74-dbfe-8341-83d9-59b8968a5f5c",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9621c00c884c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_encoded.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "584b6d52-b4e3-b50c-e758-cb56a993f9cc",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cdd125b3653e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#get the number of rows and columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#create an array which has indexes of columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "#get the number of rows and columns\n",
    "r, c = dataset_encoded.shape\n",
    "\n",
    "#create an array which has indexes of columns\n",
    "i_cols = []\n",
    "for i in range(0,c-1):\n",
    "    i_cols.append(i)\n",
    "\n",
    "#Y is the target column, X has the rest\n",
    "X = dataset_encoded[:,0:(c-1)]\n",
    "Y = dataset_encoded[:,(c-1)]\n",
    "del dataset_encoded\n",
    "\n",
    "#Validation chunk size\n",
    "val_size = 0.1\n",
    "\n",
    "#Use a common seed in all experiments so that same chunk is used for validation\n",
    "seed = 0\n",
    "\n",
    "#Split the data into chunks\n",
    "from sklearn import cross_validation\n",
    "X_train, X_val, Y_train, Y_val = cross_validation.train_test_split(X, Y, test_size=val_size, random_state=seed)\n",
    "del X\n",
    "del Y\n",
    "\n",
    "#All features\n",
    "X_all = []\n",
    "\n",
    "#List of combinations\n",
    "comb = []\n",
    "\n",
    "#Dictionary to store the MAE for all algorithms \n",
    "mae = []\n",
    "\n",
    "#Scoring parameter\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#Add this version of X to the list \n",
    "n = \"All\"\n",
    "#X_all.append([n, X_train,X_val,i_cols])\n",
    "X_all.append([n, i_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6ab93796-e594-f865-67ad-144398f774de"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* Linear Regression (Linear algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "7ca65813-470a-d333-4d79-2071fb5f6ec4",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-601dd1cd3064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#Result obtained after running the algo. Comment the below two lines if you want to run the algo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1278\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LR\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of LinearRegression\n",
    "\n",
    "#Import the library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#uncomment the below lines if you want to run the algo\n",
    "##Set the base model\n",
    "#model = LinearRegression(n_jobs=-1)\n",
    "#algo = \"LR\"\n",
    "#\n",
    "##Accuracy of the model using all features\n",
    "#for name,i_cols_list in X_all:\n",
    "#    model.fit(X_train[:,i_cols_list],Y_train)\n",
    "#    result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "#    mae.append(result)\n",
    "#    print(name + \" %s\" % result)\n",
    "#comb.append(algo)\n",
    "\n",
    "#Result obtained after running the algo. Comment the below two lines if you want to run the algo\n",
    "mae.append(1278)\n",
    "comb.append(\"LR\" )    \n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#MAE achieved is 1278"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a69eb393-e11d-7f80-e0e8-61a345e8dc9c"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* Ridge Regression (Linear algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "d04ac8d0-0623-269b-1d71-e7f53bd8f452",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9f180d8e6a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#Set the base model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Ridge\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of Ridge LinearRegression\n",
    "\n",
    "#Import the library\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#Add the alpha value to the below list if you want to run the algo\n",
    "a_list = numpy.array([10])\n",
    "\n",
    "for alpha in a_list:\n",
    "    #Set the base model\n",
    "    model = Ridge(alpha=alpha,random_state=seed)\n",
    "    \n",
    "    algo = \"Ridge\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % alpha )\n",
    "\n",
    "#Result obtained by running the algo for alpha=1.0    \n",
    "if (len(a_list)==0):\n",
    "    mae.append(1267.5)\n",
    "    comb.append(\"Ridge\" + \" %s\" % 1.0 )    \n",
    "    \n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#Best estimated performance is 1267 with alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "f78f4397-d328-8c83-4490-48ad4d4d8efb",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9a1e22ef977c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_cols_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "numpy.expm1(model.predict(X_val[:,i_cols_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f9419425-a8f4-315e-31e9-d65648224f07"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* LASSO Linear Regression (Linear algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "4b034d80-92fa-ba98-7bc0-b41165b5c244",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3fd058601359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#Result obtained by running the algo for alpha=0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1262.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lasso\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m0.001\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m##Set figure size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of Lasso LinearRegression\n",
    "\n",
    "#Import the library\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#Add the alpha value to the below list if you want to run the algo\n",
    "a_list = numpy.array([])\n",
    "\n",
    "for alpha in a_list:\n",
    "    #Set the base model\n",
    "    model = Lasso(alpha=alpha,random_state=seed)\n",
    "    \n",
    "    algo = \"Lasso\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % alpha )\n",
    "\n",
    "#Result obtained by running the algo for alpha=0.001    \n",
    "if (len(a_list)==0):\n",
    "    mae.append(1262.5)\n",
    "    comb.append(\"Lasso\" + \" %s\" % 0.001 )\n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#High computation time\n",
    "#Best estimated performance is 1262.5 for alpha = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f4f695a5-49b2-709f-d74d-e1dfa17c6b95"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* Elastic Net Regression (Linear algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "9f30aa83-61a3-8720-2960-bc08f0cc4032",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-50bc75cbd379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1260\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Elastic\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m0.001\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of ElasticNet LinearRegression\n",
    "\n",
    "#Import the library\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "#Add the alpha value to the below list if you want to run the algo\n",
    "a_list = numpy.array([])\n",
    "\n",
    "for alpha in a_list:\n",
    "    #Set the base model\n",
    "    model = ElasticNet(alpha=alpha,random_state=seed)\n",
    "    \n",
    "    algo = \"Elastic\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % alpha )\n",
    "\n",
    "if (len(a_list)==0):\n",
    "    mae.append(1260)\n",
    "    comb.append(\"Elastic\" + \" %s\" % 0.001 )\n",
    "    \n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#High computation time\n",
    "#Best estimated performance is 1260 for alpha = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5eec3a22-fb38-2876-4069-4171710a199a"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* KNN (non-linear algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "201e9309-153a-65f4-2616-43b2a6c51163",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-929a102c66f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1745\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KNN\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of KNN\n",
    "\n",
    "#Import the library\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#Add the N value to the below list if you want to run the algo\n",
    "n_list = numpy.array([])\n",
    "\n",
    "for n_neighbors in n_list:\n",
    "    #Set the base model\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors,n_jobs=-1)\n",
    "    \n",
    "    algo = \"KNN\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % n_neighbors )\n",
    "\n",
    "if (len(n_list)==0):\n",
    "    mae.append(1745)\n",
    "    comb.append(\"KNN\" + \" %s\" % 1 )\n",
    "    \n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#Very high computation time\n",
    "#Best estimated performance is 1745 for n=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e04fbf8f-e13a-5bea-fb83-2a066fbea25f"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* CART (non-linear algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "f2fe4450-2d9e-cea1-c4ac-4577fe29ace5",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6b2907ed6ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1741\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CART\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of CART\n",
    "\n",
    "#Import the library\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Add the max_depth value to the below list if you want to run the algo\n",
    "d_list = numpy.array([])\n",
    "\n",
    "for max_depth in d_list:\n",
    "    #Set the base model\n",
    "    model = DecisionTreeRegressor(max_depth=max_depth,random_state=seed)\n",
    "    \n",
    "    algo = \"CART\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % max_depth )\n",
    "\n",
    "if (len(a_list)==0):\n",
    "    mae.append(1741)\n",
    "    comb.append(\"CART\" + \" %s\" % 5 )    \n",
    "    \n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#High computation time\n",
    "#Best estimated performance is 1741 for depth=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fbfb9819-cb69-88c6-13de-ebe529306e1b"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* SVM (Non-linear algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "02470cad-9931-1644-eea7-85fcc31d2c40",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluation of various combinations of SVM\n",
    "\n",
    "#Import the library\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#Add the C value to the below list if you want to run the algo\n",
    "c_list = numpy.array([])\n",
    "\n",
    "for C in c_list:\n",
    "    #Set the base model\n",
    "    model = SVR(C=C)\n",
    "    \n",
    "    algo = \"SVM\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % C )\n",
    "\n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#very very high computation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e0e9b735-5757-d3da-d0fa-1443193ce83d"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* Bagged Decision Trees (Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "0bb62d33-2b7c-fb3f-ed6e-e4d6fe6d34ed",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluation of various combinations of Bagged Decision Trees\n",
    "\n",
    "#Import the library\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Add the n_estimators value to the below list if you want to run the algo\n",
    "n_list = numpy.array([])\n",
    "\n",
    "for n_estimators in n_list:\n",
    "    #Set the base model\n",
    "    model = BaggingRegressor(n_jobs=-1,n_estimators=n_estimators)\n",
    "    \n",
    "    algo = \"Bag\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % n_estimators )\n",
    "\n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#very high computation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "47762d5b-f1df-3c26-4fc1-4eb29cf0275c"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* Random Forest (Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "7a247d11-e71b-a2a4-69ad-e5d3fdb57b13",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a0b7cea41327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1213\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RF\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of RandomForest\n",
    "\n",
    "#Import the library\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Add the n_estimators value to the below list if you want to run the algo\n",
    "n_list = numpy.array([])\n",
    "\n",
    "for n_estimators in n_list:\n",
    "    #Set the base model\n",
    "    model = RandomForestRegressor(n_jobs=-1,n_estimators=n_estimators,random_state=seed)\n",
    "    \n",
    "    algo = \"RF\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % n_estimators )\n",
    "\n",
    "if (len(n_list)==0):\n",
    "    mae.append(1213)\n",
    "    comb.append(\"RF\" + \" %s\" % 50 )    \n",
    "    \n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#Best estimated performance is 1213 when the number of estimators is 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cb5b0c4f-1cac-01d3-1e86-d3502c05b369"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* Extra Trees (Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "68d51895-60c4-81a9-c7f1-92f9c9637b95",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-531aa651e39d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1254\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ET\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of ExtraTrees\n",
    "\n",
    "#Import the library\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "#Add the n_estimators value to the below list if you want to run the algo\n",
    "n_list = numpy.array([])\n",
    "\n",
    "for n_estimators in n_list:\n",
    "    #Set the base model\n",
    "    model = ExtraTreesRegressor(n_jobs=-1,n_estimators=n_estimators,random_state=seed)\n",
    "    \n",
    "    algo = \"ET\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % n_estimators )\n",
    "\n",
    "if (len(n_list)==0):\n",
    "    mae.append(1254)\n",
    "    comb.append(\"ET\" + \" %s\" % 100 )    \n",
    "    \n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#Best estimated performance is 1254 for 100 estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f0cc6bf4-4448-ca0f-6155-a011a92828dd"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* AdaBoost (Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "b6a61f56-fd32-ab56-b645-73d0c511ea61",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8c9634d46463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1678\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ada\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of AdaBoost\n",
    "\n",
    "#Import the library\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#Add the n_estimators value to the below list if you want to run the algo\n",
    "n_list = numpy.array([])\n",
    "\n",
    "for n_estimators in n_list:\n",
    "    #Set the base model\n",
    "    model = AdaBoostRegressor(n_estimators=n_estimators,random_state=seed)\n",
    "    \n",
    "    algo = \"Ada\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % n_estimators )\n",
    "\n",
    "if (len(n_list)==0):\n",
    "    mae.append(1678)\n",
    "    comb.append(\"Ada\" + \" %s\" % 100 )    \n",
    "    \n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#Best estimated performance is 1678 with n=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "618b74ca-39cb-041f-7a47-fa15757b40af"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* Stochastic Gradient Boosting (Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "fb8c5701-5223-d7c9-9c5a-9470b389cc15",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c620e59da436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1278\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SGB\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of SGB\n",
    "\n",
    "#Import the library\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Add the n_estimators value to the below list if you want to run the algo\n",
    "n_list = numpy.array([])\n",
    "\n",
    "for n_estimators in n_list:\n",
    "    #Set the base model\n",
    "    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=seed)\n",
    "    \n",
    "    algo = \"SGB\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % n_estimators )\n",
    "\n",
    "if (len(n_list)==0):\n",
    "    mae.append(1278)\n",
    "    comb.append(\"SGB\" + \" %s\" % 50 )    \n",
    "    \n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#Best estimated performance is ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2526bf7f-5c5a-a067-facd-dadecfbb8019"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "e2fad9ca-8d6b-bdb9-b4b8-b24a9fa7ac46",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-081e5598f6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1169\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"XGB\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of XGB\n",
    "\n",
    "#Import the library\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#Add the n_estimators value to the below list if you want to run the algo\n",
    "n_list = numpy.array([])\n",
    "\n",
    "for n_estimators in n_list:\n",
    "    #Set the base model\n",
    "    model = XGBRegressor(n_estimators=n_estimators,seed=seed)\n",
    "    \n",
    "    algo = \"XGB\"\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for name,i_cols_list in X_all:\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo + \" %s\" % n_estimators )\n",
    "\n",
    "if (len(n_list)==0):\n",
    "    mae.append(1169)\n",
    "    comb.append(\"XGB\" + \" %s\" % 1000 )    \n",
    "    \n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "##Plot the MAE of all combinations\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.plot(mae)\n",
    "##Set the tick names to names of combinations\n",
    "#ax.set_xticks(range(len(comb)))\n",
    "#ax.set_xticklabels(comb,rotation='vertical')\n",
    "##Plot the accuracy for all combinations\n",
    "#plt.show()    \n",
    "\n",
    "#Best estimated performance is 1169 with n=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f0e24c8-693b-3b56-f152-b97f06dc5e75"
   },
   "source": [
    "## Evaluation, prediction, and analysis\n",
    "* MLP (Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "6100543b-7713-162c-852b-86dd7c96cb2c",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-34ad1f8ecefa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1168\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mcomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MLP\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" baseline\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mae' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of various combinations of multi-layer perceptrons\n",
    "\n",
    "#Import libraries for deep learning\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define baseline model\n",
    "def baseline(v):\n",
    "     # create model\n",
    "     model = Sequential()\n",
    "     model.add(Dense(v*(c-1), input_dim=v*(c-1), init='normal', activation='relu'))\n",
    "     model.add(Dense(1, init='normal'))\n",
    "     # Compile model\n",
    "     model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "     return model\n",
    "\n",
    "# define smaller model\n",
    "def smaller(v):\n",
    "     # create model\n",
    "     model = Sequential()\n",
    "     model.add(Dense(v*(c-1)/2, input_dim=v*(c-1), init='normal', activation='relu'))\n",
    "     model.add(Dense(1, init='normal', activation='relu'))\n",
    "     # Compile model\n",
    "     model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "     return model\n",
    "\n",
    "# define deeper model\n",
    "def deeper(v):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(v*(c-1), input_dim=v*(c-1), init='normal', activation='relu'))\n",
    " model.add(Dense(v*(c-1)/2, init='normal', activation='relu'))\n",
    " model.add(Dense(1, init='normal', activation='relu'))\n",
    " # Compile model\n",
    " model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    " return model\n",
    "\n",
    "# Optimize using dropout and decay\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "def dropout(v):\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(v*(c-1), input_dim=v*(c-1), init='normal', activation='relu',W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(v*(c-1)/2, init='normal', activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, init='normal', activation='relu'))\n",
    "    # Compile model\n",
    "    sgd = SGD(lr=0.1,momentum=0.9,decay=0.0,nesterov=False)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=sgd)\n",
    "    return model\n",
    "\n",
    "# define decay model\n",
    "def decay(v):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(v*(c-1), input_dim=v*(c-1), init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal', activation='relu'))\n",
    "    # Compile model\n",
    "    sgd = SGD(lr=0.1,momentum=0.8,decay=0.01,nesterov=False)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=sgd)\n",
    "    return model\n",
    "\n",
    "est_list = []\n",
    "#uncomment the below if you want to run the algo\n",
    "#est_list = [('MLP',baseline),('smaller',smaller),('deeper',deeper),('dropout',dropout),('decay',decay)]\n",
    "\n",
    "for name, est in est_list:\n",
    " \n",
    "    algo = name\n",
    "\n",
    "    #Accuracy of the model using all features\n",
    "    for m,i_cols_list in X_all:\n",
    "        model = KerasRegressor(build_fn=est, v=1, nb_epoch=10, verbose=0)\n",
    "        model.fit(X_train[:,i_cols_list],Y_train)\n",
    "        result = mean_absolute_error(numpy.expm1(Y_val), numpy.expm1(model.predict(X_val[:,i_cols_list])))\n",
    "        mae.append(result)\n",
    "        print(name + \" %s\" % result)\n",
    "        \n",
    "    comb.append(algo )\n",
    "\n",
    "if (len(est_list)==0):\n",
    "    mae.append(1168)\n",
    "    comb.append(\"MLP\" + \" baseline\" )    \n",
    "    \n",
    "##Set figure size\n",
    "#plt.rc(\"figure\", figsize=(25, 10))\n",
    "\n",
    "#Plot the MAE of all combinations\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(mae)\n",
    "#Set the tick names to names of combinations\n",
    "ax.set_xticks(range(len(comb)))\n",
    "ax.set_xticklabels(comb,rotation='vertical')\n",
    "#Plot the accuracy for all combinations\n",
    "plt.show()    \n",
    "\n",
    "#Best estimated performance is MLP=1168"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9c5ef128-af5a-7c4e-87be-85676139ef5b"
   },
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "a2f64707-4996-e4b2-11d7-41cefa618da1",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d9289adfa6eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make predictions using XGB as it gave the best estimated performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions using XGB as it gave the best estimated performance        \n",
    "\n",
    "X = numpy.concatenate((X_train,X_val),axis=0)\n",
    "del X_train\n",
    "del X_val\n",
    "Y = numpy.concatenate((Y_train,Y_val),axis=0)\n",
    "del Y_train\n",
    "del Y_val\n",
    "\n",
    "n_estimators = 1000\n",
    "\n",
    "#Best model definition\n",
    "best_model = XGBRegressor(n_estimators=n_estimators,seed=seed)\n",
    "best_model.fit(X,Y)\n",
    "del X\n",
    "del Y\n",
    "#Read test dataset\n",
    "dataset_test = pandas.read_csv(\"../input/test.csv\")\n",
    "#Drop unnecessary columns\n",
    "ID = dataset_test['id']\n",
    "dataset_test.drop('id',axis=1,inplace=True)\n",
    "\n",
    "#One hot encode all categorical attributes\n",
    "cats = []\n",
    "for i in range(0, split):\n",
    "    #Label encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(labels[i])\n",
    "    feature = label_encoder.transform(dataset_test.iloc[:,i])\n",
    "    feature = feature.reshape(dataset_test.shape[0], 1)\n",
    "    #One hot encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False,n_values=len(labels[i]))\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    cats.append(feature)\n",
    "\n",
    "# Make a 2D array from a list of 1D arrays\n",
    "encoded_cats = numpy.column_stack(cats)\n",
    "\n",
    "del cats\n",
    "\n",
    "#Concatenate encoded attributes with continuous attributes\n",
    "X_test = numpy.concatenate((encoded_cats,dataset_test.iloc[:,split:].values),axis=1)\n",
    "\n",
    "del encoded_cats\n",
    "del dataset_test\n",
    "\n",
    "#Make predictions using the best model\n",
    "predictions = numpy.expm1(best_model.predict(X_test))\n",
    "del X_test\n",
    "# Write submissions to output file in the correct format\n",
    "with open(\"submission.csv\", \"w\") as subfile:\n",
    "    subfile.write(\"id,loss\\n\")\n",
    "    for i, pred in enumerate(list(predictions)):\n",
    "        subfile.write(\"%s,%s\\n\"%(ID[i],pred))"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 454,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
