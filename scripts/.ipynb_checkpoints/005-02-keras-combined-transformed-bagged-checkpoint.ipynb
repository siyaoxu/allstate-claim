{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "## import libraries\n",
    "\n",
    "import subprocess\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = 200\n",
    "COMB_FEATURE = 'cat80,cat87,cat57,cat12,cat79,cat10,cat7,cat89,cat2,cat72,' \\\n",
    "               'cat81,cat11,cat1,cat13,cat9,cat3,cat16,cat90,cat23,cat36,' \\\n",
    "               'cat73,cat103,cat40,cat28,cat111,cat6,cat76,cat50,cat5,' \\\n",
    "               'cat4,cat14,cat38,cat24,cat82,cat25'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(charcode):\n",
    "    r = 0\n",
    "    ln = len(str(charcode))\n",
    "    for i in range(ln):\n",
    "        r += (ord(str(charcode)[i]) - ord('A') + 1) * 26 ** (ln - i - 1)\n",
    "    return r\n",
    "\n",
    "fair_constant = 0.7\n",
    "def fair_obj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    x = (preds - labels)\n",
    "    den = abs(x) + fair_constant\n",
    "    grad = fair_constant * x / (den)\n",
    "    hess = fair_constant * fair_constant / (den * den)\n",
    "    return grad, hess\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y)-shift,\n",
    "                                      np.exp(yhat)-shift)\n",
    "def mungeskewed(train, test, numeric_feats):\n",
    "    ntrain = train.shape[0]\n",
    "    test['loss'] = 0\n",
    "    train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.25]\n",
    "    skewed_feats = skewed_feats.index\n",
    "\n",
    "    for feats in skewed_feats:\n",
    "        train_test[feats] = train_test[feats] + 1\n",
    "        train_test[feats], lam = boxcox(train_test[feats])\n",
    "    return train_test, ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[1245, 134802, 62926, 9302, 56409, 185105, 129365, 165158, 30177, 127591]\n",
      "\n",
      "('Combining Columns:', 'cat80_cat87')\n",
      "('Combining Columns:', 'cat80_cat57')\n",
      "('Combining Columns:', 'cat80_cat12')\n",
      "('Combining Columns:', 'cat80_cat79')\n",
      "('Combining Columns:', 'cat80_cat10')\n",
      "('Combining Columns:', 'cat80_cat7')\n",
      "('Combining Columns:', 'cat80_cat89')\n",
      "('Combining Columns:', 'cat80_cat2')\n",
      "('Combining Columns:', 'cat80_cat72')\n",
      "('Combining Columns:', 'cat80_cat81')\n",
      "('Combining Columns:', 'cat80_cat11')\n",
      "('Combining Columns:', 'cat80_cat1')\n",
      "('Combining Columns:', 'cat80_cat13')\n",
      "('Combining Columns:', 'cat80_cat9')\n",
      "('Combining Columns:', 'cat80_cat3')\n",
      "('Combining Columns:', 'cat80_cat16')\n",
      "('Combining Columns:', 'cat80_cat90')\n",
      "('Combining Columns:', 'cat80_cat23')\n",
      "('Combining Columns:', 'cat80_cat36')\n",
      "('Combining Columns:', 'cat80_cat73')\n",
      "('Combining Columns:', 'cat80_cat103')\n",
      "('Combining Columns:', 'cat80_cat40')\n",
      "('Combining Columns:', 'cat80_cat28')\n",
      "('Combining Columns:', 'cat80_cat111')\n",
      "('Combining Columns:', 'cat80_cat6')\n",
      "('Combining Columns:', 'cat80_cat76')\n",
      "('Combining Columns:', 'cat80_cat50')\n",
      "('Combining Columns:', 'cat80_cat5')\n",
      "('Combining Columns:', 'cat80_cat4')\n",
      "('Combining Columns:', 'cat80_cat14')\n",
      "('Combining Columns:', 'cat80_cat38')\n",
      "('Combining Columns:', 'cat80_cat24')\n",
      "('Combining Columns:', 'cat80_cat82')\n",
      "('Combining Columns:', 'cat80_cat25')\n",
      "('Combining Columns:', 'cat87_cat57')\n",
      "('Combining Columns:', 'cat87_cat12')\n",
      "('Combining Columns:', 'cat87_cat79')\n",
      "('Combining Columns:', 'cat87_cat10')\n",
      "('Combining Columns:', 'cat87_cat7')\n",
      "('Combining Columns:', 'cat87_cat89')\n",
      "('Combining Columns:', 'cat87_cat2')\n",
      "('Combining Columns:', 'cat87_cat72')\n",
      "('Combining Columns:', 'cat87_cat81')\n",
      "('Combining Columns:', 'cat87_cat11')\n",
      "('Combining Columns:', 'cat87_cat1')\n",
      "('Combining Columns:', 'cat87_cat13')\n",
      "('Combining Columns:', 'cat87_cat9')\n",
      "('Combining Columns:', 'cat87_cat3')\n",
      "('Combining Columns:', 'cat87_cat16')\n",
      "('Combining Columns:', 'cat87_cat90')\n",
      "('Combining Columns:', 'cat87_cat23')\n",
      "('Combining Columns:', 'cat87_cat36')\n",
      "('Combining Columns:', 'cat87_cat73')\n",
      "('Combining Columns:', 'cat87_cat103')\n",
      "('Combining Columns:', 'cat87_cat40')\n",
      "('Combining Columns:', 'cat87_cat28')\n",
      "('Combining Columns:', 'cat87_cat111')\n",
      "('Combining Columns:', 'cat87_cat6')\n",
      "('Combining Columns:', 'cat87_cat76')\n",
      "('Combining Columns:', 'cat87_cat50')\n",
      "('Combining Columns:', 'cat87_cat5')\n",
      "('Combining Columns:', 'cat87_cat4')\n",
      "('Combining Columns:', 'cat87_cat14')\n",
      "('Combining Columns:', 'cat87_cat38')\n",
      "('Combining Columns:', 'cat87_cat24')\n",
      "('Combining Columns:', 'cat87_cat82')\n",
      "('Combining Columns:', 'cat87_cat25')\n",
      "('Combining Columns:', 'cat57_cat12')\n",
      "('Combining Columns:', 'cat57_cat79')\n",
      "('Combining Columns:', 'cat57_cat10')\n",
      "('Combining Columns:', 'cat57_cat7')\n",
      "('Combining Columns:', 'cat57_cat89')\n",
      "('Combining Columns:', 'cat57_cat2')\n",
      "('Combining Columns:', 'cat57_cat72')\n",
      "('Combining Columns:', 'cat57_cat81')\n",
      "('Combining Columns:', 'cat57_cat11')\n",
      "('Combining Columns:', 'cat57_cat1')\n",
      "('Combining Columns:', 'cat57_cat13')\n",
      "('Combining Columns:', 'cat57_cat9')\n",
      "('Combining Columns:', 'cat57_cat3')\n",
      "('Combining Columns:', 'cat57_cat16')\n",
      "('Combining Columns:', 'cat57_cat90')\n",
      "('Combining Columns:', 'cat57_cat23')\n",
      "('Combining Columns:', 'cat57_cat36')\n",
      "('Combining Columns:', 'cat57_cat73')\n",
      "('Combining Columns:', 'cat57_cat103')\n",
      "('Combining Columns:', 'cat57_cat40')\n",
      "('Combining Columns:', 'cat57_cat28')\n",
      "('Combining Columns:', 'cat57_cat111')\n",
      "('Combining Columns:', 'cat57_cat6')\n",
      "('Combining Columns:', 'cat57_cat76')\n",
      "('Combining Columns:', 'cat57_cat50')\n",
      "('Combining Columns:', 'cat57_cat5')\n",
      "('Combining Columns:', 'cat57_cat4')\n",
      "('Combining Columns:', 'cat57_cat14')\n",
      "('Combining Columns:', 'cat57_cat38')\n",
      "('Combining Columns:', 'cat57_cat24')\n",
      "('Combining Columns:', 'cat57_cat82')\n",
      "('Combining Columns:', 'cat57_cat25')\n",
      "('Combining Columns:', 'cat12_cat79')\n",
      "('Combining Columns:', 'cat12_cat10')\n",
      "('Combining Columns:', 'cat12_cat7')\n",
      "('Combining Columns:', 'cat12_cat89')\n",
      "('Combining Columns:', 'cat12_cat2')\n",
      "('Combining Columns:', 'cat12_cat72')\n",
      "('Combining Columns:', 'cat12_cat81')\n",
      "('Combining Columns:', 'cat12_cat11')\n",
      "('Combining Columns:', 'cat12_cat1')\n",
      "('Combining Columns:', 'cat12_cat13')\n",
      "('Combining Columns:', 'cat12_cat9')\n",
      "('Combining Columns:', 'cat12_cat3')\n",
      "('Combining Columns:', 'cat12_cat16')\n",
      "('Combining Columns:', 'cat12_cat90')\n",
      "('Combining Columns:', 'cat12_cat23')\n",
      "('Combining Columns:', 'cat12_cat36')\n",
      "('Combining Columns:', 'cat12_cat73')\n",
      "('Combining Columns:', 'cat12_cat103')\n",
      "('Combining Columns:', 'cat12_cat40')\n",
      "('Combining Columns:', 'cat12_cat28')\n",
      "('Combining Columns:', 'cat12_cat111')\n",
      "('Combining Columns:', 'cat12_cat6')\n",
      "('Combining Columns:', 'cat12_cat76')\n",
      "('Combining Columns:', 'cat12_cat50')\n",
      "('Combining Columns:', 'cat12_cat5')\n",
      "('Combining Columns:', 'cat12_cat4')\n",
      "('Combining Columns:', 'cat12_cat14')\n",
      "('Combining Columns:', 'cat12_cat38')\n",
      "('Combining Columns:', 'cat12_cat24')\n",
      "('Combining Columns:', 'cat12_cat82')\n",
      "('Combining Columns:', 'cat12_cat25')\n",
      "('Combining Columns:', 'cat79_cat10')\n",
      "('Combining Columns:', 'cat79_cat7')\n",
      "('Combining Columns:', 'cat79_cat89')\n",
      "('Combining Columns:', 'cat79_cat2')\n",
      "('Combining Columns:', 'cat79_cat72')\n",
      "('Combining Columns:', 'cat79_cat81')\n",
      "('Combining Columns:', 'cat79_cat11')\n",
      "('Combining Columns:', 'cat79_cat1')\n",
      "('Combining Columns:', 'cat79_cat13')\n",
      "('Combining Columns:', 'cat79_cat9')\n",
      "('Combining Columns:', 'cat79_cat3')\n",
      "('Combining Columns:', 'cat79_cat16')\n",
      "('Combining Columns:', 'cat79_cat90')\n",
      "('Combining Columns:', 'cat79_cat23')\n",
      "('Combining Columns:', 'cat79_cat36')\n",
      "('Combining Columns:', 'cat79_cat73')\n",
      "('Combining Columns:', 'cat79_cat103')\n",
      "('Combining Columns:', 'cat79_cat40')\n",
      "('Combining Columns:', 'cat79_cat28')\n",
      "('Combining Columns:', 'cat79_cat111')\n",
      "('Combining Columns:', 'cat79_cat6')\n",
      "('Combining Columns:', 'cat79_cat76')\n",
      "('Combining Columns:', 'cat79_cat50')\n",
      "('Combining Columns:', 'cat79_cat5')\n",
      "('Combining Columns:', 'cat79_cat4')\n",
      "('Combining Columns:', 'cat79_cat14')\n",
      "('Combining Columns:', 'cat79_cat38')\n",
      "('Combining Columns:', 'cat79_cat24')\n",
      "('Combining Columns:', 'cat79_cat82')\n",
      "('Combining Columns:', 'cat79_cat25')\n",
      "('Combining Columns:', 'cat10_cat7')\n",
      "('Combining Columns:', 'cat10_cat89')\n",
      "('Combining Columns:', 'cat10_cat2')\n",
      "('Combining Columns:', 'cat10_cat72')\n",
      "('Combining Columns:', 'cat10_cat81')\n",
      "('Combining Columns:', 'cat10_cat11')\n",
      "('Combining Columns:', 'cat10_cat1')\n",
      "('Combining Columns:', 'cat10_cat13')\n",
      "('Combining Columns:', 'cat10_cat9')\n",
      "('Combining Columns:', 'cat10_cat3')\n",
      "('Combining Columns:', 'cat10_cat16')\n",
      "('Combining Columns:', 'cat10_cat90')\n",
      "('Combining Columns:', 'cat10_cat23')\n",
      "('Combining Columns:', 'cat10_cat36')\n",
      "('Combining Columns:', 'cat10_cat73')\n",
      "('Combining Columns:', 'cat10_cat103')\n",
      "('Combining Columns:', 'cat10_cat40')\n",
      "('Combining Columns:', 'cat10_cat28')\n",
      "('Combining Columns:', 'cat10_cat111')\n",
      "('Combining Columns:', 'cat10_cat6')\n",
      "('Combining Columns:', 'cat10_cat76')\n",
      "('Combining Columns:', 'cat10_cat50')\n",
      "('Combining Columns:', 'cat10_cat5')\n",
      "('Combining Columns:', 'cat10_cat4')\n",
      "('Combining Columns:', 'cat10_cat14')\n",
      "('Combining Columns:', 'cat10_cat38')\n",
      "('Combining Columns:', 'cat10_cat24')\n",
      "('Combining Columns:', 'cat10_cat82')\n",
      "('Combining Columns:', 'cat10_cat25')\n",
      "('Combining Columns:', 'cat7_cat89')\n",
      "('Combining Columns:', 'cat7_cat2')\n",
      "('Combining Columns:', 'cat7_cat72')\n",
      "('Combining Columns:', 'cat7_cat81')\n",
      "('Combining Columns:', 'cat7_cat11')\n",
      "('Combining Columns:', 'cat7_cat1')\n",
      "('Combining Columns:', 'cat7_cat13')\n",
      "('Combining Columns:', 'cat7_cat9')\n",
      "('Combining Columns:', 'cat7_cat3')\n",
      "('Combining Columns:', 'cat7_cat16')\n",
      "('Combining Columns:', 'cat7_cat90')\n",
      "('Combining Columns:', 'cat7_cat23')\n",
      "('Combining Columns:', 'cat7_cat36')\n",
      "('Combining Columns:', 'cat7_cat73')\n",
      "('Combining Columns:', 'cat7_cat103')\n",
      "('Combining Columns:', 'cat7_cat40')\n",
      "('Combining Columns:', 'cat7_cat28')\n",
      "('Combining Columns:', 'cat7_cat111')\n",
      "('Combining Columns:', 'cat7_cat6')\n",
      "('Combining Columns:', 'cat7_cat76')\n",
      "('Combining Columns:', 'cat7_cat50')\n",
      "('Combining Columns:', 'cat7_cat5')\n",
      "('Combining Columns:', 'cat7_cat4')\n",
      "('Combining Columns:', 'cat7_cat14')\n",
      "('Combining Columns:', 'cat7_cat38')\n",
      "('Combining Columns:', 'cat7_cat24')\n",
      "('Combining Columns:', 'cat7_cat82')\n",
      "('Combining Columns:', 'cat7_cat25')\n",
      "('Combining Columns:', 'cat89_cat2')\n",
      "('Combining Columns:', 'cat89_cat72')\n",
      "('Combining Columns:', 'cat89_cat81')\n",
      "('Combining Columns:', 'cat89_cat11')\n",
      "('Combining Columns:', 'cat89_cat1')\n",
      "('Combining Columns:', 'cat89_cat13')\n",
      "('Combining Columns:', 'cat89_cat9')\n",
      "('Combining Columns:', 'cat89_cat3')\n",
      "('Combining Columns:', 'cat89_cat16')\n",
      "('Combining Columns:', 'cat89_cat90')\n",
      "('Combining Columns:', 'cat89_cat23')\n",
      "('Combining Columns:', 'cat89_cat36')\n",
      "('Combining Columns:', 'cat89_cat73')\n",
      "('Combining Columns:', 'cat89_cat103')\n",
      "('Combining Columns:', 'cat89_cat40')\n",
      "('Combining Columns:', 'cat89_cat28')\n",
      "('Combining Columns:', 'cat89_cat111')\n",
      "('Combining Columns:', 'cat89_cat6')\n",
      "('Combining Columns:', 'cat89_cat76')\n",
      "('Combining Columns:', 'cat89_cat50')\n",
      "('Combining Columns:', 'cat89_cat5')\n",
      "('Combining Columns:', 'cat89_cat4')\n",
      "('Combining Columns:', 'cat89_cat14')\n",
      "('Combining Columns:', 'cat89_cat38')\n",
      "('Combining Columns:', 'cat89_cat24')\n",
      "('Combining Columns:', 'cat89_cat82')\n",
      "('Combining Columns:', 'cat89_cat25')\n"
     ]
    }
   ],
   "source": [
    "print('\\nStarted')\n",
    "directory = '../input/'\n",
    "train = pd.read_csv(directory + 'train.csv')\n",
    "# train = train.sample(n=1000,random_state = 0,replace=True)\n",
    "index0 = list(train.index)\n",
    "index = [x for x in index0]\n",
    "print index[0:10]\n",
    "np.random.shuffle(index)\n",
    "print index[0:10]\n",
    "train = train.iloc[index]\n",
    "\n",
    "test = pd.read_csv(directory + 'test.csv')\n",
    "\n",
    "numeric_feats = [x for x in train.columns[1:-1] if 'cont' in x]\n",
    "categorical_feats = [x for x in train.columns[1:-1] if 'cat' in x]\n",
    "train_test, ntrain = mungeskewed(train, test, numeric_feats)\n",
    "\n",
    "# taken from Vladimir's script (https://www.kaggle.com/iglovikov/allstate-claims-severity/xgb-1114)\n",
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = remove_train.union(remove_test)\n",
    "\n",
    "\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "\n",
    "        train_test[column] = train_test[column].apply(lambda x: filter_cat(x), 1)\n",
    "\n",
    "# taken from Ali's script (https://www.kaggle.com/aliajouz/allstate-claims-severity/singel-model-lb-1117)\n",
    "train_test[\"cont1\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont1\"]))\n",
    "train_test[\"cont4\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont4\"]))\n",
    "train_test[\"cont5\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont5\"]))\n",
    "train_test[\"cont8\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont8\"]))\n",
    "train_test[\"cont10\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont10\"]))\n",
    "train_test[\"cont11\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont11\"]))\n",
    "train_test[\"cont12\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont12\"]))\n",
    "\n",
    "train_test[\"cont6\"] = np.log(preprocessing.minmax_scale(train_test[\"cont6\"]) + 0000.1)\n",
    "train_test[\"cont7\"] = np.log(preprocessing.minmax_scale(train_test[\"cont7\"]) + 0000.1)\n",
    "train_test[\"cont9\"] = np.log(preprocessing.minmax_scale(train_test[\"cont9\"]) + 0000.1)\n",
    "train_test[\"cont13\"] = np.log(preprocessing.minmax_scale(train_test[\"cont13\"]) + 0000.1)\n",
    "train_test[\"cont14\"] = (np.maximum(train_test[\"cont14\"] - 0.179722, 0) / 0.665122) ** 0.25\n",
    "\n",
    "print('')\n",
    "for comb in itertools.combinations(COMB_FEATURE, 2):\n",
    "    feat = comb[0] + \"_\" + comb[1]\n",
    "    train_test[feat] = train_test[comb[0]] + train_test[comb[1]]\n",
    "    train_test[feat] = train_test[feat].apply(encode)\n",
    "    print('Combining Columns:', feat)\n",
    "\n",
    "print('')\n",
    "for col in categorical_feats:\n",
    "    print('Analyzing Column:', col)\n",
    "    train_test[col] = train_test[col].apply(encode)\n",
    "\n",
    "print(train_test[categorical_feats])\n",
    "\n",
    "# ss = StandardScaler()\n",
    "# train_test[numeric_feats] = \\\n",
    "#     ss.fit_transform(train_test[numeric_feats].values)\n",
    "\n",
    "## Preprocessing and transforming to sparse data\n",
    "sparse_data = []\n",
    "tr_te = train_test\n",
    "\n",
    "f_cat = [f for f in tr_te.columns if 'cat' in f]\n",
    "for f in f_cat:\n",
    "    dummy = pd.get_dummies(tr_te[f].astype('category'))\n",
    "    tmp = csr_matrix(dummy)\n",
    "    sparse_data.append(tmp)\n",
    "\n",
    "f_num = numeric_feats\n",
    "scaler = StandardScaler()\n",
    "tmp = csr_matrix(scaler.fit_transform(tr_te[f_num]))\n",
    "sparse_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## sparse train and test data\n",
    "xtr_te = hstack(sparse_data, format = 'csr')\n",
    "\n",
    "train = train_test.iloc[:ntrain, :].copy()\n",
    "test = train_test.iloc[ntrain:, :].copy()\n",
    "\n",
    "print('\\nMedian Loss:', train.loss.median())\n",
    "print('Mean Loss:', train.loss.mean())\n",
    "\n",
    "ids = pd.read_csv('../input/test.csv')['id']\n",
    "\n",
    "xtrain = xtr_te[:ntrain, :]\n",
    "xtest = xtr_te[ntrain:, :]\n",
    "y = np.log(train['loss'].values + shift)\n",
    "print('Dim train', xtrain.shape)\n",
    "print('Dim test', xtest.shape)\n",
    "print('Dim train y ', y.shape)\n",
    "# xtrain = train.drop(['loss','id'], axis=1)\n",
    "# test_x = test.drop(['loss','id'], axis=1)\n",
    "# del sparse, test_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ids = pd.read_csv('../input/test.csv')['id']\n",
    "# # train_y = np.log(train['loss'] + shift)\n",
    "# # train_x = train.drop(['loss','id'], axis=1)\n",
    "# # test_x = test.drop(['loss','id'], axis=1)\n",
    "# y = np.log(train['loss'] + shift)\n",
    "# y = np.log(train['loss'].values+shift)\n",
    "# xtrain = csr_matrix(train.drop(['loss','id'], axis=1).values)\n",
    "# xtest = csr_matrix(test.drop(['loss','id'], axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Batch generators ##################################################################################################################################\n",
    "\n",
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator (https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0\n",
    "\n",
    "## neural net\n",
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(400, input_dim = xtrain.shape[1], init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "        \n",
    "    model.add(Dense(200, init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(50, init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, init = 'he_normal'))\n",
    "    model.compile(loss = 'mae', optimizer = 'adadelta')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## cv-folds\n",
    "nfolds = 5\n",
    "folds = KFold(len(y), n_folds = nfolds, shuffle = True, random_state = 111)\n",
    "# folds = KFold(xtrain.shape[0], n_folds=nfolds, shuffle = True, random_state = 111)\n",
    "\n",
    "## train models\n",
    "i = 0\n",
    "nbags = 10\n",
    "nepochs = 55\n",
    "pred_oob = np.zeros(xtrain.shape[0])\n",
    "pred_test = np.zeros(xtest.shape[0])\n",
    "\n",
    "for (inTr, inTe) in folds:\n",
    "    xtr = xtrain[inTr]\n",
    "    ytr = y[inTr]\n",
    "    xte = xtrain[inTe]\n",
    "    yte = y[inTe]\n",
    "    pred = np.zeros(xte.shape[0])\n",
    "    for j in range(nbags):\n",
    "        model = nn_model()\n",
    "        fit = model.fit_generator(generator = batch_generator(xtr, ytr, 128, True),\n",
    "                                  nb_epoch = nepochs,\n",
    "                                  samples_per_epoch = xtr.shape[0],\n",
    "                                  verbose = 0)\n",
    "        pred += np.exp(model.predict_generator(generator = batch_generatorp(xte, 800, False), val_samples = xte.shape[0])[:,0])-shift\n",
    "        pred_test += np.exp(model.predict_generator(generator = batch_generatorp(xtest, 800, False), val_samples = xtest.shape[0])[:,0])-shift\n",
    "    pred /= nbags\n",
    "    pred_oob[inTe] = pred\n",
    "    score = mean_absolute_error(np.exp(yte)-shift, pred)\n",
    "    i += 1\n",
    "    print('Fold ', i, '- MAE:', score)\n",
    "\n",
    "print('Total - MAE:', mean_absolute_error(np.exp(y)-shift, pred_oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train predictions\n",
    "# df = pd.DataFrame({'id': id_train, 'loss': pred_oob})\n",
    "# df.to_csv('../output/keras_preds_oob.csv', index = False)\n",
    "\n",
    "## test predictions\n",
    "pred_test /= (nfolds*nbags)\n",
    "df = pd.DataFrame({'id': id_test, 'loss': pred_test})\n",
    "df.to_csv('../output/keras_combined_transformed_bagging_5folds.csv', index = False)\n",
    "joblib.dump(pred_oob, '../output/keras_combined_transformed_5folds_pred_on_trian.sav', compress=9)\n",
    "joblib.dump(y, '../output/keras_combined_transformed_5folds_pred_trian_y.sav', compress=9)\n",
    "joblib.dump(index0, '../output/keras_combined_transformed_5folds_pred_on_trian_index0.sav', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
