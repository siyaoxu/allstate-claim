{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy as sp\n",
    "\n",
    "# from scipy.special import erfinv\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_raw = pd.read_csv('../input/train.csv')\n",
    "# data_train_raw = data_train_raw.sample(frac=0.01, random_state=0)\n",
    "data_test_raw = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188318, 132)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ylog=np.log1p(data_train_raw['loss'])\n",
    "# ymean=ylog.mean()\n",
    "# ystd=ylog.std()\n",
    "ymean=ylog.min()\n",
    "ystd=ylog.max()\n",
    "data_train_raw['loss_g']=(ylog-ymean)/ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # clean outliers in training data\n",
    "# lossMean = data_train_raw['loss_g'].mean()\n",
    "# lossStd = data_train_raw['loss_g'].std()\n",
    "# print('Mean of log1py: {}'.format(lossMean))\n",
    "# print('Std of log1py: {}'.format(lossStd))\n",
    "# lbound = lossMean-3.0*lossStd\n",
    "# ubound = lossMean+3.0*lossStd\n",
    "# print('Lower clipping bound: {}\\nUpper clipping bound: {}'.format(lbound, ubound))\n",
    "# data_train_raw = data_train_raw[(data_train_raw['loss_g']>=lbound) & (data_train_raw['loss_g']<=ubound)]\n",
    "# print('Shape of cleaned data: {}'.format(data_train_raw.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ToUniform(y):\n",
    "    z = norm.cdf(-y/np.sqrt(2))\n",
    "    return z\n",
    "def UniformToGauss(z):\n",
    "    return -np.sqrt(2)*norm.ppf(z)*ystd+ymean\n",
    "# def BackToOriginal(z):\n",
    "#     return np.exp(UniformToGauss(z))\n",
    "\n",
    "data_train_raw['loss_u']=ToUniform(data_train_raw['loss_g'])\n",
    "\n",
    "def lossRestore(logloss, ymean, ystd):\n",
    "    loss = np.expm1(logloss*ystd+ymean)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4cAAAEKCAYAAAChXCC5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b39b58e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(data_train_raw['loss'],100)\n",
    "plt.title('loss');\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(ylog,100)\n",
    "plt.title('log(loss) - Gauss');\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(data_train_raw['loss_g'],100)\n",
    "plt.title('Normal');\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(lossRestore(data_train_raw['loss_g'],ymean,ystd),100)\n",
    "plt.title('Normal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation - labeling encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDf has features from the raw data:\n",
      "Index([u'cat1', u'cat2', u'cat3', u'cat4', u'cat5', u'cat6', u'cat7', u'cat8',\n",
      "       u'cat9', u'cat10',\n",
      "       ...\n",
      "       u'cont5', u'cont6', u'cont7', u'cont8', u'cont9', u'cont10', u'cont11',\n",
      "       u'cont12', u'cont13', u'cont14'],\n",
      "      dtype='object', length=130)\n",
      "testDf has features from the raw data:\n",
      "Index([u'cat1', u'cat2', u'cat3', u'cat4', u'cat5', u'cat6', u'cat7', u'cat8',\n",
      "       u'cat9', u'cat10',\n",
      "       ...\n",
      "       u'cont5', u'cont6', u'cont7', u'cont8', u'cont9', u'cont10', u'cont11',\n",
      "       u'cont12', u'cont13', u'cont14'],\n",
      "      dtype='object', length=130)\n"
     ]
    }
   ],
   "source": [
    "# save label in a seperate serie\n",
    "labelSs = data_train_raw['loss_g'] \n",
    "trainDf = data_train_raw.drop(['id','loss','loss_g','loss_u'],axis=1)\n",
    "subId = data_test_raw['id']\n",
    "testDf = data_test_raw.drop(['id'],axis=1)\n",
    "\n",
    "print('trainDf has features from the raw data:\\n{}'.format(trainDf.columns))\n",
    "print('testDf has features from the raw data:\\n{}'.format(testDf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the stacked data's dimension are:\n",
      "(313500, 130)\n",
      "(313500, 116) of which are categorical\n",
      "(313500, 14) of which are continuous\n"
     ]
    }
   ],
   "source": [
    "dataAll = pd.concat([trainDf,testDf])\n",
    "dataCatAll = dataAll.select_dtypes(include=['object'])\n",
    "dataFltAll = dataAll.select_dtypes(include=['float64'])\n",
    "print('the stacked data\\'s dimension are:\\n{}'.format(dataAll.shape))\n",
    "print('{} of which are categorical'.format(dataCatAll.shape))\n",
    "print('{} of which are continuous'.format(dataFltAll.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>BU</td>\n",
       "      <td>BC</td>\n",
       "      <td>C</td>\n",
       "      <td>AS</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CQ</td>\n",
       "      <td>A</td>\n",
       "      <td>AV</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>AB</td>\n",
       "      <td>DK</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>AF</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>GK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CS</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>AE</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>CK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10  ...   cat107 cat108  \\\n",
       "0    A    B    A    B    A    A    A    A    B     A  ...        J      G   \n",
       "1    A    B    A    A    A    A    A    A    B     B  ...        K      K   \n",
       "2    A    B    A    A    B    A    A    A    B     B  ...        F      A   \n",
       "3    B    B    A    B    A    A    A    A    B     A  ...        K      K   \n",
       "4    A    B    A    B    A    A    A    A    B     B  ...        G      B   \n",
       "\n",
       "  cat109 cat110 cat111 cat112 cat113 cat114 cat115 cat116  \n",
       "0     BU     BC      C     AS      S      A      O     LB  \n",
       "1     BI     CQ      A     AV     BM      A      O     DP  \n",
       "2     AB     DK      A      C     AF      A      I     GK  \n",
       "3     BI     CS      C      N     AE      A      O     DJ  \n",
       "4      H      C      C      Y     BM      A      K     CK  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCatAll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>...</td>\n",
       "      <td>0J</td>\n",
       "      <td>0G</td>\n",
       "      <td>BU</td>\n",
       "      <td>BC</td>\n",
       "      <td>0C</td>\n",
       "      <td>AS</td>\n",
       "      <td>0S</td>\n",
       "      <td>0A</td>\n",
       "      <td>0O</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0B</td>\n",
       "      <td>...</td>\n",
       "      <td>0K</td>\n",
       "      <td>0K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CQ</td>\n",
       "      <td>0A</td>\n",
       "      <td>AV</td>\n",
       "      <td>BM</td>\n",
       "      <td>0A</td>\n",
       "      <td>0O</td>\n",
       "      <td>DP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0B</td>\n",
       "      <td>...</td>\n",
       "      <td>0F</td>\n",
       "      <td>0A</td>\n",
       "      <td>AB</td>\n",
       "      <td>DK</td>\n",
       "      <td>0A</td>\n",
       "      <td>0C</td>\n",
       "      <td>AF</td>\n",
       "      <td>0A</td>\n",
       "      <td>0I</td>\n",
       "      <td>GK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0B</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>...</td>\n",
       "      <td>0K</td>\n",
       "      <td>0K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CS</td>\n",
       "      <td>0C</td>\n",
       "      <td>0N</td>\n",
       "      <td>AE</td>\n",
       "      <td>0A</td>\n",
       "      <td>0O</td>\n",
       "      <td>DJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0B</td>\n",
       "      <td>...</td>\n",
       "      <td>0G</td>\n",
       "      <td>0B</td>\n",
       "      <td>0H</td>\n",
       "      <td>0C</td>\n",
       "      <td>0C</td>\n",
       "      <td>0Y</td>\n",
       "      <td>BM</td>\n",
       "      <td>0A</td>\n",
       "      <td>0K</td>\n",
       "      <td>CK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10  ...   cat107 cat108  \\\n",
       "0   0A   0B   0A   0B   0A   0A   0A   0A   0B    0A  ...       0J     0G   \n",
       "1   0A   0B   0A   0A   0A   0A   0A   0A   0B    0B  ...       0K     0K   \n",
       "2   0A   0B   0A   0A   0B   0A   0A   0A   0B    0B  ...       0F     0A   \n",
       "3   0B   0B   0A   0B   0A   0A   0A   0A   0B    0A  ...       0K     0K   \n",
       "4   0A   0B   0A   0B   0A   0A   0A   0A   0B    0B  ...       0G     0B   \n",
       "\n",
       "  cat109 cat110 cat111 cat112 cat113 cat114 cat115 cat116  \n",
       "0     BU     BC     0C     AS     0S     0A     0O     LB  \n",
       "1     BI     CQ     0A     AV     BM     0A     0O     DP  \n",
       "2     AB     DK     0A     0C     AF     0A     0I     GK  \n",
       "3     BI     CS     0C     0N     AE     0A     0O     DJ  \n",
       "4     0H     0C     0C     0Y     BM     0A     0K     CK  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LevelList = {'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z'}\n",
    "def LetterRep(x,LevelList):\n",
    "    if x in LevelList:\n",
    "        x = '0'+x\n",
    "    return x\n",
    "        \n",
    "dataCatAll = dataCatAll.applymap(lambda x: LetterRep(x,LevelList))\n",
    "dataCatAll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat99</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat102</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat99  cat100  cat101  cat102  cat103  cat104  cat105  cat106  cat107  \\\n",
       "0     15       1       6       0       0       8       4       6       9   \n",
       "1     15      11       5       0       0       4       4       8      10   \n",
       "2      1      11      14       0       1       4       5       7       5   \n",
       "3     15       8       3       0       0       4       4       8      10   \n",
       "4     12       5       9       0       0       3       4      10       6   \n",
       "\n",
       "   cat108  cat109  cat110  cat111  cat112  cat113  cat114  cat115  cat116  \n",
       "0       6      68      49       2      43      17       0      14     300  \n",
       "1      10      56      87       0      46      60       0      14     114  \n",
       "2       0      25     106       0       2      28       0       8     184  \n",
       "3      10      56      89       2      13      27       0      14     108  \n",
       "4       1       7       2       2      24      60       0      10      84  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dataCatAll.columns[98:]\n",
    "dataCatAll_2 = dataCatAll[features]\n",
    "cats = [feature for feature in features if feature.startswith('cat')]\n",
    "for feat in cats:\n",
    "    dataCatAll_2[feat] = pd.factorize(dataCatAll_2[feat], sort=True)[0]\n",
    "dataCatAll_2.head()\n",
    "# le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat89</th>\n",
       "      <th>cat90</th>\n",
       "      <th>cat91</th>\n",
       "      <th>cat92</th>\n",
       "      <th>cat93</th>\n",
       "      <th>cat94</th>\n",
       "      <th>cat95</th>\n",
       "      <th>cat96</th>\n",
       "      <th>cat97</th>\n",
       "      <th>cat98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>...</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0D</td>\n",
       "      <td>0B</td>\n",
       "      <td>0C</td>\n",
       "      <td>0E</td>\n",
       "      <td>0A</td>\n",
       "      <td>0C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0B</td>\n",
       "      <td>...</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0D</td>\n",
       "      <td>0D</td>\n",
       "      <td>0C</td>\n",
       "      <td>0E</td>\n",
       "      <td>0E</td>\n",
       "      <td>0D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0B</td>\n",
       "      <td>...</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0D</td>\n",
       "      <td>0D</td>\n",
       "      <td>0C</td>\n",
       "      <td>0E</td>\n",
       "      <td>0E</td>\n",
       "      <td>0A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0B</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>...</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0D</td>\n",
       "      <td>0D</td>\n",
       "      <td>0C</td>\n",
       "      <td>0E</td>\n",
       "      <td>0E</td>\n",
       "      <td>0D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0B</td>\n",
       "      <td>...</td>\n",
       "      <td>0A</td>\n",
       "      <td>0A</td>\n",
       "      <td>0B</td>\n",
       "      <td>0H</td>\n",
       "      <td>0D</td>\n",
       "      <td>0B</td>\n",
       "      <td>0D</td>\n",
       "      <td>0E</td>\n",
       "      <td>0E</td>\n",
       "      <td>0A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10  ...  cat89 cat90 cat91  \\\n",
       "0   0A   0B   0A   0B   0A   0A   0A   0A   0B    0A  ...     0A    0A    0A   \n",
       "1   0A   0B   0A   0A   0A   0A   0A   0A   0B    0B  ...     0A    0A    0A   \n",
       "2   0A   0B   0A   0A   0B   0A   0A   0A   0B    0B  ...     0A    0A    0A   \n",
       "3   0B   0B   0A   0B   0A   0A   0A   0A   0B    0A  ...     0A    0A    0A   \n",
       "4   0A   0B   0A   0B   0A   0A   0A   0A   0B    0B  ...     0A    0A    0B   \n",
       "\n",
       "  cat92 cat93 cat94 cat95 cat96 cat97 cat98  \n",
       "0    0A    0D    0B    0C    0E    0A    0C  \n",
       "1    0A    0D    0D    0C    0E    0E    0D  \n",
       "2    0A    0D    0D    0C    0E    0E    0A  \n",
       "3    0A    0D    0D    0C    0E    0E    0D  \n",
       "4    0H    0D    0B    0D    0E    0E    0A  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCatAll = dataCatAll.drop(features,axis=1)\n",
    "dataCatAll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'cat1', u'cat2', u'cat3', u'cat4', u'cat5', u'cat6', u'cat7', u'cat8',\n",
      "       u'cat9', u'cat10', u'cat11', u'cat12', u'cat13', u'cat14', u'cat15',\n",
      "       u'cat16', u'cat17', u'cat18', u'cat19', u'cat20', u'cat21', u'cat22',\n",
      "       u'cat23', u'cat24', u'cat25', u'cat26', u'cat27', u'cat28', u'cat29',\n",
      "       u'cat30', u'cat31', u'cat32', u'cat33', u'cat34', u'cat35', u'cat36',\n",
      "       u'cat37', u'cat38', u'cat39', u'cat40', u'cat41', u'cat42', u'cat43',\n",
      "       u'cat44', u'cat45', u'cat46', u'cat47', u'cat48', u'cat49', u'cat50',\n",
      "       u'cat51', u'cat52', u'cat53', u'cat54', u'cat55', u'cat56', u'cat57',\n",
      "       u'cat58', u'cat59', u'cat60', u'cat61', u'cat62', u'cat63', u'cat64',\n",
      "       u'cat65', u'cat66', u'cat67', u'cat68', u'cat69', u'cat70', u'cat71',\n",
      "       u'cat72', u'cat73', u'cat74', u'cat75', u'cat76', u'cat77', u'cat78',\n",
      "       u'cat79', u'cat80', u'cat81', u'cat82', u'cat83', u'cat84', u'cat85',\n",
      "       u'cat86', u'cat87', u'cat88', u'cat89', u'cat90', u'cat91', u'cat92',\n",
      "       u'cat93', u'cat94', u'cat95', u'cat96', u'cat97', u'cat98'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in dataCatAll.columns:\n",
    "    if (col.find('cat') !=-1):\n",
    "#        print(col)\n",
    "        dataCatAll[col]=le.fit_transform(dataCatAll[col])\n",
    "#         dataAll[col] = dataAll[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "#         le.classes_ = np.append(le.classes_, '<unknown>')\n",
    "#         data_test_raw[str(col+'_numerical')]=le.transform(data_test_raw[col])\n",
    "print(dataCatAll.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat89</th>\n",
       "      <th>cat90</th>\n",
       "      <th>cat91</th>\n",
       "      <th>cat92</th>\n",
       "      <th>cat93</th>\n",
       "      <th>cat94</th>\n",
       "      <th>cat95</th>\n",
       "      <th>cat96</th>\n",
       "      <th>cat97</th>\n",
       "      <th>cat98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10  ...    cat89  \\\n",
       "0     0     1     0     1     0     0     0     0     1      0  ...        0   \n",
       "1     0     1     0     0     0     0     0     0     1      1  ...        0   \n",
       "2     0     1     0     0     1     0     0     0     1      1  ...        0   \n",
       "3     1     1     0     1     0     0     0     0     1      0  ...        0   \n",
       "4     0     1     0     1     0     0     0     0     1      1  ...        0   \n",
       "\n",
       "   cat90  cat91  cat92  cat93  cat94  cat95  cat96  cat97  cat98  \n",
       "0      0      0      0      3      1      2      4      0      2  \n",
       "1      0      0      0      3      3      2      4      4      3  \n",
       "2      0      0      0      3      3      2      4      4      0  \n",
       "3      0      0      0      3      3      2      4      4      3  \n",
       "4      0      1      7      3      1      3      4      4      0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCatAll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rescale the labeled categorical data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "x_catAll_2 = mms.fit_transform(dataCatAll_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313500, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.9375    ,  0.07142857,  0.33333333, ...,  0.        ,\n",
       "         0.63636364,  0.86455331],\n",
       "       [ 0.9375    ,  0.78571429,  0.27777778, ...,  0.        ,\n",
       "         0.63636364,  0.32853026],\n",
       "       [ 0.0625    ,  0.78571429,  0.77777778, ...,  0.        ,\n",
       "         0.36363636,  0.53025937],\n",
       "       ..., \n",
       "       [ 0.9375    ,  0.35714286,  0.27777778, ...,  0.        ,\n",
       "         0.68181818,  0.93083573],\n",
       "       [ 0.9375    ,  0.64285714,  0.        , ...,  0.22222222,\n",
       "         0.63636364,  0.31123919],\n",
       "       [ 0.75      ,  0.5       ,  0.33333333, ...,  0.        ,\n",
       "         0.5       ,  0.26224784]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_catAll_2.shape)\n",
    "x_catAll_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restore to x_trainDf and x_testDf - skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # hstack all the features and .\n",
    "# x_allDf = pd.concat([dataCatAll,dataFltAll],axis=1)\n",
    "# x_means = x_allDf.mean()\n",
    "# x_stds = x_allDf.std()\n",
    "# x_allDf = (x_allDf-x_means)/x_stds\n",
    "# x_allDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_Train = x_allDf.iloc[0:len(labelSs),:]\n",
    "# x_Test = x_allDf.iloc[len(labelSs):,:]\n",
    "# y_Train = labelSs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-hot-encoding - skipped in order to keep the alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313500, 275)\n"
     ]
    }
   ],
   "source": [
    "# one-hot-encoding the categorical features\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "x_catAll = enc.fit_transform(dataCatAll)\n",
    "print(x_catAll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split x_train and x_test\n",
    "x_Train = sp.sparse.hstack((x_catAll[0:len(labelSs),:],x_catAll_2[0:len(labelSs),:],sp.sparse.csr_matrix(dataFltAll.as_matrix())[0:len(labelSs),:]))\n",
    "x_Test = sp.sparse.hstack((x_catAll[len(labelSs):,:],x_catAll_2[len(labelSs):,:],sp.sparse.csr_matrix(dataFltAll.as_matrix())[len(labelSs):,:]))\n",
    "y_Train = labelSs.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the dimension of prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125546, 307)\n",
      "(187954, 307)\n",
      "(187954,)\n"
     ]
    }
   ],
   "source": [
    "print(x_Test.shape)\n",
    "print(x_Train.shape)\n",
    "print(y_Train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splite the training data for valication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150363, 307)\n",
      "(150363,)\n",
      "(37591, 307)\n",
      "(37591,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "val_size = 0.2\n",
    "seed = 0\n",
    "x_train, x_val, y_train, y_val = cross_validation.train_test_split(x_Train, y_Train, test_size=val_size, random_state=seed)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x_Train\n",
    "del y_Train\n",
    "del x_catAll\n",
    "del dataCatAll\n",
    "# del trainDf\n",
    "# del testDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = []\n",
    "y_pred_val = []\n",
    "submission = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testList = ['XGBoostTrees', 'AdaBoosting', 'MLPRegressor','Ensemble']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV\n",
    "# # from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cv = 3\n",
    "# # alphas = (1e-2,1e-1,1,1e1,1e2)\n",
    "# # alphas = (5,20,30,40)\n",
    "# alphas = [10]\n",
    "# regCV = RidgeCV(cv=cv,alphas = alphas)\n",
    "# regCV.fit(x_train,y_train)\n",
    "# print('alpha: {}\\n'.format(regCV.alpha_))\n",
    "# # print('cv_values_: {}\\n'.format(regCV.cv_values_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(regCV.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(regCV.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(regCV.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cv = 3\n",
    "# # alphas = (1e-3,1e-2,1e-1,1,1e1,1e2,1e3)\n",
    "# # alphas = (0.0005,0.0007,0.001,0.003,0.005)\n",
    "# # alphas = [0.00005,0.0001,0.0003,0.0005]\n",
    "# alphas = [0.00005]\n",
    "# LassoCV = LassoCV(cv=cv,alphas = alphas)\n",
    "# LassoCV.fit(x_train,y_train)\n",
    "# print('alpha: {}\\n'.format(LassoCV.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(LassoCV.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(LassoCV.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(LassoCV.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipped - Random Forest - using mse rather than mae, because the mae implementation is much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# criterion = 'mse'\n",
    "# n_estimators = [30]\n",
    "# err = 999999999\n",
    "# n_estimator = 0\n",
    "# random_state = 0\n",
    "# for n_est in n_estimators:\n",
    "#     tmpRFReg = RandomForestRegressor(n_estimators = n_est,criterion = criterion, random_state = random_state)\n",
    "#     tmpRFReg.fit(x_train,y_train)\n",
    "#     err_i = mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(tmpRFReg.predict(x_val),ymean,ystd))\n",
    "#     print(err_i)\n",
    "#     if err_i < err:\n",
    "#         RFReg = tmpRFReg\n",
    "#         n_estimator = n_est\n",
    "#         err = err_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('n_estimator = {}'.format(n_estimator))\n",
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(RFReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(RFReg.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(RFReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_train_xgb = xgb.DMatrix(x_train.tocsc(),label=y_train)\n",
    "d_val_xgb = xgb.DMatrix(x_val.tocsc(),label = y_val)\n",
    "x_val_xgb = xgb.DMatrix(x_val.tocsc())\n",
    "d_test_xgb = xgb.DMatrix(x_Test.tocsc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mae:0.246067\ttrain-mae:0.246598\n",
      "[1]\teval-mae:0.233767\ttrain-mae:0.234284\n",
      "[2]\teval-mae:0.222084\ttrain-mae:0.222586\n",
      "[3]\teval-mae:0.210995\ttrain-mae:0.211482\n",
      "[4]\teval-mae:0.200467\ttrain-mae:0.200936\n",
      "[5]\teval-mae:0.190472\ttrain-mae:0.190926\n",
      "[6]\teval-mae:0.180988\ttrain-mae:0.18143\n",
      "[7]\teval-mae:0.171998\ttrain-mae:0.172426\n",
      "[8]\teval-mae:0.163477\ttrain-mae:0.16389\n",
      "[9]\teval-mae:0.15541\ttrain-mae:0.155805\n",
      "[10]\teval-mae:0.147779\ttrain-mae:0.148151\n",
      "[11]\teval-mae:0.140552\ttrain-mae:0.14091\n",
      "[12]\teval-mae:0.133729\ttrain-mae:0.134068\n",
      "[13]\teval-mae:0.12729\ttrain-mae:0.127614\n",
      "[14]\teval-mae:0.121224\ttrain-mae:0.121532\n",
      "[15]\teval-mae:0.11552\ttrain-mae:0.115805\n",
      "[16]\teval-mae:0.110167\ttrain-mae:0.110428\n",
      "[17]\teval-mae:0.105141\ttrain-mae:0.105384\n",
      "[18]\teval-mae:0.100433\ttrain-mae:0.100656\n",
      "[19]\teval-mae:0.096029\ttrain-mae:0.096243\n",
      "[20]\teval-mae:0.091919\ttrain-mae:0.092121\n",
      "[21]\teval-mae:0.08808\ttrain-mae:0.088282\n",
      "[22]\teval-mae:0.084509\ttrain-mae:0.084706\n",
      "[23]\teval-mae:0.081209\ttrain-mae:0.081395\n",
      "[24]\teval-mae:0.078156\ttrain-mae:0.078325\n",
      "[25]\teval-mae:0.075318\ttrain-mae:0.075474\n",
      "[26]\teval-mae:0.072708\ttrain-mae:0.07284\n",
      "[27]\teval-mae:0.070304\ttrain-mae:0.070413\n",
      "[28]\teval-mae:0.06808\ttrain-mae:0.068159\n",
      "[29]\teval-mae:0.066028\ttrain-mae:0.066081\n",
      "[30]\teval-mae:0.064154\ttrain-mae:0.064172\n",
      "[31]\teval-mae:0.062426\ttrain-mae:0.062421\n",
      "[32]\teval-mae:0.060842\ttrain-mae:0.060811\n",
      "[33]\teval-mae:0.059375\ttrain-mae:0.05933\n",
      "[34]\teval-mae:0.058014\ttrain-mae:0.057958\n",
      "[35]\teval-mae:0.056794\ttrain-mae:0.05671\n",
      "[36]\teval-mae:0.055667\ttrain-mae:0.055565\n",
      "[37]\teval-mae:0.054625\ttrain-mae:0.054501\n",
      "[38]\teval-mae:0.053681\ttrain-mae:0.053535\n",
      "[39]\teval-mae:0.05282\ttrain-mae:0.052657\n",
      "[40]\teval-mae:0.052022\ttrain-mae:0.051839\n",
      "[41]\teval-mae:0.051298\ttrain-mae:0.051099\n",
      "[42]\teval-mae:0.050617\ttrain-mae:0.050408\n",
      "[43]\teval-mae:0.049997\ttrain-mae:0.049774\n",
      "[44]\teval-mae:0.049421\ttrain-mae:0.049195\n",
      "[45]\teval-mae:0.048905\ttrain-mae:0.048672\n",
      "[46]\teval-mae:0.048425\ttrain-mae:0.048184\n",
      "[47]\teval-mae:0.047993\ttrain-mae:0.047743\n",
      "[48]\teval-mae:0.047602\ttrain-mae:0.047343\n",
      "[49]\teval-mae:0.047234\ttrain-mae:0.046965\n",
      "[50]\teval-mae:0.046894\ttrain-mae:0.046617\n",
      "[51]\teval-mae:0.04658\ttrain-mae:0.046294\n",
      "[52]\teval-mae:0.046287\ttrain-mae:0.045999\n",
      "[53]\teval-mae:0.046025\ttrain-mae:0.045734\n",
      "[54]\teval-mae:0.045781\ttrain-mae:0.045487\n",
      "[55]\teval-mae:0.045546\ttrain-mae:0.045245\n",
      "[56]\teval-mae:0.04534\ttrain-mae:0.045038\n",
      "[57]\teval-mae:0.045135\ttrain-mae:0.044831\n",
      "[58]\teval-mae:0.04497\ttrain-mae:0.04466\n",
      "[59]\teval-mae:0.044782\ttrain-mae:0.04447\n",
      "[60]\teval-mae:0.044635\ttrain-mae:0.044321\n",
      "[61]\teval-mae:0.044493\ttrain-mae:0.044172\n",
      "[62]\teval-mae:0.044356\ttrain-mae:0.044033\n",
      "[63]\teval-mae:0.044214\ttrain-mae:0.043891\n",
      "[64]\teval-mae:0.044103\ttrain-mae:0.043775\n",
      "[65]\teval-mae:0.044\ttrain-mae:0.04367\n",
      "[66]\teval-mae:0.043902\ttrain-mae:0.043565\n",
      "[67]\teval-mae:0.043794\ttrain-mae:0.043453\n",
      "[68]\teval-mae:0.043717\ttrain-mae:0.043368\n",
      "[69]\teval-mae:0.043627\ttrain-mae:0.043275\n",
      "[70]\teval-mae:0.043549\ttrain-mae:0.043189\n",
      "[71]\teval-mae:0.043462\ttrain-mae:0.043099\n",
      "[72]\teval-mae:0.043396\ttrain-mae:0.043028\n",
      "[73]\teval-mae:0.043333\ttrain-mae:0.042961\n",
      "[74]\teval-mae:0.043272\ttrain-mae:0.042896\n",
      "[75]\teval-mae:0.043213\ttrain-mae:0.04283\n",
      "[76]\teval-mae:0.043151\ttrain-mae:0.042766\n",
      "[77]\teval-mae:0.043104\ttrain-mae:0.042718\n",
      "[78]\teval-mae:0.043058\ttrain-mae:0.042667\n",
      "[79]\teval-mae:0.043001\ttrain-mae:0.042611\n",
      "[80]\teval-mae:0.042953\ttrain-mae:0.042558\n",
      "[81]\teval-mae:0.042914\ttrain-mae:0.042519\n",
      "[82]\teval-mae:0.042869\ttrain-mae:0.042472\n",
      "[83]\teval-mae:0.042826\ttrain-mae:0.042428\n",
      "[84]\teval-mae:0.042789\ttrain-mae:0.04239\n",
      "[85]\teval-mae:0.04276\ttrain-mae:0.042359\n",
      "[86]\teval-mae:0.042726\ttrain-mae:0.042322\n",
      "[87]\teval-mae:0.042693\ttrain-mae:0.042289\n",
      "[88]\teval-mae:0.042657\ttrain-mae:0.042246\n",
      "[89]\teval-mae:0.042627\ttrain-mae:0.042214\n",
      "[90]\teval-mae:0.042597\ttrain-mae:0.042179\n",
      "[91]\teval-mae:0.042565\ttrain-mae:0.042144\n",
      "[92]\teval-mae:0.042526\ttrain-mae:0.042106\n",
      "[93]\teval-mae:0.042498\ttrain-mae:0.042077\n",
      "[94]\teval-mae:0.042468\ttrain-mae:0.042044\n",
      "[95]\teval-mae:0.042441\ttrain-mae:0.042013\n",
      "[96]\teval-mae:0.042408\ttrain-mae:0.041979\n",
      "[97]\teval-mae:0.042387\ttrain-mae:0.041956\n",
      "[98]\teval-mae:0.042371\ttrain-mae:0.041939\n",
      "[99]\teval-mae:0.042348\ttrain-mae:0.041912\n",
      "[100]\teval-mae:0.042323\ttrain-mae:0.041885\n",
      "[101]\teval-mae:0.042301\ttrain-mae:0.041861\n",
      "[102]\teval-mae:0.042274\ttrain-mae:0.041833\n",
      "[103]\teval-mae:0.042256\ttrain-mae:0.041815\n",
      "[104]\teval-mae:0.042236\ttrain-mae:0.041793\n",
      "[105]\teval-mae:0.042217\ttrain-mae:0.04177\n",
      "[106]\teval-mae:0.042195\ttrain-mae:0.041747\n",
      "[107]\teval-mae:0.042181\ttrain-mae:0.04173\n",
      "[108]\teval-mae:0.042162\ttrain-mae:0.04171\n",
      "[109]\teval-mae:0.042147\ttrain-mae:0.041692\n",
      "[110]\teval-mae:0.042123\ttrain-mae:0.041669\n",
      "[111]\teval-mae:0.042106\ttrain-mae:0.041649\n",
      "[112]\teval-mae:0.04209\ttrain-mae:0.041631\n",
      "[113]\teval-mae:0.042071\ttrain-mae:0.041612\n",
      "[114]\teval-mae:0.042054\ttrain-mae:0.041595\n",
      "[115]\teval-mae:0.04204\ttrain-mae:0.041579\n",
      "[116]\teval-mae:0.042021\ttrain-mae:0.04156\n",
      "[117]\teval-mae:0.042011\ttrain-mae:0.041549\n",
      "[118]\teval-mae:0.041997\ttrain-mae:0.041533\n",
      "[119]\teval-mae:0.041978\ttrain-mae:0.041513\n",
      "[120]\teval-mae:0.041964\ttrain-mae:0.041498\n",
      "[121]\teval-mae:0.041949\ttrain-mae:0.041482\n",
      "[122]\teval-mae:0.041936\ttrain-mae:0.041466\n",
      "[123]\teval-mae:0.041923\ttrain-mae:0.04145\n",
      "[124]\teval-mae:0.04191\ttrain-mae:0.041433\n",
      "[125]\teval-mae:0.041898\ttrain-mae:0.041419\n",
      "[126]\teval-mae:0.041889\ttrain-mae:0.041408\n",
      "[127]\teval-mae:0.04188\ttrain-mae:0.041397\n",
      "[128]\teval-mae:0.041862\ttrain-mae:0.04138\n",
      "[129]\teval-mae:0.041849\ttrain-mae:0.041363\n",
      "[130]\teval-mae:0.04183\ttrain-mae:0.041344\n",
      "[131]\teval-mae:0.041817\ttrain-mae:0.041328\n",
      "[132]\teval-mae:0.041804\ttrain-mae:0.041313\n",
      "[133]\teval-mae:0.04179\ttrain-mae:0.041298\n",
      "[134]\teval-mae:0.041781\ttrain-mae:0.041287\n",
      "[135]\teval-mae:0.04177\ttrain-mae:0.041274\n",
      "[136]\teval-mae:0.04176\ttrain-mae:0.041261\n",
      "[137]\teval-mae:0.041747\ttrain-mae:0.041247\n",
      "[138]\teval-mae:0.041732\ttrain-mae:0.04123\n",
      "[139]\teval-mae:0.041724\ttrain-mae:0.04122\n",
      "[140]\teval-mae:0.041717\ttrain-mae:0.041211\n",
      "[141]\teval-mae:0.041708\ttrain-mae:0.041201\n",
      "[142]\teval-mae:0.041701\ttrain-mae:0.041191\n",
      "[143]\teval-mae:0.041692\ttrain-mae:0.041182\n",
      "[144]\teval-mae:0.041681\ttrain-mae:0.041168\n",
      "[145]\teval-mae:0.041667\ttrain-mae:0.041153\n",
      "[146]\teval-mae:0.041661\ttrain-mae:0.041145\n",
      "[147]\teval-mae:0.041654\ttrain-mae:0.041137\n",
      "[148]\teval-mae:0.041648\ttrain-mae:0.04113\n",
      "[149]\teval-mae:0.041641\ttrain-mae:0.041121\n",
      "[150]\teval-mae:0.04163\ttrain-mae:0.041108\n",
      "[151]\teval-mae:0.041622\ttrain-mae:0.041099\n",
      "[152]\teval-mae:0.041613\ttrain-mae:0.041087\n",
      "[153]\teval-mae:0.041601\ttrain-mae:0.041076\n",
      "[154]\teval-mae:0.041591\ttrain-mae:0.041064\n",
      "[155]\teval-mae:0.04158\ttrain-mae:0.041053\n",
      "[156]\teval-mae:0.041573\ttrain-mae:0.041044\n",
      "[157]\teval-mae:0.041567\ttrain-mae:0.041036\n",
      "[158]\teval-mae:0.041557\ttrain-mae:0.041025\n",
      "[159]\teval-mae:0.041551\ttrain-mae:0.041017\n",
      "[160]\teval-mae:0.041543\ttrain-mae:0.041008\n",
      "[161]\teval-mae:0.041539\ttrain-mae:0.041002\n",
      "[162]\teval-mae:0.041533\ttrain-mae:0.040994\n",
      "[163]\teval-mae:0.041522\ttrain-mae:0.040983\n",
      "[164]\teval-mae:0.041517\ttrain-mae:0.040975\n",
      "[165]\teval-mae:0.04151\ttrain-mae:0.040966\n",
      "[166]\teval-mae:0.041503\ttrain-mae:0.040959\n",
      "[167]\teval-mae:0.041497\ttrain-mae:0.04095\n",
      "[168]\teval-mae:0.041489\ttrain-mae:0.04094\n",
      "[169]\teval-mae:0.041484\ttrain-mae:0.040933\n",
      "[170]\teval-mae:0.041475\ttrain-mae:0.040924\n",
      "[171]\teval-mae:0.041471\ttrain-mae:0.040917\n",
      "[172]\teval-mae:0.041465\ttrain-mae:0.040912\n",
      "[173]\teval-mae:0.041461\ttrain-mae:0.040906\n",
      "[174]\teval-mae:0.041454\ttrain-mae:0.040897\n",
      "[175]\teval-mae:0.041446\ttrain-mae:0.040888\n",
      "[176]\teval-mae:0.041437\ttrain-mae:0.040879\n",
      "[177]\teval-mae:0.041432\ttrain-mae:0.040873\n",
      "[178]\teval-mae:0.041422\ttrain-mae:0.040862\n",
      "[179]\teval-mae:0.041418\ttrain-mae:0.040857\n",
      "[180]\teval-mae:0.041411\ttrain-mae:0.040849\n",
      "[181]\teval-mae:0.041402\ttrain-mae:0.040838\n",
      "[182]\teval-mae:0.041396\ttrain-mae:0.040831\n",
      "[183]\teval-mae:0.041391\ttrain-mae:0.040825\n",
      "[184]\teval-mae:0.041388\ttrain-mae:0.04082\n",
      "[185]\teval-mae:0.041381\ttrain-mae:0.04081\n",
      "[186]\teval-mae:0.041376\ttrain-mae:0.040801\n",
      "[187]\teval-mae:0.041371\ttrain-mae:0.040794\n",
      "[188]\teval-mae:0.041365\ttrain-mae:0.040788\n",
      "[189]\teval-mae:0.041361\ttrain-mae:0.040782\n",
      "[190]\teval-mae:0.041353\ttrain-mae:0.040774\n",
      "[191]\teval-mae:0.041348\ttrain-mae:0.040766\n",
      "[192]\teval-mae:0.041344\ttrain-mae:0.040763\n",
      "[193]\teval-mae:0.04134\ttrain-mae:0.040755\n",
      "[194]\teval-mae:0.041333\ttrain-mae:0.040744\n",
      "[195]\teval-mae:0.041331\ttrain-mae:0.04074\n",
      "[196]\teval-mae:0.041324\ttrain-mae:0.040731\n",
      "[197]\teval-mae:0.04132\ttrain-mae:0.040725\n",
      "[198]\teval-mae:0.041317\ttrain-mae:0.040721\n",
      "[199]\teval-mae:0.04131\ttrain-mae:0.040711\n",
      "[200]\teval-mae:0.041304\ttrain-mae:0.040703\n",
      "[201]\teval-mae:0.041299\ttrain-mae:0.040697\n",
      "[202]\teval-mae:0.041292\ttrain-mae:0.040687\n",
      "[203]\teval-mae:0.041285\ttrain-mae:0.04068\n",
      "[204]\teval-mae:0.041281\ttrain-mae:0.040675\n",
      "[205]\teval-mae:0.041277\ttrain-mae:0.040669\n",
      "[206]\teval-mae:0.041274\ttrain-mae:0.040664\n",
      "[207]\teval-mae:0.041268\ttrain-mae:0.040657\n",
      "[208]\teval-mae:0.041263\ttrain-mae:0.040651\n",
      "[209]\teval-mae:0.04126\ttrain-mae:0.040647\n",
      "[210]\teval-mae:0.041256\ttrain-mae:0.040642\n",
      "[211]\teval-mae:0.041251\ttrain-mae:0.040635\n",
      "[212]\teval-mae:0.041247\ttrain-mae:0.04063\n",
      "[213]\teval-mae:0.041242\ttrain-mae:0.040623\n",
      "[214]\teval-mae:0.041239\ttrain-mae:0.040619\n",
      "[215]\teval-mae:0.041235\ttrain-mae:0.040614\n",
      "[216]\teval-mae:0.041233\ttrain-mae:0.040609\n",
      "[217]\teval-mae:0.041231\ttrain-mae:0.040605\n",
      "[218]\teval-mae:0.041229\ttrain-mae:0.040602\n",
      "[219]\teval-mae:0.041221\ttrain-mae:0.040594\n",
      "[220]\teval-mae:0.041211\ttrain-mae:0.040583\n",
      "[221]\teval-mae:0.041207\ttrain-mae:0.040576\n",
      "[222]\teval-mae:0.041201\ttrain-mae:0.040571\n",
      "[223]\teval-mae:0.041199\ttrain-mae:0.040568\n",
      "[224]\teval-mae:0.041196\ttrain-mae:0.040563\n",
      "[225]\teval-mae:0.041192\ttrain-mae:0.040558\n",
      "[226]\teval-mae:0.04119\ttrain-mae:0.040554\n",
      "[227]\teval-mae:0.041186\ttrain-mae:0.040551\n",
      "[228]\teval-mae:0.041183\ttrain-mae:0.040545\n",
      "[229]\teval-mae:0.041181\ttrain-mae:0.040541\n",
      "[230]\teval-mae:0.041179\ttrain-mae:0.040537\n",
      "[231]\teval-mae:0.041176\ttrain-mae:0.040534\n",
      "[232]\teval-mae:0.041171\ttrain-mae:0.040528\n",
      "[233]\teval-mae:0.041168\ttrain-mae:0.040524\n",
      "[234]\teval-mae:0.041164\ttrain-mae:0.040518\n",
      "[235]\teval-mae:0.041158\ttrain-mae:0.04051\n",
      "[236]\teval-mae:0.041156\ttrain-mae:0.040506\n",
      "[237]\teval-mae:0.041154\ttrain-mae:0.040503\n",
      "[238]\teval-mae:0.041151\ttrain-mae:0.0405\n",
      "[239]\teval-mae:0.041146\ttrain-mae:0.040494\n",
      "[240]\teval-mae:0.041143\ttrain-mae:0.04049\n",
      "[241]\teval-mae:0.041141\ttrain-mae:0.040486\n",
      "[242]\teval-mae:0.041138\ttrain-mae:0.040481\n",
      "[243]\teval-mae:0.041133\ttrain-mae:0.040475\n",
      "[244]\teval-mae:0.04113\ttrain-mae:0.040471\n",
      "[245]\teval-mae:0.041129\ttrain-mae:0.040468\n",
      "[246]\teval-mae:0.041126\ttrain-mae:0.040465\n",
      "[247]\teval-mae:0.041124\ttrain-mae:0.040461\n",
      "[248]\teval-mae:0.041121\ttrain-mae:0.040455\n",
      "[249]\teval-mae:0.041117\ttrain-mae:0.040451\n",
      "[250]\teval-mae:0.041114\ttrain-mae:0.040446\n",
      "[251]\teval-mae:0.041112\ttrain-mae:0.040443\n",
      "[252]\teval-mae:0.041111\ttrain-mae:0.040441\n",
      "[253]\teval-mae:0.04111\ttrain-mae:0.040438\n",
      "[254]\teval-mae:0.041108\ttrain-mae:0.040433\n",
      "[255]\teval-mae:0.041106\ttrain-mae:0.040429\n",
      "[256]\teval-mae:0.041104\ttrain-mae:0.040427\n",
      "[257]\teval-mae:0.041097\ttrain-mae:0.04042\n",
      "[258]\teval-mae:0.041094\ttrain-mae:0.040416\n",
      "[259]\teval-mae:0.041091\ttrain-mae:0.040412\n",
      "[260]\teval-mae:0.04109\ttrain-mae:0.040409\n",
      "[261]\teval-mae:0.041083\ttrain-mae:0.0404\n",
      "[262]\teval-mae:0.041082\ttrain-mae:0.040398\n",
      "[263]\teval-mae:0.04108\ttrain-mae:0.040395\n",
      "[264]\teval-mae:0.041077\ttrain-mae:0.040389\n",
      "[265]\teval-mae:0.041075\ttrain-mae:0.040387\n",
      "[266]\teval-mae:0.041074\ttrain-mae:0.040384\n",
      "[267]\teval-mae:0.041073\ttrain-mae:0.040381\n",
      "[268]\teval-mae:0.041068\ttrain-mae:0.040375\n",
      "[269]\teval-mae:0.041066\ttrain-mae:0.04037\n",
      "[270]\teval-mae:0.041062\ttrain-mae:0.040366\n"
     ]
    }
   ],
   "source": [
    "num_round = 1500\n",
    "# params = {'eval_metric':'mae','max_depth':6,'colsample_bytree':1,'alpha':1,'gamma':1,'eta':0.155,'min_child_weight':1}# 1132, 75 rounds\n",
    "# params = {'eval_metric':'mae','max_depth':6,'colsample_bytree':1,'alpha':1,'gamma':1,'eta':0.15,'min_child_weight':1}# 1136, 75 rounds\n",
    "# params = {'eval_metric':'mae','max_depth':12,'colsample_bytree':1,'alpha':1,'gamma':0.01,'eta':0.05,'min_child_weight':1}# 1136, 500 rounds\n",
    "params = {'eval_metric':'mae','max_depth':6,'colsample_bytree':1,'alpha':1,'gamma':0.01,'eta':0.05,'min_child_weight':0}# 1130, 2500 rounds\n",
    "\n",
    "watchlist  = [(d_val_xgb,'eval'), (d_train_xgb,'train')]\n",
    "gbt = xgb.train(params, d_train_xgb,num_round,watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(gbt.predict(x_val_xgb),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(gbt.predict(d_test_xgb),ymean,ystd)\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(gbt.predict(x_val_xgb),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_estimators = [30, 60, 90, 120]\n",
    "# n_estimators = [10,20,30,40]\n",
    "n_estimators = [6]\n",
    "base_estimator = Ridge(alpha = 40)\n",
    "err = 999999999\n",
    "n_estimator = 0\n",
    "random_state = 0\n",
    "for n_est in n_estimators:\n",
    "    tmpAdReg = AdaBoostRegressor(n_estimators = n_est, random_state = random_state,base_estimator = base_estimator)\n",
    "#     tmpAdReg = AdaBoostRegressor(n_estimators = n_est, random_state = random_state)\n",
    "    tmpAdReg.fit(x_train,y_train)\n",
    "    err_i = mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(tmpAdReg.predict(x_val),ymean,ystd))\n",
    "    print(err_i)\n",
    "    if err_i < err:\n",
    "        AdReg = tmpAdReg\n",
    "        n_estimator = n_est\n",
    "        err = err_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('n_estimator = {}'.format(n_estimator))\n",
    "print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(AdReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(AdReg.predict(x_Test),ymean,ystd)\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(AdReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipped - K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_neighbors = [5, 10, 15]\n",
    "# weights = 'distance'\n",
    "# err = 999999999\n",
    "# n_nns = 0\n",
    "# # random_state = 0\n",
    "# for n_nn in n_neighbors:\n",
    "#     tmpKNReg = KNeighborsRegressor(n_neighbors = n_nn,weights = weights)\n",
    "#     tmpKNReg.fit(x_train,y_train)\n",
    "#     err_i = mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(tmpKNReg.predict(x_val),ymean,ystd))\n",
    "#     print(err_i)\n",
    "#     if err_i < err:\n",
    "#         KNReg = tmpKNReg\n",
    "#         n_nns = n_nn\n",
    "#         err = err_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('n_neighbors = {}'.format(n_nns))\n",
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(KNReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(KNReg.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(KNReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # SVReg = svm.SVR(kernel = 'rbf')\n",
    "# # SVReg.fit(x_train,y_train)\n",
    "# SVReg = LinearSVR(C=0.5)\n",
    "# SVReg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(SVReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred_i = lossRestore(SVReg.predict(x_Test),ymean,ystd)\n",
    "# y_pred.append(y_pred_i)\n",
    "# y_pred_val.append(lossRestore(SVReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLPReg = MLPRegressor(alpha = 1e-5, hidden_layer_sizes = (35,3),random_state=0,early_stopping=True)\n",
    "MLPReg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(lossRestore(y_val,ymean,ystd),lossRestore(MLPReg.predict(x_val),ymean,ystd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_i = lossRestore(MLPReg.predict(x_Test),ymean,ystd)\n",
    "y_pred.append(y_pred_i)\n",
    "y_pred_val.append(lossRestore(MLPReg.predict(x_val),ymean,ystd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save files for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ensemble the results\n",
    "y_pred.append(np.ndarray.mean(np.vstack(y_pred).T,axis=1))\n",
    "\n",
    "# ensembled y_val\n",
    "print('The loss of the ensembled result:')\n",
    "y_pred_val_en = np.ndarray.mean(np.vstack(y_pred_val).T,axis=1)\n",
    "mean_absolute_error(lossRestore(y_val,ymean,ystd),y_pred_val_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save all the predictions for submission\n",
    "for i,stri in enumerate(testList):\n",
    "    submission['id'] = subId\n",
    "    submission['loss']=pd.Series(data=y_pred[i])\n",
    "    submission.to_csv('../output/'+stri+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump([regCV, gbt, AdReg, MLPReg, y_pred, y_pred_val, x_train, x_val, y_train, y_val, x_Test]\n",
    "            ,'../output/models_data_on_raw_features.pkl',compress=3) \n",
    "\n",
    "# clf = joblib.load('filename.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
